#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YouTube Shorts Script Generator
Generates video titles and 35-50 second scripts for restaurant promotional shorts
Uses Google Gemini API and Google Cloud TTS
Requires: pip install google-generativeai gradio python-dotenv google-cloud-texttospeech
"""

import os
import json
import subprocess
import gradio as gr
import google.generativeai as genai
from google.cloud import texttospeech
import azure.cognitiveservices.speech as speechsdk
from dotenv import load_dotenv
import socket
from typing import List, Dict, Tuple, Optional
from pathlib import Path
import tempfile
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
import base64
import io
from PIL import Image as PILImage
import requests
import logging

# byteplussdkarkruntime removed due to installation issues on Python 3.13
Ark = None # Placeholder to minimize diff noise, though we won't use it

# Configure logging
logging.basicConfig(
    filename='server_debug.log',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

# Path to save last input
LAST_INPUT_FILE = Path(__file__).parent / "last_input.json"
LAST_SELECTION_FILE = Path(__file__).parent / "last_video_selection.json"
LAST_OUTPUT_FILE = Path(__file__).parent / "last_output.json"

# Video merger paths
VIDEOS_DIR = Path(__file__).parent.parent / "videos"
OUTPUT_DIR = Path(__file__).parent.parent / "final_shorts"
BGM_DIR = Path(__file__).parent.parent / "background music"
TTS_AUDIO_DIR = Path(__file__).parent / "audio"

# Video generation paths
INPUT_DIR = Path(__file__).parent.parent / "input"
OUTPUT_BYTEPLUS_DIR = Path(__file__).parent.parent / "output_byteplus"

# BytePlus API configuration
ARK_BASE_URL = "https://ark.ap-southeast.bytepluses.com/api/v3"
ARK_VIDEO_TASK_ENDPOINT = "/contents/generations/tasks"

# Network safety timeouts (prevents endless loading when APIs hang)
GENERATION_TIMEOUT = 60  # seconds for Gemini requests
TTS_TIMEOUT = 30         # seconds for Google TTS

# Create output directory
OUTPUT_DIR.mkdir(exist_ok=True)
TTS_AUDIO_DIR.mkdir(exist_ok=True)

# Script styles with Korean and English descriptions
SCRIPT_STYLES = {
    "ë¦¬ë·°í˜• (Review)": {
        "korean": "ë¦¬ë·°í˜•",
        "english": "Review",
        "description": "ê°œì¸ì ì¸ ë°©ë¬¸ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ì§„ì†”í•œ ë¦¬ë·° ìŠ¤íƒ€ì¼"
    },
    "í™ë³´í˜• (Promotional)": {
        "korean": "í™ë³´í˜•",
        "english": "Promotional",
        "description": "ë§¤ì¥ì˜ ì¥ì ì„ ê°•ì¡°í•˜ëŠ” ì§ì ‘ì ì¸ í™ë³´ ìŠ¤íƒ€ì¼"
    },
    "ìŠ¤í† ë¦¬í…”ë§í˜• (Storytelling)": {
        "korean": "ìŠ¤í† ë¦¬í…”ë§í˜•",
        "english": "Storytelling",
        "description": "ê°€ê²Œì˜ ìŠ¤í† ë¦¬ë‚˜ ì‚¬ì¥ë‹˜ì˜ ì´ì•¼ê¸°ë¥¼ ë‹´ì€ ê°ì„± ìŠ¤íƒ€ì¼"
    },
    "íŒ/ì¶”ì²œí˜• (Tips)": {
        "korean": "íŒ/ì¶”ì²œí˜•",
        "english": "Tips & Recommendation",
        "description": "ê¿€íŒì´ë‚˜ ì¶”ì²œ ë©”ë‰´ë¥¼ ì†Œê°œí•˜ëŠ” ì •ë³´ ì œê³µ ìŠ¤íƒ€ì¼"
    },
    "ê¸´ê¸‰/FOMOí˜• (Urgency)": {
        "korean": "ê¸´ê¸‰/FOMOí˜•",
        "english": "Urgency/FOMO",
        "description": "ì§€ê¸ˆ ê°€ì•¼ í•˜ëŠ” ì´ìœ ë¥¼ ê°•ì¡°í•˜ëŠ” ê¸´ë°•ê° ìˆëŠ” ìŠ¤íƒ€ì¼"
    },
    "ë¹„êµí˜• (Comparison)": {
        "korean": "ë¹„êµí˜•",
        "english": "Comparison",
        "description": "ë‹¤ë¥¸ ê³³ê³¼ ë¹„êµí•˜ë©° ì°¨ë³„ì ì„ ë¶€ê°í•˜ëŠ” ìŠ¤íƒ€ì¼"
    },
    "ì§ˆë¬¸í˜• (Question)": {
        "korean": "ì§ˆë¬¸í˜•",
        "english": "Question",
        "description": "ì‹œì²­ìì—ê²Œ ì§ˆë¬¸ì„ ë˜ì§€ë©° í˜¸ê¸°ì‹¬ì„ ìœ ë°œí•˜ëŠ” ìŠ¤íƒ€ì¼"
    }
}

# Intro styles
INTRO_STYLES = {
    "ì¶©ê²©ì  ì‚¬ì‹¤í˜•": {
        "korean": "ì¶©ê²©ì  ì‚¬ì‹¤í˜•",
        "english": "Shocking Fact",
        "description": "ë†€ë¼ìš´ ì‚¬ì‹¤ë¡œ ì‹œì‘ (ì˜ˆ: ì•Œê³  ê³„ì…¨ë‚˜ìš”? ì´ ì§‘ì€...)"
    },
    "ì§ˆë¬¸ ë˜ì§€ê¸°í˜•": {
        "korean": "ì§ˆë¬¸ ë˜ì§€ê¸°í˜•",
        "english": "Question Hook",
        "description": "ì‹œì²­ìì—ê²Œ ì§ˆë¬¸ ë˜ì§€ê¸° (ì˜ˆ: ì—¬ëŸ¬ë¶„ì€ ì–´ë–¤ ìŒì‹ ì¢‹ì•„í•˜ì„¸ìš”?)"
    },
    "ë†€ëŒ í›„í¬í˜•": {
        "korean": "ë†€ëŒ í›„í¬í˜•",
        "english": "Surprise Hook",
        "description": "ê°íƒ„ì‚¬ë¡œ ì‹œì‘ (ì˜ˆ: ì™€, ì§„ì§œ ëŒ€ë°•ì´ì—ìš”!)"
    },
    "ì§€ì—­ ì¸ì¦í˜•": {
        "korean": "ì§€ì—­ ì¸ì¦í˜•",
        "english": "Local Authority",
        "description": "ì§€ì—­ ì‚¬ëŒë“¤ì˜ ì¸ì • ê°•ì¡° (ì˜ˆ: ê³ ì–‘ì‹œ íƒì‹œ ê¸°ì‚¬ë‹˜ë“¤ì´ 1ë“±ìœ¼ë¡œ ë½‘ëŠ”ë‹¤ëŠ”...)"
    },
    "ì§ì„¤ì  ì†Œê°œí˜•": {
        "korean": "ì§ì„¤ì  ì†Œê°œí˜•",
        "english": "Direct Introduction",
        "description": "ë°”ë¡œ ë³¸ë¡ ìœ¼ë¡œ ì‹œì‘ (ì˜ˆ: 40ë…„ ì „í†µì˜ í• ë§¤ ìˆœëŒ€êµ­, ë“œë””ì–´ ë°©ë¬¸í–ˆìŠµë‹ˆë‹¤!)"
    },
    "ë°©ë¬¸ ì¸ì¦í˜•": {
        "korean": "ë°©ë¬¸ ì¸ì¦í˜•",
        "english": "Visit Verification",
        "description": "ë§¤ì¥ ìœ„ì¹˜ì™€ ì´ë¦„ì„ ì–¸ê¸‰í•˜ë©° ë°©ë¬¸ ì‚¬ì‹¤ì„ ì•Œë¦¬ë©° ì‹œì‘ (ì˜ˆ: ì˜¤ëŠ˜ì€ [ìœ„ì¹˜]ì— ìˆëŠ” [ê°€ê²Œì´ë¦„]ì— ë‹¤ë…€ì™”ëŠ”ë°ìš”...)"
    }
}

# Outro styles
OUTRO_STYLES = {
    "ë¬¼ìŒí‘œ ë§ˆë¬´ë¦¬í˜•": {
        "korean": "ë¬¼ìŒí‘œ ë§ˆë¬´ë¦¬í˜•",
        "english": "Question Mark Ending",
        "description": "ì¥ì†Œë¥¼ ë¬¼ìŒí‘œë¡œ ë§ˆë¬´ë¦¬ (ì˜ˆ: ë°°í„°ì§€ê²Œ ë¨¹ì„ ìˆ˜ ìˆëŠ” ì´ê³³ì€?)"
    },
    "ì¥ì  ê°•ì¡° ë¬¼ìŒí˜•": {
        "korean": "ì¥ì  ê°•ì¡° ë¬¼ìŒí˜•",
        "english": "Benefits Question",
        "description": "ë§¤ì¥ ì¥ì  ê°•ì¡° í›„ 'ì´ê³³ì€?'ìœ¼ë¡œ ë§ˆë¬´ë¦¬ (ì˜ˆ: ì‚¼ê²¹ì‚´ì„ ì €ë ´í•˜ê²Œ ë°°í„°ì§€ê²Œ ë¨¹ì„ ìˆ˜ ìˆëŠ” ì´ê³³ì€?)"
    },
    "ë¬¼ìŒí‘œ ì¥ë‚œí˜•": {
        "korean": "ë¬¼ìŒí‘œ ì¥ë‚œí˜•",
        "english": "Playful Question",
        "description": "ì¬ì¹˜ìˆëŠ” ì§ˆë¬¸ìœ¼ë¡œ ë§ˆë¬´ë¦¬ (ì˜ˆ: ì´ ê°€ê²©ì— ë­ ë‚¨ëŠ” ê²ƒ ìˆìœ¼ì„¸ìš”?)"
    },
    "ì¶”ì²œí˜•": {
        "korean": "ì¶”ì²œí˜•",
        "english": "Recommendation",
        "description": "ì§ì ‘ì ì¸ ì¶”ì²œ (ì˜ˆ: ë“ ë“ í•œ í•œ ë¼ ìƒê°ë‚˜ë©´ ê¼­ ë“¤ëŸ¬ë³´ì„¸ìš”!)"
    },
    "í–‰ë™ ìœ ë„í˜•": {
        "korean": "í–‰ë™ ìœ ë„í˜•",
        "english": "Call to Action",
        "description": "ë°©ë¬¸ ìœ ë„ (ì˜ˆ: ì—¬ëŸ¬ë¶„ë„ í•œë²ˆ ê°€ë³´ì‹œê¸¸ ì¶”ì²œë“œë¦½ë‹ˆë‹¤!)"
    },
    "ë°˜ì „ í™•ì‹ í˜•": {
        "korean": "ë°˜ì „ í™•ì‹ í˜•",
        "english": "Confident Conclusion",
        "description": "í™•ì‹ ì„ ì£¼ëŠ” ë§ˆë¬´ë¦¬ (ì˜ˆ: ì§„ì§œ ì°ë§›ì§‘ ë§ë”ë¼ê³ ìš”!)"
    }
}


def save_last_input(restaurant_name: str, description: str,
                    selected_styles: List[str], language: str, intro_style: str, outro_style: str,
                    location: str = "", location_in: str = "intro",
                    include_restaurant_name: bool = True):
    """Save last input to JSON file."""
    data = {
        "restaurant_name": restaurant_name,
        "description": description,
        "selected_styles": selected_styles,
        "language": language,
        "intro_style": intro_style,
        "outro_style": outro_style,
        "location": location,
        "location_in": location_in,
        "include_restaurant_name": include_restaurant_name
    }
    try:
        with open(LAST_INPUT_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"Failed to save last input: {e}")


def load_last_input() -> Dict:
    """Load last input from JSON file."""
    default_values = {
        "restaurant_name": "",
        "description": "",
        "selected_styles": ["ë¦¬ë·°í˜• (Review)", "í™ë³´í˜• (Promotional)"],
        "language": "Korean",
        "intro_style": "ì§ì„¤ì  ì†Œê°œí˜•",
        "outro_style": "ì¶”ì²œí˜•",
        "include_restaurant_name": True
    }

    if not LAST_INPUT_FILE.exists():
        return default_values

    try:
        with open(LAST_INPUT_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
            # Migration path: if strengths or reviews exist, append them to description
            description = data.get("description", "")
            strengths = data.get("strengths", "")
            reviews = data.get("reviews", "")
            
            combined_desc = description
            if strengths:
                combined_desc += f"\n\nì£¼ìš” ì¥ì :\n{strengths}"
            if reviews:
                combined_desc += f"\n\në§¤ì¥ ë¦¬ë·°:\n{reviews}"
            
            data["description"] = combined_desc.strip()
            
            # Remove old keys
            data.pop("strengths", None)
            data.pop("reviews", None)
            
            # Add defaults for intro/outro if not present
            data.setdefault("intro_style", "ì§ì„¤ì  ì†Œê°œí˜•")
            data.setdefault("outro_style", "ì¶”ì²œí˜•")
            data.setdefault("include_restaurant_name", True)
            return data
    except Exception as e:
        print(f"Failed to load last input: {e}")
        return default_values


def save_last_output(output: str, audios: List[str]):
    """Save last generated output to JSON file (text only, no audio paths)."""
    data = {
        "output": output
        # Note: Audio paths are not saved as they are temporary files
    }
    try:
        with open(LAST_OUTPUT_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"Failed to save last output: {e}")


def load_last_output() -> Dict:
    """Load last generated output from JSON file."""
    default_values = {
        "output": "",
        "audios": [None] * 7
    }

    if not LAST_OUTPUT_FILE.exists():
        return default_values

    try:
        with open(LAST_OUTPUT_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
            # Ensure audios list has exactly 7 elements
            audios = data.get("audios", [])
            while len(audios) < 7:
                audios.append(None)
            data["audios"] = audios[:7]  # Limit to 7
            return data
    except Exception as e:
        print(f"Failed to load last output: {e}")
        return default_values


def text_to_speech(text: str, language: str = "Korean", restaurant_name: str = "") -> str:
    """
    Convert text to speech using Google Cloud TTS.

    Args:
        text: Script text to convert
        language: "Korean" or "English"
        restaurant_name: Used for naming the audio file

    Returns:
        Path to generated audio file
    """
    # Fail fast if credentials are missing to avoid long hangs
    credentials_path = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS")
    if credentials_path and not Path(credentials_path).exists():
        print(f"TTS skipped: GOOGLE_APPLICATION_CREDENTIALS not found at {credentials_path}")
        return None

    try:
        # Initialize TTS client
        client = texttospeech.TextToSpeechClient()

        # Set language and voice
        if language == "Korean":
            language_code = "ko-KR"
            voice_name = "ko-KR-Chirp3-HD-Algenib"  # Algenib (Male) voice
        else:
            language_code = "en-US"
            voice_name = "en-US-Neural2-F"  # Female voice

        # Configure synthesis input
        synthesis_input = texttospeech.SynthesisInput(text=text)

        # Configure voice
        voice = texttospeech.VoiceSelectionParams(
            language_code=language_code,
            name=voice_name
        )

        # Configure audio
        audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.MP3,
            speaking_rate=1.2,  # 1.2x speed as per user request
            pitch=0.0
        )

        # Generate speech
        response = client.synthesize_speech(
            input=synthesis_input,
            voice=voice,
            audio_config=audio_config,
            timeout=TTS_TIMEOUT
        )

        # Save to temporary file
        TTS_AUDIO_DIR.mkdir(parents=True, exist_ok=True)
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        safe_restaurant = restaurant_name.strip().replace("/", "_").replace("\\", "_")
        if not safe_restaurant:
            safe_restaurant = "restaurant"
        safe_name = f"{safe_restaurant}_{timestamp}.mp3"
        output_path = TTS_AUDIO_DIR / safe_name
        with open(output_path, "wb") as f:
            f.write(response.audio_content)

        return str(output_path)
    except Exception as e:
        print(f"TTS error: {e}")
        return None


def text_to_speech_azure(text: str, language: str = "Korean", restaurant_name: str = "") -> str:
    """
    Convert text to speech using Azure TTS.
    
    Args:
        text: Script text to convert
        language: "Korean" or "English"
        restaurant_name: Used for naming the audio file
        
    Returns:
        Path to generated audio file
    """
    speech_key = os.environ.get('SPEECH_KEY')
    service_region = os.environ.get('SPEECH_REGION')
    
    if not speech_key or not service_region:
        print("Azure TTS skipped: SPEECH_KEY or SPEECH_REGION not set")
        return None
        
    try:
        speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)
        
        # Set voice based on language
        if language == "Korean":
            # Hyunsu (Male) - requested by user
            speech_config.speech_synthesis_voice_name = "ko-KR-HyunsuNeural"
        else:
            # Andrew (Male) - to match male persona
            speech_config.speech_synthesis_voice_name = "en-US-AndrewNeural"
            
        # Create audio config
        TTS_AUDIO_DIR.mkdir(parents=True, exist_ok=True)
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        safe_restaurant = restaurant_name.strip().replace("/", "_").replace("\\", "_")
        if not safe_restaurant:
            safe_restaurant = "restaurant"
        
        # Add provider suffix to distinguish files
        safe_name = f"{safe_restaurant}_{timestamp}_azure.mp3"
        output_path = TTS_AUDIO_DIR / safe_name
        
        audio_config = speechsdk.audio.AudioOutputConfig(filename=str(output_path))
        
        # Create synthesizer
        synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)
        
        # Synthesize
        # Apply speed adjustment via SSML since Azure SDK doesn't have a direct 'speaking_rate' param like Google
        # 1.2 rate = +20%
        ssml = f"""
        <speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="{language.lower()}">
            <voice name="{speech_config.speech_synthesis_voice_name}">
                <prosody rate="+50.00%">
                    {text}
                </prosody>
            </voice>
        </speak>
        """
        
        result = synthesizer.speak_ssml_async(ssml).get()
        
        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
            return str(output_path)
        elif result.reason == speechsdk.ResultReason.Canceled:
            cancellation_details = result.cancellation_details
            print(f"Azure TTS canceled: {cancellation_details.reason}")
            if cancellation_details.reason == speechsdk.CancellationReason.Error:
                print(f"Error details: {cancellation_details.error_details}")
            return None
            
    except Exception as e:
        print(f"Azure TTS error: {e}")
        return None
        
        
def text_to_speech(text: str, language: str = "Korean", restaurant_name: str = "", provider: str = "Google") -> str:
    """
    Convert text to speech using selected provider.

    Args:
        text: Script text to convert
        language: "Korean" or "English"
        restaurant_name: Used for naming the audio file
        provider: "Google" or "Azure"

    Returns:
        Path to generated audio file
    """
    if provider == "Azure":
        return text_to_speech_azure(text, language, restaurant_name)
    
    # Default to Google (existing logic)
    # Fail fast if credentials are missing via env var check logic (kept from original)
    credentials_path = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS")


# ============================================================================
# Video Merger Functions
# ============================================================================

def get_video_files() -> List[str]:
    """Get list of video files from videos directory."""
    if not VIDEOS_DIR.exists():
        return []

    video_files = []
    for ext in ['*.mp4', '*.MP4']:
        video_files.extend(VIDEOS_DIR.glob(ext))

    # Sort by name
    video_files = sorted(list(set([str(f) for f in video_files])))
    return video_files


def get_bgm_files() -> List[str]:
    """Get list of background music files from background music directory."""
    if not BGM_DIR.exists():
        BGM_DIR.mkdir(parents=True, exist_ok=True)
        return []

    bgm_files = []
    for ext in ['*.mp3', '*.MP3', '*.wav', '*.WAV', '*.m4a', '*.M4A']:
        bgm_files.extend(BGM_DIR.glob(ext))

    # Sort by name and return filenames only
    bgm_files = sorted(list(set([f.name for f in bgm_files])))
    return bgm_files


def save_video_selection(selected_videos: List[str]):
    """Save last video selection."""
    try:
        with open(LAST_SELECTION_FILE, 'w', encoding='utf-8') as f:
            json.dump({"selected_videos": selected_videos}, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"Failed to save video selection: {e}")


def load_video_selection() -> List[str]:
    """Load last video selection."""
    if not LAST_SELECTION_FILE.exists():
        return []

    try:
        with open(LAST_SELECTION_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return data.get("selected_videos", [])
    except Exception as e:
        print(f"Failed to load video selection: {e}")
        return []


def concat_videos(video_paths: List[str], output_path: str, clip_duration: int = 3) -> bool:
    """
    Concatenate multiple videos using ffmpeg, taking only first N seconds of each.

    Args:
        video_paths: List of video file paths
        output_path: Output file path
        clip_duration: Duration in seconds to take from each video (default: 3)

    Returns:
        True if successful, False otherwise
    """
    if not video_paths:
        return False

    # Create temporary directory for clipped videos
    temp_dir = tempfile.mkdtemp()
    clipped_videos = []
    concat_file = None

    try:
        # Clip each video to specified duration
        for i, video_path in enumerate(video_paths):
            clipped_path = os.path.join(temp_dir, f"clip_{i}.mp4")

            # Use ffmpeg to extract first N seconds (remove audio)
            cmd = [
                'ffmpeg',
                '-i', video_path,
                '-t', str(clip_duration),  # Duration
                '-c:v', 'libx264',         # Re-encode video (ensures accurate cutting)
                '-an',                     # Remove audio
                '-y',
                clipped_path
            ]

            result = subprocess.run(cmd, capture_output=True, text=True)

            if result.returncode != 0:
                print(f"FFmpeg clip error for {video_path}: {result.stderr}")
                continue

            clipped_videos.append(clipped_path)

        if not clipped_videos:
            return False

        # Create concat file list
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
            for clipped_path in clipped_videos:
                f.write(f"file '{clipped_path}'\n")
            concat_file = f.name

        # Concatenate clipped videos
        cmd = [
            'ffmpeg',
            '-f', 'concat',
            '-safe', '0',
            '-i', concat_file,
            '-c', 'copy',
            '-y',
            output_path
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode != 0:
            print(f"FFmpeg concat error: {result.stderr}")
            return False

        return True

    finally:
        # Cleanup temporary files
        if concat_file and os.path.exists(concat_file):
            os.unlink(concat_file)

        # Remove temporary directory and clipped videos
        for clipped_path in clipped_videos:
            if os.path.exists(clipped_path):
                os.unlink(clipped_path)

        if os.path.exists(temp_dir):
            os.rmdir(temp_dir)


def get_audio_duration(audio_path: str) -> float:
    """Get audio duration in seconds using ffprobe."""
    try:
        cmd = [
            'ffprobe',
            '-v', 'error',
            '-show_entries', 'format=duration',
            '-of', 'default=noprint_wrappers=1:nokey=1',
            audio_path
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode != 0:
            print(f"FFprobe error: {result.stderr}")
            return 0.0

        return float(result.stdout.strip())

    except Exception as e:
        print(f"Error getting audio duration: {e}")
        return 0.0


def get_tts_audio_files() -> List[str]:
    """List saved TTS audio files in the audio directory (sorted by modified time, newest first)."""
    if not TTS_AUDIO_DIR.exists():
        return []
    audio_files = []
    for ext in ['*.mp3', '*.MP3', '*.wav', '*.WAV', '*.m4a', '*.M4A', '*.aac', '*.AAC']:
        audio_files.extend(TTS_AUDIO_DIR.glob(ext))
    # Deduplicate using set (handles case-insensitive file systems returning duplicates for *.ext and *.EXT)
    unique_files = list(set(audio_files))
    audio_files = sorted(unique_files, key=lambda p: p.stat().st_mtime, reverse=True)
    return [p.name for p in audio_files]


def mix_audio_with_bgm(tts_audio_path: str, bgm_path: str, output_path: str, bgm_volume: float = 0.2) -> bool:
    """Mix TTS audio with background music using ffmpeg."""
    try:
        # Mix TTS (full volume) with BGM (reduced volume)
        cmd = [
            'ffmpeg',
            '-i', tts_audio_path,
            '-i', bgm_path,
            '-filter_complex', f'[1:a]volume={bgm_volume}[bg];[0:a][bg]amix=inputs=2:duration=first',
            '-c:a', 'aac',
            '-y',
            output_path
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode != 0:
            print(f"FFmpeg audio mix error: {result.stderr}")
            return False

        return True

    except Exception as e:
        print(f"Error mixing audio with BGM: {e}")
        return False


def merge_video_audio(video_path: str, audio_path: str, output_path: str) -> bool:
    """Merge video with audio using ffmpeg."""
    try:
        cmd = [
            'ffmpeg',
            '-i', video_path,
            '-i', audio_path,
            '-c:v', 'copy',
            '-c:a', 'aac',
            '-map', '0:v:0',
            '-map', '1:a:0',
            '-shortest',
            '-y',
            output_path
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode != 0:
            print(f"FFmpeg merge error: {result.stderr}")
            return False

        return True

    except Exception as e:
        print(f"Error merging video and audio: {e}")
        return False


def create_shorts(
    selected_videos: List[str],
    audio_files: List[str],
    video_order: str,
    bgm_file: str = None
) -> Tuple[str, List[str]]:
    """Create shorts by merging selected videos with audio files and optional background music."""
    if not selected_videos:
        return "âŒ ë¹„ë””ì˜¤ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš” / Please select videos", []

    if not audio_files:
        return "âŒ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš” / Please upload audio files", []

    # Parse video order
    try:
        if video_order.strip():
            order_indices = [int(x.strip()) for x in video_order.split(',')]
            if len(order_indices) != len(selected_videos):
                return f"âŒ ìˆœì„œ ê°œìˆ˜({len(order_indices)})ì™€ ì„ íƒëœ ë¹„ë””ì˜¤ ê°œìˆ˜({len(selected_videos)})ê°€ ë‹¤ë¦…ë‹ˆë‹¤", []
            ordered_videos = [selected_videos[i] for i in order_indices]
        else:
            ordered_videos = selected_videos
    except (ValueError, IndexError) as e:
        return f"âŒ ìˆœì„œ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤: {e}", []

    # Convert filenames to full paths
    video_paths = []
    for video_name in ordered_videos:
        video_path = VIDEOS_DIR / video_name
        if not video_path.exists():
            return f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_name}", []
        video_paths.append(str(video_path))

    status_msg = ""
    output_videos = []

    # Process each audio file separately
    for i, audio_file in enumerate(audio_files, 1):
        status_msg += f"\nğŸ”Š ì‡¼ì¸  {i} ìƒì„± ì¤‘ (ì˜¤ë””ì˜¤: {Path(audio_file).name})...\n"

        # Get audio duration
        audio_duration = get_audio_duration(audio_file)
        if audio_duration <= 0:
            status_msg += f"âŒ ì˜¤ë””ì˜¤ ê¸¸ì´ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\n"
            continue

        status_msg += f"â±ï¸ ì˜¤ë””ì˜¤ ê¸¸ì´: {audio_duration:.1f}ì´ˆ\n"

        # Calculate clip duration per video
        clip_duration = audio_duration / len(video_paths)
        status_msg += f"ğŸ¬ {len(video_paths)}ê°œ ë¹„ë””ì˜¤ ì—°ê²° ì¤‘ (ê° {clip_duration:.1f}ì´ˆ)...\n"

        # Concatenate videos with calculated duration
        concat_video_path = OUTPUT_DIR / f"temp_concatenated_{i}.mp4"

        if not concat_videos(video_paths, str(concat_video_path), int(clip_duration) + 1):
            status_msg += "âŒ ë¹„ë””ì˜¤ ì—°ê²° ì‹¤íŒ¨\n"
            continue

        status_msg += "âœ… ë¹„ë””ì˜¤ ì—°ê²° ì™„ë£Œ\n"

        # Prepare audio (mix with BGM if provided)
        final_audio_path = audio_file
        temp_mixed_audio = None

        if bgm_file and bgm_file != "ì—†ìŒ / None":
            bgm_path = BGM_DIR / bgm_file
            if bgm_path.exists():
                status_msg += f"ğŸµ ë°°ê²½ìŒì•… ë¯¹ì‹± ì¤‘: {bgm_file}\n"
                temp_mixed_audio = OUTPUT_DIR / f"temp_mixed_audio_{i}.aac"
                if mix_audio_with_bgm(audio_file, str(bgm_path), str(temp_mixed_audio)):
                    final_audio_path = str(temp_mixed_audio)
                    status_msg += "âœ… ì˜¤ë””ì˜¤ ë¯¹ì‹± ì™„ë£Œ\n"
                else:
                    status_msg += "âš ï¸ ì˜¤ë””ì˜¤ ë¯¹ì‹± ì‹¤íŒ¨, TTSë§Œ ì‚¬ìš©\n"

        # Merge with audio
        output_name = f"shorts_{i}.mp4"
        output_path = OUTPUT_DIR / output_name

        if merge_video_audio(str(concat_video_path), final_audio_path, str(output_path)):
            status_msg += f"âœ… ì‡¼ì¸  {i} ì™„ë£Œ: {output_path}\n"
            output_videos.append(str(output_path))
        else:
            status_msg += f"âŒ ì‡¼ì¸  {i} ìƒì„± ì‹¤íŒ¨\n"

        # Clean up temp files
        if concat_video_path.exists():
            concat_video_path.unlink()
        if temp_mixed_audio and temp_mixed_audio.exists():
            temp_mixed_audio.unlink()

    # Save selection
    save_video_selection(selected_videos)

    status_msg += f"\nğŸ‰ ì´ {len(output_videos)}ê°œ ì‡¼ì¸  ìƒì„± ì™„ë£Œ!"

    return status_msg, output_videos


# ==================== Video Generation Pipeline ====================

def get_input_images() -> List[str]:
    """Get list of images from input directory."""
    if not INPUT_DIR.exists():
        INPUT_DIR.mkdir(parents=True, exist_ok=True)
        return []

    image_files = []
    for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:
        image_files.extend(INPUT_DIR.glob(ext))

    return sorted(list(set([str(f) for f in image_files])))


class BytePlusVideoClient:
    """Client for BytePlus ModelArk Video API with parallel processing using direct REST API."""

    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://ark.ap-southeast.bytepluses.com/api/v3"
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

    def _pil_to_base64_data_url(self, pil_img: PILImage.Image, format: str = "PNG") -> str:
        """Convert PIL Image to base64 data URL."""
        buffer = io.BytesIO()
        pil_img.save(buffer, format=format)
        buffer.seek(0)
        b64_str = base64.b64encode(buffer.read()).decode("utf-8")
        return f"data:image/{format.lower()};base64,{b64_str}"

    def create_task(self, image: PILImage.Image, prompt: str, model: str = "seedance-1-0-lite-i2v-250428", duration: int = 2) -> str:
        """Create video generation task using REST API."""
        image_data = self._pil_to_base64_data_url(image)

        payload = {
            "model": model,
            "content": [
                {"type": "text", "text": f"{prompt} --ratio 9:16 --dur {duration}"},
                {"type": "image_url", "image_url": {"url": image_data}}
            ]
        }

        try:
            logger.info(f"Creating video task. Model: {model}")
            response = requests.post(
                f"{self.base_url}/contents/generations/tasks",
                headers=self.headers,
                json=payload,
                timeout=60
            )
            response.raise_for_status()
            task_id = response.json()["id"]
            logger.info(f"Task created successfully. ID: {task_id}")
            return task_id
        except Exception as e:
            # Try to get more error info
            error_msg = str(e)
            if hasattr(e, 'response') and e.response:
                try:
                    error_msg += f" Response: {e.response.text}"
                except:
                    pass
            logger.error(f"Video generation task creation failed: {error_msg}")
            raise RuntimeError(f"Video generation task creation failed: {error_msg}")

    def poll_task(self, task_id: str, max_wait: int = 600, poll_interval: int = 10) -> bytes:
        """Poll task until completion and return video bytes using REST API."""
        start_time = time.time()
        logger.info(f"Polling task {task_id}...")

        while time.time() - start_time < max_wait:
            try:
                response = requests.get(
                    f"{self.base_url}/contents/generations/tasks/{task_id}",
                    headers=self.headers,
                    timeout=30
                )
                response.raise_for_status()
                task = response.json()
                
                status = task.get("status")
                logger.debug(f"Task {task_id} status: {status}")

                if status == "succeeded":
                    logger.info(f"Task {task_id} succeeded.")
                    # Extract video URL from task result
                    content = task.get("content")
                    if content:
                        video_url = None
                        # Content is usually a list of dicts in the JSON response
                        items = content if isinstance(content, list) else [content]
                        
                        for item in items:
                            video_url = item.get("video_url") or item.get("url")
                            if video_url:
                                break
                        
                        if not video_url:
                            logger.error(f"No video URL found in task content: {content}")
                            raise ValueError(f"No video URL found in task content: {content}")
                        
                        logger.info(f"Downloading video from: {video_url}")
                        video_response = requests.get(video_url, timeout=60)
                        video_response.raise_for_status()
                        logger.info(f"Video downloaded ({len(video_response.content)} bytes)")
                        return video_response.content
                    else:
                        logger.error(f"Task succeeded but no content found: {task}")
                        raise ValueError(f"Task succeeded but no content found: {task}")

                elif status == "failed":
                    error = task.get("error", {})
                    error_msg = error.get("message", "Unknown error") if isinstance(error, dict) else str(error)
                    logger.error(f"Task {task_id} failed: {error_msg}")
                    raise RuntimeError(f"Task {task_id} failed: {error_msg}")

                time.sleep(poll_interval)
            
            except Exception as e:
                # If it's the last attempt or a fatal error, re-raise
                if time.time() - start_time >= max_wait:
                     logger.error(f"Polling failed fatally: {e}")
                     raise RuntimeError(f"Polling failed: {e}")
                # Otherwise verify if we should continue polling
                logger.warning(f"Poll request failed ({e}), retrying...")
                print(f"Warning: Poll request failed ({e}), retrying...")
                time.sleep(poll_interval)

        raise TimeoutError(f"Task {task_id} did not complete within {max_wait}s")


def run_image_processing(selected_images: List[str], progress=gr.Progress()) -> Tuple[str, List[str]]:
    """Process selected images (3:4 outpainting + people removal)."""
    if not selected_images:
        return "âŒ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”", []

    progress(0, desc="ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘...")

    # Import and run nano_banana script functions
    try:
        import sys
        sys.path.insert(0, str(Path(__file__).parent))
        from nano_banana_byteplus_sdk import process_images

        processed = []
        status_msg = f"ğŸ–¼ï¸ {len(selected_images)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘...\n\n"

        for i, img_path in enumerate(selected_images):
            progress((i + 1) / len(selected_images), desc=f"ì²˜ë¦¬ ì¤‘ {i+1}/{len(selected_images)}")
            img_name = Path(img_path).name
            status_msg += f"[{i+1}/{len(selected_images)}] {img_name}...\n"

            # Process image using nano_banana functions
            # This will be implemented by calling the actual processing logic
            processed.append(img_path)

        status_msg += "\nâœ… ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ!"
        return status_msg, processed

    except Exception as e:
        return f"âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}", []


# Global stop flag
_stop_video_generation = False

def generate_videos_parallel(image_paths: List[str], model_id: str = "seedance-1-0-lite-i2v-250428", progress=gr.Progress()) -> str:
    """Generate videos from processed images in parallel (creation + polling)."""
    global _stop_video_generation
    _stop_video_generation = False  # Reset flag

    if not image_paths:
        return "âŒ ì²˜ë¦¬ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤"

    api_key = os.environ.get("ARK_API_KEY")
    if not api_key:
        return "âŒ ARK_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"

    client = BytePlusVideoClient(api_key)
    VIDEOS_DIR.mkdir(parents=True, exist_ok=True)

    progress(0, desc="ë¹„ë””ì˜¤ ìƒì„± ì¤€ë¹„ ì¤‘...")

    # Video types and prompts
    video_types = [
        ("diagonal_zoom_out", "Camera descends from above with zoom-out effect, dish remains completely static. Use the provided image strictly as the final frame."),
        ("rotate", "Camera rotates 10-15 degrees around the dish, dish must remain completely static. Use the provided image as the final frame."),
        ("zoom", "Camera zooms from 1.0x to 1.2x toward center, dish stays static. Use the provided image as the final frame."),
        ("pan_down", "Camera pans from top to bottom, dish remains static. Use the provided image as the final frame."),
        ("diagonal", "Camera moves diagonally from bottom-left to top-right, dish stays static. Use the provided image as the final frame."),
    ]

    total_tasks = len(image_paths) * len(video_types)
    status_msg = f"ğŸ¬ {len(image_paths)}ê°œ ì´ë¯¸ì§€ì—ì„œ ê° 5ê°œ ë¹„ë””ì˜¤ ìƒì„± ì¤‘ (ì´ {total_tasks}ê°œ)... ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘\n\n"

    def process_single_video(img_path, vid_type, prompt):
        img_name = Path(img_path).stem
        if _stop_video_generation:
            return f"âš ï¸ {img_name}_{vid_type}: ì¤‘ì§€ë¨ (ì‹œì‘ ì „)"
        
        try:
            # 1. Load Image
            img = PILImage.open(img_path).convert("RGB")
            
            # 2. Create Task
            logger.info(f"Starting {img_name}_{vid_type}")
            try:
                task_id = client.create_task(img, prompt, model=model_id, duration=2)
            except Exception as e:
                 return f"âŒ {img_name}_{vid_type} ìƒì„± ìš”ì²­ ì‹¤íŒ¨: {e}"

            if _stop_video_generation:
                return f"âš ï¸ {img_name}_{vid_type}: ì¤‘ì§€ë¨ (ìš”ì²­ í›„)"

            # 3. Poll Task
            video_bytes = client.poll_task(task_id)
            
            if _stop_video_generation:
                return f"âš ï¸ {img_name}_{vid_type}: ì¤‘ì§€ë¨ (ì™„ë£Œ í›„ ì €ì¥ ì•ˆí•¨)"

            # 4. Save Video
            output_path = VIDEOS_DIR / f"{img_name}_{vid_type}.mp4"
            with open(output_path, "wb") as f:
                f.write(video_bytes)
            
            return f"âœ… {img_name}_{vid_type}.mp4"

        except Exception as e:
            logger.error(f"Failed {img_name}_{vid_type}: {e}")
            return f"âŒ {img_name}_{vid_type}: {e}"

    # Submit all tasks
    completed = 0
    with ThreadPoolExecutor(max_workers=10) as executor:
        # Create futures
        futures = []
        for img_path in image_paths:
            for vid_type, prompt in video_types:
                futures.append(executor.submit(process_single_video, img_path, vid_type, prompt))
        
        progress(0.1, desc=f"ëª¨ë“  ì‘ì—… ìš”ì²­ ì‹œì‘... (0/{total_tasks})")

        # Process as they complete
        for future in as_completed(futures):
            if _stop_video_generation:
                status_msg += "\nâš ï¸ ì‚¬ìš©ìê°€ ì¤‘ì§€í–ˆìŠµë‹ˆë‹¤.\n"
                executor.shutdown(wait=False, cancel_futures=True)
                break

            result = future.result()
            status_msg += f"{result}\n"
            completed += 1
            progress(0.1 + 0.9 * completed / total_tasks, desc=f"ì™„ë£Œë¨: {completed}/{total_tasks}")

    if _stop_video_generation:
        status_msg += f"\nâš ï¸ ì¤‘ì§€ë¨! (ì™„ë£Œ: {completed}/{total_tasks}ê°œ)"
    else:
        status_msg += f"\nğŸ‰ ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ! (ì´ {completed}ê°œ)"

    return status_msg


def stop_video_generation() -> str:
    """Stop the video generation process."""
    global _stop_video_generation
    _stop_video_generation = True
    return "â¹ï¸ ì¤‘ì§€ ì‹ í˜¸ë¥¼ ë³´ëƒˆìŠµë‹ˆë‹¤. í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ì‘ì—…ì´ ì™„ë£Œë˜ë©´ ë©ˆì¶¥ë‹ˆë‹¤..."


class YouTubeShortsScriptGenerator:
    """YouTube Shorts script generator using Google Gemini."""

    def __init__(self, api_key: str, generation_timeout: int = GENERATION_TIMEOUT):
        """Initialize Gemini API client."""
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-2.5-flash')
        self.generation_timeout = generation_timeout

    def generate_script(
        self,
        restaurant_name: str,
        description: str,
        style: str,
        language: str,
        intro_style: str = "ì§ì„¤ì  ì†Œê°œí˜•",
        outro_style: str = "ì¶”ì²œí˜•",
        location: str = "",
        location_in: str = "intro",
        include_restaurant_name: bool = True,
        return_prompt: bool = False
    ):
        """
        Generate YouTube Shorts script.

        Args:
            restaurant_name: Name of the restaurant
            description: Combined description, strengths, and reviews
            style: Script style (e.g., "Review", "Promotional")
            language: "Korean" or "English"
            intro_style: Intro style (default: "ì§ì„¤ì  ì†Œê°œí˜•")
            outro_style: Outro style (default: "ì¶”ì²œí˜•")
            location: Restaurant location (default: "")
            location_in: Where to include location - "intro" or "outro" (default: "intro")

        Returns:
            Generated script text (or tuple of text and prompt when return_prompt=True)
        """
        # Build prompt based on language
        if language == "Korean":
            prompt = self._build_korean_prompt(restaurant_name, description, style, intro_style, outro_style, location, location_in, include_restaurant_name)
        else:
            prompt = self._build_english_prompt(restaurant_name, description, style, intro_style, outro_style, location, location_in, include_restaurant_name)

        # Generate script using Gemini with timeout to prevent infinite hangs
        try:
            response = self.model.generate_content(
                prompt,
                request_options={"timeout": self.generation_timeout}
            )
            if return_prompt:
                return response.text, prompt
            return response.text
        except Exception as e:
            raise RuntimeError(f"Gemini ìš”ì²­ ì‹¤íŒ¨: {e}") from e

    def _build_korean_prompt(self, restaurant_name: str, description: str, style: str, intro_style: str, outro_style: str, location: str = "", location_in: str = "intro", include_restaurant_name: bool = True) -> str:
        """Build Korean prompt for Gemini."""
        # Get intro/outro descriptions
        intro_desc = INTRO_STYLES.get(intro_style, {}).get("description", "")
        outro_desc = OUTRO_STYLES.get(outro_style, {}).get("description", "")

        # Build location instruction
        location_instruction = ""
        if location:
            if location_in == "intro":
                location_instruction = f"""
**ë§¤ì¥ ìœ„ì¹˜ ì •ë³´ (í•„ìˆ˜):**
- ìœ„ì¹˜: {location}
- **ì¤‘ìš”**: ì¸íŠ¸ë¡œì—ì„œ ë°˜ë“œì‹œ ìœ„ì¹˜ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•´ì•¼ í•©ë‹ˆë‹¤.
- ì˜ˆì‹œ: "ì˜¤ëŠ˜ì€ {location}ì— ìˆëŠ” {restaurant_name if include_restaurant_name else 'ì´ê³³'}ì— ë‹¤ë…€ì™”ëŠ”ë°ìš”..", "{location}ì—ì„œ ì°¾ì€ ìˆ¨ì€ ë§›ì§‘..", "ì´ë²ˆì— {location}ì— ê°”ë‹¤ê°€ ë°œê²¬í•œ.."
- ì¸íŠ¸ë¡œ ìŠ¤íƒ€ì¼({intro_style})ì— ë§ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ìœ„ì¹˜ ì •ë³´ë¥¼ ë…¹ì—¬ë‚´ì„¸ìš”. íŠ¹ë³„íˆ '{intro_style}'ì¸ ê²½ìš° ìœ„ì¹˜ì™€ ê°€ê²Œ ì´ë¦„ì„ ì¸íŠ¸ë¡œ ì²« ë¬¸ì¥ì— ë°”ë¡œ ì–¸ê¸‰í•˜ì„¸ìš”."""
            else:  # outro
                location_instruction = f"""
**ë§¤ì¥ ìœ„ì¹˜ ì •ë³´ (í•„ìˆ˜):**
- ìœ„ì¹˜: {location}
- **ì¤‘ìš”**: ì•„ì›ƒíŠ¸ë¡œì—ì„œ ë°˜ë“œì‹œ ìœ„ì¹˜ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•´ì•¼ í•©ë‹ˆë‹¤.
- ì˜ˆì‹œ: "{location}ì— 40ë…„ ì „í†µì„ ì´ì–´ê°€ëŠ” ì´ê³³ì€?", "{location}ì—ì„œ ê¼­ ê°€ë´ì•¼ í•  ë§›ì§‘ì€?", "{location} ë§›ì§‘ ì°¾ëŠ”ë‹¤ë©´ ë°”ë¡œ ì—¬ê¸°"
- ì•„ì›ƒíŠ¸ë¡œ ìŠ¤íƒ€ì¼({outro_style})ì— ë§ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ìœ„ì¹˜ ì •ë³´ë¥¼ ë…¹ì—¬ë‚´ì„¸ìš”."""

        return f"""ë‹¹ì‹ ì€ ìœ íŠœë¸Œ ì‡¼ì¸  ì „ë¬¸ ëŒ€ë³¸ ì‘ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜ìƒ ì œëª©ê³¼ 35-50ì´ˆ ë¶„ëŸ‰ì˜ ì‡¼ì¸  ëŒ€ë³¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ì‹ë‹¹ ì •ë³´:**
- ê°€ê²Œ ì´ë¦„: {restaurant_name if include_restaurant_name else "ë¹„ê³µê°œ (ëŒ€ë³¸/ì œëª©ì— ì–¸ê¸‰ ê¸ˆì§€)"}
- ì‹ë‹¹ ìƒì„¸ ì„¤ëª… (ì¥ì , ë¦¬ë·° ë“± í¬í•¨ ê°€ëŠ¥): 
{description}
{location_instruction}

**ëŒ€ë³¸ ìŠ¤íƒ€ì¼:** {style}

**ì¸íŠ¸ë¡œ ìŠ¤íƒ€ì¼:** {intro_style}
- {intro_desc}

**ì•„ì›ƒíŠ¸ë¡œ ìŠ¤íƒ€ì¼:** {outro_style}
- {outro_desc}

**ì‘ì„± ê°€ì´ë“œë¼ì¸:**

1. ì œëª© ì‘ì„±:
   - í´ë¦­ì„ ìœ ë„í•˜ëŠ” ì„íŒ©íŠ¸ ìˆëŠ” ì œëª©
   - 20-30ì ë‚´ì™¸
   - í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” í‘œí˜„ ì‚¬ìš©
   - ì˜ˆ: "íƒì‹œê¸°ì‚¬ë‹˜ë“¤ë„ ì¸ì •í•˜ëŠ” ê³ ì–‘ ëˆê¹ŒìŠ¤ ì°ë§›ì§‘"

2. ëŒ€ë³¸ ë¶„ëŸ‰: 35-50ì´ˆì— ë§ê²Œ ì‘ì„± (ì•½ 150-170ì ë‚´ì™¸, ê³µë°± ì œì™¸)
   - êµ¬ì²´ì ì¸ ë””í…Œì¼ì„ í¬í•¨í•˜ë˜ ì¥í™©í•˜ì§€ ì•Šê²Œ
   - í•µì‹¬ ê²½í—˜ì„ ìƒë™ê° ìˆê²Œ ì „ë‹¬

3. ë§íˆ¬: ìì—°ìŠ¤ëŸ¬ìš´ ì¼ìƒ ëŒ€í™”ì²´ êµ¬ì–´ì²´
   - "~í–ˆëŠ”ë°", "~í•˜ë”ë¼ê³ ìš”", "~ìŠµë‹ˆë‹¤", "~ê¸¸ë˜", "~ì¸ì§€", "~í•˜ë©´ê°€" ê°™ì€ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ ì‚¬ìš©
   - ì‹¤ì œ ì‚¬ëŒì´ ë§í•˜ë“¯ì´ í¸ì•ˆí•˜ê³  ì¹œê·¼í•œ í†¤

4. ë‚´ìš©: ì„¸ë¶€ì ì´ê³  êµ¬ì²´ì ì¸ ê²½í—˜ ë¬˜ì‚¬
   - ë‹¨ìˆœ ë‚˜ì—´ì´ ì•„ë‹Œ ë””í…Œì¼í•œ ì„¤ëª…
   - ì‹¤ì œ ë°©ë¬¸ ê²½í—˜ì²˜ëŸ¼ ìƒë™ê° ìˆê²Œ
   - êµ¬ì²´ì ì¸ í¬ê¸°, ë§›, ëŠë‚Œ ë“± ë””í…Œì¼ í¬í•¨

5. {style} ìŠ¤íƒ€ì¼ì— ë§ê²Œ ì‘ì„±

6. ëŒ€ë³¸ êµ¬ì¡°:
   - **ì¸íŠ¸ë¡œ**: {intro_style} ìŠ¤íƒ€ì¼ë¡œ ì‹œì‘í•˜ì—¬ ì‹œì²­ìì˜ ì£¼ì˜ë¥¼ ëŒê¸°
   - **ë³¸ë¬¸**: í•µì‹¬ ê²½í—˜ê³¼ ì¥ì ì„ êµ¬ì²´ì ìœ¼ë¡œ ì „ë‹¬
   - **ì•„ì›ƒíŠ¸ë¡œ**: {outro_style} ìŠ¤íƒ€ì¼ë¡œ ë§ˆë¬´ë¦¬í•˜ì—¬ ê°•í•œ ì¸ìƒ ë‚¨ê¸°ê¸°

7. ì˜ìƒê³¼ í•¨ê»˜ ë‚˜ë ˆì´ì…˜ë  ê²ƒì„ ê³ ë ¤

8. ì´ëª¨ì§€ë‚˜ íŠ¹ìˆ˜ë¬¸ì ì‚¬ìš©í•˜ì§€ ì•Šê¸°

{"9. ê°€ê²Œ ì´ë¦„ì„ ì œëª©/ëŒ€ë³¸ ì¤‘ í•œ ê³³ì— ì •í™•íˆ 1ë²ˆë§Œ ìì—°ìŠ¤ëŸ½ê²Œ ë„£ì„ ê²ƒ (ì œëª©ì— ì“°ë©´ ëŒ€ë³¸ì—ì„œëŠ” ì“°ì§€ ë§ê³ , ì œëª©ì— ì•ˆ ì“°ë©´ ëŒ€ë³¸ì—ì„œ 1ë²ˆ ì–¸ê¸‰)" if include_restaurant_name else "9. ê°€ê²Œ ì´ë¦„ì„ ì œëª©/ëŒ€ë³¸ì— ì§ì ‘ ì–¸ê¸‰í•˜ì§€ ë§ ê²ƒ"}

**ì˜ˆì‹œ ë§íˆ¬ (161ì):**
"ê³ ì–‘ì‹œ íƒì‹œ ê¸°ì‚¬ë‹˜ë“¤ì´ 1ë“±ìœ¼ë¡œ ë½‘ëŠ”ë‹¤ëŠ” ëˆê°€ìŠ¤ ë§›ì§‘ì…ë‹ˆë‹¤. ì‚¬ì´ì¦ˆê°€ ì‚¬ëŒ ì–¼êµ´ë³´ë‹¤ í›¨ì”¬ í¬ê¸¸ë˜ ë‘ê»˜ëŠ” ì–‡ê²Œ ì°Œí–ˆëŠ”ë° ë‘ê»˜ë„ ì ë‹¹íˆ ë‘ê»ê³  ê¸°ë¦„ë„ ì¢‹ì€ ê±° ì“°ëŠ”ì§€ ê¸°ë¦„ ëƒ„ìƒˆ 1ì¼ë„ ì•ˆ ë‚˜ê³  ê¹”ë”í•˜ê²Œ ë°”ì‚­í•˜ê³  ë§›ìˆìŠµë‹ˆë‹¤. ìˆ˜ì œ ì†ŒìŠ¤ë„ í›Œë¥­í•˜ê³  ì…€í”„ë°”ì—ì„œ ë°¥ì´ë‘ ìŠ¤í”„ ë°˜ì°¬ë“¤ê¹Œì§€ ì „ë¶€ ë¬´í•œì¸ ê²ƒë„ ì¢‹ë”ë¼ê³ ìš”."

**ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ ì´ í˜•ì‹ì„ ë”°ë¼ì£¼ì„¸ìš”):**
ì œëª©: [ì—¬ê¸°ì— ì œëª© ì‘ì„±]

ëŒ€ë³¸: [ì—¬ê¸°ì— ëŒ€ë³¸ ì‘ì„±]

**ì„¤ëª…ì´ë‚˜ ì£¼ì„ì€ ë¶ˆí•„ìš”í•©ë‹ˆë‹¤. ìœ„ í˜•ì‹ëŒ€ë¡œë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”.**"""

    def _build_english_prompt(self, restaurant_name: str, description: str, style: str, intro_style: str, outro_style: str, location: str = "", location_in: str = "intro", include_restaurant_name: bool = True) -> str:
        """Build English prompt for Gemini."""
        # Get intro/outro descriptions (use English version)
        intro_desc = INTRO_STYLES.get(intro_style, {}).get("description", "")
        outro_desc = OUTRO_STYLES.get(outro_style, {}).get("description", "")
        intro_eng = INTRO_STYLES.get(intro_style, {}).get("english", intro_style)
        outro_eng = OUTRO_STYLES.get(outro_style, {}).get("english", outro_style)

        # Build location instruction
        location_instruction = ""
        if location:
            if location_in == "intro":
                location_instruction = f"""
**Restaurant Location (REQUIRED):**
- Location: {location}
- **IMPORTANT**: You MUST naturally mention the location in the intro.
- Examples: "Today I visited this amazing restaurant in {location}...", "Found this hidden gem in {location}...", "Went to {location} and discovered..."
- Blend the location naturally into the {intro_eng} style."""
            else:  # outro
                location_instruction = f"""
**Restaurant Location (REQUIRED):**
- Location: {location}
- **IMPORTANT**: You MUST naturally mention the location in the outro.
- Examples: "This 40-year tradition continues in {location}, where is it?", "Must-visit spot in {location}?", "If you're looking for great food in {location}, this is it"
- Blend the location naturally into the {outro_eng} style."""

        return f"""You are a professional YouTube Shorts scriptwriter. Create a video title and 35-50 second script based on the following information.

**Restaurant Information:**
- Restaurant Name: {restaurant_name if include_restaurant_name else "Hidden (DO NOT mention name in title/script)"}
- Restaurant Description (detailed features, strengths, reviews):
{description}
{location_instruction}

**Script Style:** {style}

**Intro Style:** {intro_eng}
- {intro_desc}

**Outro Style:** {outro_eng}
- {outro_desc}

**Writing Guidelines:**

1. Title:
   - Create an attention-grabbing, click-worthy title
   - 10-15 words max
   - Use curiosity-inducing language
   - Example: "Taxi Drivers' #1 Pick: The Best Tonkatsu in Town"

2. Script Duration: 35-50 seconds (approximately 100-130 words)
   - Include specific details but stay focused
   - Deliver the core experience vividly

3. Tone: Natural, conversational, casual speech
   - Use everyday language like "so", "actually", "you know", "I mean"
   - Sound like a real person talking to a friend
   - Relaxed and authentic voice

4. Content: Detailed and specific descriptions
   - Include specific details about size, taste, atmosphere
   - Paint a vivid picture with concrete examples
   - Share personal observations and experiences

5. Match the {style} style

6. Script Structure:
   - **Intro**: Use {intro_eng} style to grab viewer's attention
   - **Body**: Deliver core experience and strengths in detail
   - **Outro**: End with {outro_eng} style for strong impression

7. Consider this will be narrated over video

8. No emojis or special characters

{"9. Include the restaurant name exactly once across title+script (if allowed): if used in the title, do NOT repeat it in the script; if not in the title, mention it once in the script." if include_restaurant_name else "9. Do NOT mention the restaurant name in the title or script."}

**Example tone:**
"This is the tonkatsu place that Goyang taxi drivers voted number one. The portion size was way bigger than I expected - like, seriously huge compared to my face. I thought it would be thin, but it was actually pretty thick and crispy. The oil they use must be really good quality because there's zero greasy smell, and everything tastes so fresh and clean. The homemade sauce is excellent, and the self-service bar with unlimited rice, soup, and side dishes is a great touch."

**Output Format (You must follow this format):**
Title: [Your title here]

Script: [Your script here]

**No explanations or annotations needed. Follow the format above.**"""

    def generate_multiple_scripts(
        self,
        restaurant_name: str,
        description: str,
        styles: List[str],
        language: str,
        intro_style: str = "ì§ì„¤ì  ì†Œê°œí˜•",
        outro_style: str = "ì¶”ì²œí˜•"
    ) -> Dict[str, str]:
        """Generate scripts for multiple styles."""
        scripts = {}
        for style in styles:
            script = self.generate_script(
                restaurant_name, description, style, language,
                intro_style, outro_style
            )
            scripts[style] = script
        return scripts


def create_gradio_interface():
    """Create Gradio UI for script generation and shorts merging."""

    # Initialize API key
    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        raise ValueError("GEMINI_API_KEY environment variable not set. Please add it to .env file")

    generator = YouTubeShortsScriptGenerator(api_key)

    def generate_scripts_ui(
        restaurant_name: str,
        description: str,
        selected_styles: List[str],
        language: str,
        intro_style: str,
        outro_style: str,
        location: str,
        location_in: str,
        include_restaurant_name: bool,
        tts_provider: str = "Google",
        progress=gr.Progress(track_tqdm=True)
    ):
        """Generate scripts based on UI inputs with progress updates."""
        print(f"[DEBUG] UI Request - Provider: {tts_provider}, Language: {language}")

        status_lines = []
        current_output = ""
        audios = [None] * 7
        audio_list_state = []

        def trunc(text: str, length: int = 180) -> str:
            if text is None:
                return ""
            return text if len(text) <= length else text[:length] + "..."

        def push_status(msg: str):
            status_lines.append(msg)
            # Keep last 20 lines to avoid overflow
            return "\n".join(status_lines[-20:])

        def make_return(status_msg, output_text=None, audio_paths=None, audio_state=None):
            nonlocal current_output, audios, audio_list_state
            if output_text is not None:
                current_output = output_text
            if audio_paths is not None:
                audios = (audio_paths + [None] * 7)[:7]
            if audio_state is not None:
                audio_list_state = audio_state
            # Force multiline display by keeping newline-separated log text
            return (status_msg, current_output, *audios, audio_list_state)

        if not restaurant_name or not description:
            return make_return("âŒ í•„ìˆ˜ í•„ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (ê°€ê²Œ ì´ë¦„, ì‹ë‹¹ ì„¤ëª…) / Please fill in required fields (Name, Description)")

        if not selected_styles:
            return make_return("âŒ ìµœì†Œ 1ê°œ ì´ìƒì˜ ìŠ¤íƒ€ì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš” / Please select at least 1 style")

        # Initial status update so UI shows "in progress"
        yield make_return(push_status("ğŸš€ ëŒ€ë³¸ ìƒì„± ì‹œì‘ / Starting script generation..."))

        # Get style keys from selected style names
        style_keys = []
        for style_name in selected_styles:
            for key, value in SCRIPT_STYLES.items():
                if key == style_name:
                    if language == "Korean":
                        style_keys.append(value["korean"])
                    else:
                        style_keys.append(value["english"])
                    break

        # Generate scripts
        try:
            total = len(style_keys)
            scripts = {}
            script_contents = {}  # Store only script content for TTS

            # Generate each script
            for idx, style in enumerate(style_keys, start=1):
                progress(idx / max(total, 1), desc=f"ìƒì„± ì¤‘ {idx}/{total}")
                status_msg = push_status(f"â†’ [{idx}/{total}] Gemini ìš”ì²­ ì¤€ë¹„: ìŠ¤íƒ€ì¼={style}, ì–¸ì–´={language}, ì¸íŠ¸ë¡œ={intro_style}, ì•„ì›ƒíŠ¸ë¡œ={outro_style}, ìœ„ì¹˜={'ìˆìŒ' if location else 'ì—†ìŒ'}")
                yield make_return(status_msg)

                try:
                    script_resp, prompt_text = generator.generate_script(
                        restaurant_name, description, style, language,
                        intro_style, outro_style, location, location_in, include_restaurant_name,
                        return_prompt=True
                    )
                except Exception as e:
                    status_msg = push_status(f"âŒ [{idx}/{total}] Gemini ì˜¤ë¥˜: {e}")
                    yield make_return(status_msg)
                    return make_return(status_msg)

                status_msg = push_status(
                    f"â† [{idx}/{total}] Gemini ì‘ë‹µ ìˆ˜ì‹  (í”„ë¡¬í”„íŠ¸ {len(prompt_text)}ì, ì‘ë‹µ {len(script_resp or '')}ì)"
                )
                yield make_return(status_msg)

                scripts[style] = script_resp

                # Extract script content only (without title)
                script_content = script_resp
                if "ì œëª©:" in script_resp or "Title:" in script_resp:
                    lines = script_resp.strip().split('\n')
                    for j, line in enumerate(lines):
                        if line.startswith("ëŒ€ë³¸:") or line.startswith("Script:"):
                            script_content = '\n'.join(lines[j:]).split(":", 1)[1].strip()
                            break
                script_contents[style] = script_content

            # Save last input on success
            save_last_input(restaurant_name, description, selected_styles, language,
                          intro_style, outro_style, location, location_in, include_restaurant_name)

            status_msg = push_status("ğŸ“¦ ëŒ€ë³¸ í¬ë§·íŒ…...")
            yield make_return(status_msg)

            # Format final output
            output = f"# ìƒì„±ëœ ëŒ€ë³¸ / Generated Scripts\n\n"
            output += f"**ê°€ê²Œ ì´ë¦„ / Restaurant:** {restaurant_name}\n\n"
            output += "---\n\n"

            for i, (style, script) in enumerate(scripts.items(), 1):
                output += f"## ìŠ¤íƒ€ì¼ {i}: {style}\n\n"

                # Parse title and script
                title = ""
                script_content = script

                if "ì œëª©:" in script or "Title:" in script:
                    lines = script.strip().split('\n')
                    for j, line in enumerate(lines):
                        if line.startswith("ì œëª©:") or line.startswith("Title:"):
                            title = line.split(":", 1)[1].strip()
                        elif line.startswith("ëŒ€ë³¸:") or line.startswith("Script:"):
                            script_content = '\n'.join(lines[j:]).split(":", 1)[1].strip()
                            break

                if title:
                    output += f"**ì œëª© / Title:**\n{title}\n\n"
                    output += f"**ëŒ€ë³¸ / Script:**\n{script_content}\n\n"
                else:
                    output += f"{script_resp}\n\n"

                output += "---\n\n"

            # Generate TTS audio for each script (max 7)
            audios = [None] * 7
            audio_list = []  # Store non-None audio paths for merger tab
            for i, (style, script_content) in enumerate(script_contents.items()):
                if i < 7:  # Maximum 7 audio outputs
                    status_msg = push_status(f"ğŸ”Š TTS ìƒì„± ì¤‘ (ìŠ¤íƒ€ì¼ {i+1}/{len(script_contents)}): {style} [{tts_provider}]")
                    yield make_return(status_msg, output, audios, audio_list)

                    audio_path = text_to_speech(script_content, language, restaurant_name, provider=tts_provider)
                    audios[i] = audio_path
                    if audio_path:
                        audio_list.append(audio_path)
                        status_msg = push_status(f"âœ… TTS ì™„ë£Œ: {Path(audio_path).name}")
                    else:
                        status_msg = push_status("âš ï¸ TTS ìƒì„± ì‹¤íŒ¨ (ë¡œê·¸ í™•ì¸)")
                    yield make_return(status_msg, output, audios, audio_list)

            # Save last output for persistence
            save_last_output(output, audios)

            status_msg = push_status(f"âœ… ëŒ€ë³¸ {len(script_contents)}ê°œ ìƒì„± ì™„ë£Œ")
            return make_return(status_msg, output, audios, audio_list)
        except Exception as e:
            status_msg = push_status(f"âŒ ì˜¤ë¥˜ ë°œìƒ / Error occurred: {str(e)}")
            return make_return(status_msg, current_output, audios, audio_list_state)

    # Load last input to prefill form
    last_input = load_last_input()

    # Get video files for merger tab
    video_files = get_video_files()
    video_names = [Path(v).name for v in video_files]
    last_video_selection = load_video_selection()

    # Custom CSS for the UI
    custom_css = """
    .order-display {
        min-width: 70px !important;
        max-width: 70px !important;
        margin-right: 15px !important;
        background: transparent !important;
    }
    .order-display input {
        background-color: #FF4343 !important;
        color: white !important;
        border-radius: 50% !important;
        width: 60px !important;
        height: 60px !important;
        font-size: 32px !important;
        font-weight: 900 !important;
        text-align: center !important;
        border: 3px solid white !important;
        box-shadow: 0 4px 15px rgba(255, 67, 67, 0.4) !important;
        padding: 0 !important;
        cursor: pointer !important;
        transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1) !important;
    }
    .order-display input:focus {
        background-color: #D32F2F !important;
        box-shadow: 0 0 0 4px rgba(255, 67, 67, 0.3) !important;
        transform: scale(1.1);
        outline: none !important;
    }
    .order-display input:hover {
        background-color: #FF5252 !important;
        transform: translateY(-2px);
    }
    .order-display div {
        border: none !important;
        box-shadow: none !important;
        background: transparent !important;
    }
    """

    # Create Gradio interface
    with gr.Blocks(title="YouTube Shorts Creator", css=custom_css) as demo:
        gr.Markdown("""
        # ğŸ¬ ìœ íŠœë¸Œ ì‡¼ì¸  í¬ë¦¬ì—ì´í„° / YouTube Shorts Creator

        ëŒ€ë³¸ ìƒì„±ë¶€í„° ë¹„ë””ì˜¤ ë³‘í•©ê¹Œì§€ í•œ ê³³ì—ì„œ!

        From script generation to video merging - all in one place!
        """)

        # State to store generated audio paths
        generated_audios = gr.State(value=[])
        # State to store selected videos in order
        selection_order_state = gr.State(value=last_video_selection if last_video_selection else [])

        with gr.Tabs():
            # Tab 1: Video Generation
            with gr.Tab("ğŸ¥ ë¹„ë””ì˜¤ ìƒì„± / Video Generation"):
                gr.Markdown("""
                input í´ë”ì˜ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì—¬ ìë™ìœ¼ë¡œ ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

                Select images from input folder to automatically generate videos.
                """)

                # State for input images and ordered selections
                input_images_state = gr.State(value=get_input_images())
                image_selections_state = gr.State(value=[]) # List of selected image paths in order

                def refresh_images():
                    """Re-scan input folder for images."""
                    new_images = get_input_images()
                    print(f"[DEBUG] Refreshing images. Found: {len(new_images)}")
                    return new_images, [] # Clear selections on refresh

                def image_checkbox_change(img_path, is_checked, current_order):
                    """Update ordered selection when a checkbox is toggled."""
                    new_order = list(current_order)
                    if is_checked:
                        if img_path not in new_order:
                            new_order.append(img_path)
                    else:
                        if img_path in new_order:
                            new_order.remove(img_path)
                    return new_order

                def image_order_submit(img_path, new_val, current_order):
                    """Handle manual order number changes with swap logic for images."""
                    if not new_val or not str(new_val).isdigit():
                        return list(current_order)
                    
                    new_pos = int(new_val)
                    new_order = list(current_order)
                    if img_path not in new_order:
                        new_order.append(img_path)
                        
                    old_idx = new_order.index(img_path)
                    new_idx = new_pos - 1
                    
                    if 0 <= new_idx < len(new_order):
                        new_order[old_idx], new_order[new_idx] = new_order[new_idx], new_order[old_idx]
                    
                    return new_order

                with gr.Row():
                    with gr.Column(scale=4):
                        with gr.Row():
                            gr.Markdown(f"### ğŸ“ ì´ë¯¸ì§€ ì„ íƒ / Select Images")
                            refresh_img_btn = gr.Button("ğŸ”„ ìµœì‹ í™” / Refresh", size="sm", variant="secondary")

                        @gr.render(inputs=[input_images_state, image_selections_state])
                        def render_image_gallery(images, current_order):
                            image_names = [Path(img).name for img in images]
                            if len(images) > 0:
                                gr.Markdown(f"*ğŸ“± ì²˜ë¦¬í•  ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš” ({len(images)}ê°œ) / Select images to process*")
                                
                                num_images = len(images)
                                images_per_row = 3
                                
                                for row_start in range(0, num_images, images_per_row):
                                    with gr.Row():
                                        for col in range(images_per_row):
                                            i = row_start + col
                                            if i < num_images:
                                                img_path = images[i]
                                                with gr.Column(scale=1, min_width=200):
                                                    gr.Image(
                                                        value=img_path,
                                                        label=None,
                                                        interactive=False,
                                                        height=280,
                                                        show_label=False
                                                    )
                                                    with gr.Row():
                                                        order_val = str(current_order.index(img_path) + 1) if img_path in current_order else ""
                                                        order_display = gr.Textbox(
                                                            value=order_val,
                                                            label=None,
                                                            container=False,
                                                            elem_classes=["order-display"],
                                                            interactive=True
                                                        )
                                                        checkbox = gr.Checkbox(
                                                            label=f"{image_names[i][:22]}..." if len(image_names[i]) > 22 else f"{image_names[i]}",
                                                            value=img_path in current_order,
                                                            container=False
                                                        )
                                                        
                                                        checkbox.change(
                                                            fn=image_checkbox_change,
                                                            inputs=[gr.State(img_path), checkbox, image_selections_state],
                                                            outputs=[image_selections_state]
                                                        )
                                                        order_display.submit(
                                                            fn=image_order_submit,
                                                            inputs=[gr.State(img_path), order_display, image_selections_state],
                                                            outputs=[image_selections_state]
                                                        )
                                            else:
                                                with gr.Column(scale=1, min_width=200):
                                                    pass
                            else:
                                gr.Markdown("âš ï¸ **input í´ë”ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!** ì´ë¯¸ì§€ë¥¼ ì¶”ê°€í•œ í›„ ìµœì‹ í™” ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.")

                        refresh_img_btn.click(
                            fn=refresh_images,
                            outputs=[input_images_state, image_selections_state]
                        )

                    with gr.Column(scale=1, min_width=250):
                        gr.Markdown("### âš™ï¸ ì„¤ì • / Settings")

                        gr.Markdown("#### ğŸ“‹ íŒŒì´í”„ë¼ì¸ ë‹¨ê³„")
                        gr.Markdown("""
                        1. **ì´ë¯¸ì§€ ì²˜ë¦¬**: 3:4 ë¹„ìœ¨ ë³€í™˜ + ì¸ë¬¼ ì œê±°
                        2. **ë¹„ë””ì˜¤ ìƒì„±**: 5ê°€ì§€ ì¹´ë©”ë¼ ì›€ì§ì„ (ë³‘ë ¬ ì²˜ë¦¬)
                        3. **ì†ë„ ì¡°ì ˆ**: 0.8ë°°ì†ìœ¼ë¡œ ìŠ¬ë¡œìš° ëª¨ì…˜
                        """)

                        gr.Markdown("#### âš™ï¸ íŒŒë¼ë¯¸í„° / Parameters")
                        model_selection = gr.Dropdown(
                            label="ë¹„ë””ì˜¤ ëª¨ë¸ / Video Model",
                            choices=[
                                ("Lite (Fast)", "seedance-1-0-lite-i2v-250428"),
                                ("Pro (High Quality)", "seedance-1-0-pro-250528")
                            ],
                            value="seedance-1-0-lite-i2v-250428",
                            info="LiteëŠ” ë¹ ë¥´ê³  ì €ë ´í•˜ë©°, ProëŠ” ë” ë†’ì€ í’ˆì§ˆì˜ ì˜ìƒì„ ìƒì„±í•©ë‹ˆë‹¤."
                        )

                        generate_pipeline_btn = gr.Button("ğŸš€ ë¹„ë””ì˜¤ ìƒì„± ì‹œì‘ / Start Pipeline", variant="primary", size="lg")
                        stop_pipeline_btn = gr.Button("â¹ï¸ ì¤‘ì§€ / Stop", variant="stop", size="lg")

                        gr.Markdown("---")

                        gr.Markdown("### ğŸ“Š ì§„í–‰ ìƒí™© / Progress")
                        pipeline_status = gr.Textbox(
                            label="ìƒíƒœ / Status",
                            lines=15,
                            interactive=False,
                            placeholder="íŒŒì´í”„ë¼ì¸ì„ ì‹œì‘í•˜ë ¤ë©´ ìœ„ì˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”..."
                        )

                        gr.Markdown("### ğŸ’¡ ì„¤ëª… / Info")
                        gr.Markdown("""
                        **ë¹„ë””ì˜¤ ìœ í˜•** (ê° ì´ë¯¸ì§€ë§ˆë‹¤ 5ê°œ ìƒì„±):
                        1. diagonal_zoom_out - ìœ„ì—ì„œ ì¤Œì•„ì›ƒ
                        2. rotate - íšŒì „ (10-15ë„)
                        3. zoom - ì¤Œ (1.0x â†’ 1.2x)
                        4. pan_down - ìœ„ì—ì„œ ì•„ë˜ë¡œ
                        5. diagonal - ëŒ€ê°ì„  ì´ë™

                        **ë³‘ë ¬ ì²˜ë¦¬**: ëª¨ë“  ë¹„ë””ì˜¤ë¥¼ ë™ì‹œì— ìƒì„±í•˜ì—¬ ì‹œê°„ ë‹¨ì¶•!
                        **ì¶œë ¥ í´ë”**: `videos/`
                        """)

                # Pipeline execution handler
                def run_pipeline_handler(model_id, current_order):
                    """Run the full video generation pipeline."""
                    # Use current_order directly from state
                    if not current_order:
                        return "âŒ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš” / Please select images"

                    # For now, just run video generation (skip image processing step)
                    status = generate_videos_parallel(current_order, model_id=model_id)

                    return status

                generate_pipeline_btn.click(
                    fn=run_pipeline_handler,
                    inputs=[model_selection, image_selections_state],
                    outputs=[pipeline_status]
                )
                stop_pipeline_btn.click(
                    fn=stop_video_generation,
                    inputs=None,
                    outputs=[pipeline_status]
                )

            # Tab 2: Script Generator
            with gr.Tab("ğŸ“ ëŒ€ë³¸ ìƒì„± / Script Generator"):
                gr.Markdown("""
                ì‹ë‹¹ ì •ë³´ë¥¼ ì…ë ¥í•˜ë©´ ì˜ìƒ ì œëª©ê³¼ 35-50ì´ˆ ë¶„ëŸ‰ì˜ ì‡¼ì¸  ëŒ€ë³¸ì„ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.

                Enter restaurant information to generate video title and 35-50 second YouTube Shorts scripts.
                """)

                with gr.Row():
                    with gr.Column():
                        gr.Markdown("### ğŸ“ ì…ë ¥ ì •ë³´ / Input Information")

                        restaurant_name = gr.Textbox(
                            label="ê°€ê²Œ ì´ë¦„ / Restaurant Name",
                            placeholder="ì˜ˆ: í• ë§¤ìˆœëŒ€êµ­ / Example: Grandma's Soondae Soup",
                            lines=1,
                            value=last_input.get("restaurant_name", "")
                        )

                        description = gr.Textbox(
                            label="ì‹ë‹¹ ìƒì„¸ ì„¤ëª… / Restaurant Description",
                            placeholder="ì‹ë‹¹ì— ëŒ€í•œ ëª¨ë“  ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (ì˜ˆ: 40ë…„ ì „í†µì˜ ìˆœëŒ€êµ­ ì „ë¬¸ì . ì§„í•œ êµ­ë¬¼ê³¼ í‘¸ì§í•œ ì–‘ì´ ì¥ì ì´ë©°, 'ì¸ìƒ ìˆœëŒ€êµ­'ì´ë¼ëŠ” ë¦¬ë·°ê°€ ë§ìŒ).",
                            lines=10,
                            value=last_input.get("description", "")
                        )

                        include_restaurant_name = gr.Checkbox(
                            label="ëŒ€ë³¸ì— ê°€ê²Œ ì´ë¦„ í¬í•¨ / Include restaurant name in title & script",
                            value=last_input.get("include_restaurant_name", True)
                        )

                        language = gr.Radio(
                            choices=["Korean", "English"],
                            value=last_input.get("language", "Korean"),
                            label="ì–¸ì–´ / Language"
                        )
                        
                        tts_provider = gr.Radio(
                            choices=["Google", "Azure"],
                            value="Google",
                            label="TTS ì„œë¹„ìŠ¤ / TTS Provider",
                            info="Google: Algenib (ë‚¨) / Azure: Hyunsu (ë‚¨)",
                            interactive=True
                        )

                        style_choices = list(SCRIPT_STYLES.keys())
                        selected_styles = gr.CheckboxGroup(
                            choices=style_choices,
                            value=last_input.get("selected_styles", [style_choices[0], style_choices[1]]),
                            label="ìŠ¤í¬ë¦½íŠ¸ ìŠ¤íƒ€ì¼ ì„ íƒ / Select Script Styles (ìµœì†Œ 1ê°œ / min 1)",
                        )

                        # Intro/Outro style selection
                        gr.Markdown("### ğŸ­ ì¸íŠ¸ë¡œ/ì•„ì›ƒíŠ¸ë¡œ ìŠ¤íƒ€ì¼ / Intro/Outro Styles")

                        intro_choices = list(INTRO_STYLES.keys())
                        intro_style = gr.Dropdown(
                            choices=intro_choices,
                            value=last_input.get("intro_style", "ì§ì„¤ì  ì†Œê°œí˜•"),
                            label="ì¸íŠ¸ë¡œ ìŠ¤íƒ€ì¼ / Intro Style"
                        )

                        outro_choices = list(OUTRO_STYLES.keys())
                        outro_style = gr.Dropdown(
                            choices=outro_choices,
                            value=last_input.get("outro_style", "ì¶”ì²œí˜•"),
                            label="ì•„ì›ƒíŠ¸ë¡œ ìŠ¤íƒ€ì¼ / Outro Style"
                        )

                        # Location settings
                        gr.Markdown("### ğŸ“ ë§¤ì¥ ìœ„ì¹˜ ì •ë³´ / Location Information")
                        gr.Markdown("*ìœ„ì¹˜ ì •ë³´ë¥¼ ì…ë ¥í•˜ë©´ ì¸íŠ¸ë¡œ ë˜ëŠ” ì•„ì›ƒíŠ¸ë¡œì— ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨ë©ë‹ˆë‹¤*")

                        location = gr.Textbox(
                            label="ë§¤ì¥ ìœ„ì¹˜ / Location",
                            placeholder="ì˜ˆ: ì„±ìˆ˜ë™, ê°•ë‚¨ì—­, í™ëŒ€ì…êµ¬ / Example: Seongsu-dong, Gangnam Station",
                            lines=1,
                            value=last_input.get("location", "")
                        )

                        location_in = gr.Radio(
                            choices=["intro", "outro"],
                            value=last_input.get("location_in", "intro"),
                            label="ìœ„ì¹˜ ì •ë³´ í¬í•¨ ìœ„ì¹˜ / Include Location In",
                            info="ì¸íŠ¸ë¡œ: ì˜ìƒ ì‹œì‘ ë¶€ë¶„ / ì•„ì›ƒíŠ¸ë¡œ: ì˜ìƒ ë§ˆë¬´ë¦¬ ë¶€ë¶„"
                        )

                        # Show style descriptions
                        gr.Markdown("### ğŸ“š ìŠ¤íƒ€ì¼ ì„¤ëª… / Style Descriptions")

                        gr.Markdown("**ëŒ€ë³¸ ìŠ¤íƒ€ì¼ / Script Styles:**")
                        for style_name, style_info in SCRIPT_STYLES.items():
                            gr.Markdown(f"- **{style_name}**: {style_info['description']}")

                        gr.Markdown("**ì¸íŠ¸ë¡œ ìŠ¤íƒ€ì¼ / Intro Styles:**")
                        for intro_name, intro_info in INTRO_STYLES.items():
                            gr.Markdown(f"- **{intro_name}**: {intro_info['description']}")

                        gr.Markdown("**ì•„ì›ƒíŠ¸ë¡œ ìŠ¤íƒ€ì¼ / Outro Styles:**")
                        for outro_name, outro_info in OUTRO_STYLES.items():
                            gr.Markdown(f"- **{outro_name}**: {outro_info['description']}")

                        generate_btn = gr.Button("ğŸ¬ ëŒ€ë³¸ ìƒì„± / Generate Scripts", variant="primary", size="lg")

                    with gr.Column():
                        script_status = gr.Textbox(
                            label="ìƒíƒœ / Status",
                            value="ëŒ€ê¸° ì¤‘ / Idle",
                            interactive=False,
                            lines=12
                        )
                        gr.Markdown("### ğŸ“„ ìƒì„±ëœ ëŒ€ë³¸ / Generated Scripts")
                        output = gr.Markdown(label="Output")

                        gr.Markdown("### ğŸ”Š ì˜¤ë””ì˜¤ ë¯¸ë¦¬ë“£ê¸° / Audio Preview")
                        gr.Markdown("*ëŒ€ë³¸ ë‚´ìš©ë§Œ ìŒì„±ìœ¼ë¡œ ë³€í™˜ë©ë‹ˆë‹¤ / Only script content is converted to speech*")
                        # Keep audio players visible so returned filepaths render immediately
                        audio1 = gr.Audio(label="ìŠ¤íƒ€ì¼ 1 / Style 1", type="filepath", visible=True, interactive=False)
                        audio2 = gr.Audio(label="ìŠ¤íƒ€ì¼ 2 / Style 2", type="filepath", visible=True, interactive=False)
                        audio3 = gr.Audio(label="ìŠ¤íƒ€ì¼ 3 / Style 3", type="filepath", visible=True, interactive=False)
                        audio4 = gr.Audio(label="ìŠ¤íƒ€ì¼ 4 / Style 4", type="filepath", visible=True, interactive=False)
                        audio5 = gr.Audio(label="ìŠ¤íƒ€ì¼ 5 / Style 5", type="filepath", visible=True, interactive=False)
                        audio6 = gr.Audio(label="ìŠ¤íƒ€ì¼ 6 / Style 6", type="filepath", visible=True, interactive=False)
                        audio7 = gr.Audio(label="ìŠ¤íƒ€ì¼ 7 / Style 7", type="filepath", visible=True, interactive=False)

                generate_btn.click(
                    fn=generate_scripts_ui,
                    inputs=[
                    restaurant_name, description, selected_styles, language,
                    intro_style, outro_style, location, location_in, include_restaurant_name,
                    tts_provider
                ],
                    outputs=[script_status, output, audio1, audio2, audio3, audio4, audio5, audio6, audio7, generated_audios]
                )

                # Examples
                gr.Markdown("### ğŸ’¡ ì˜ˆì‹œ / Examples")
                gr.Examples(
                    examples=[
                        ["í• ë§¤ìˆœëŒ€êµ­", "40ë…„ ì „í†µì˜ ìˆœëŒ€êµ­ ì „ë¬¸ì . ì§„í•œ êµ­ë¬¼, í‘¸ì§í•œ ì–‘, 24ì‹œê°„ ì˜ì—…. êµ­ë¬¼ì´ ì§„ì§œ ì§„í•˜ê³  ë§›ìˆë‹¤ëŠ” ë¦¬ë·°ê°€ ë§ìŒ.", True, "Korean", ["ë¦¬ë·°í˜• (Review)", "í™ë³´í˜• (Promotional)"]],
                        ["Grandma's Soondae Soup", "40-year traditional Korean soup restaurant. Rich broth, generous portions, 24/7 open. Many customers recommend the pork belly.", True, "English", ["ë¦¬ë·°í˜• (Review)", "íŒ/ì¶”ì²œí˜• (Tips)"]],
                        ["ì´íƒœë¦¬ ì •ì›", "ì •í†µ ì´íƒˆë¦¬ì•ˆ íŒŒìŠ¤íƒ€ì™€ í”¼ì ë ˆìŠ¤í† ë‘. ìˆ˜ì œ íŒŒìŠ¤íƒ€, í™”ë• í”¼ì, ì™€ì¸ í˜ì–´ë§. ë¶„ìœ„ê¸°ê°€ ì¢‹ê³  ë°ì´íŠ¸ ì½”ìŠ¤ë¡œ ìµœê³ ë¼ëŠ” í‰.", True, "Korean", ["ìŠ¤í† ë¦¬í…”ë§í˜• (Storytelling)", "ë¹„êµí˜• (Comparison)"]],
                    ],
                    inputs=[restaurant_name, description, include_restaurant_name, language, selected_styles]
                )

            # Tab 3: Shorts Merger
            with gr.Tab("ğŸ¬ ì‡¼ì¸  ë³‘í•© / Shorts Merger"):
                gr.Markdown("""
                ë¹„ë””ì˜¤ë¥¼ ë¯¸ë¦¬ë³´ë©´ì„œ ì„ íƒí•˜ê³  ì˜¤ë””ì˜¤ì™€ ë³‘í•©í•˜ì—¬ ìµœì¢… ì‡¼ì¸ ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

                Preview and select videos, then merge them with audio files to create final shorts.
                """)

                # Tab 3 State
                video_files_state = gr.State(value=get_video_files())

                def refresh_videos(current_order):
                    """Re-scan videos folder and prune selection."""
                    new_videos = get_video_files()
                    print(f"[DEBUG] Refreshing videos. Found: {len(new_videos)}")
                    # Keep selected videos that still exist
                    new_order = [v for v in current_order if (VIDEOS_DIR / v).exists()]
                    return new_videos, list(new_order)

                def merger_checkbox_change(video_name, is_checked, current_order):
                    """Update selection order when a checkbox is toggled."""
                    new_order = list(current_order)
                    if is_checked:
                        if video_name not in new_order:
                            new_order.append(video_name)
                    else:
                        if video_name in new_order:
                            new_order.remove(video_name)
                    return new_order

                def merger_order_submit(video_name, new_val, current_order):
                    """Handle manual order number changes with swap logic."""
                    if not new_val or not str(new_val).isdigit():
                        return list(current_order)
                    
                    new_pos = int(new_val)
                    new_order = list(current_order)
                    if video_name not in new_order:
                        new_order.append(video_name)
                        
                    old_idx = new_order.index(video_name)
                    new_idx = new_pos - 1
                    
                    if 0 <= new_idx < len(new_order):
                        new_order[old_idx], new_order[new_idx] = new_order[new_idx], new_order[old_idx]
                    
                    return new_order

                with gr.Row():
                    with gr.Column(scale=4):
                        with gr.Row():
                            gr.Markdown(f"### ğŸ“¹ ë¹„ë””ì˜¤ ê°¤ëŸ¬ë¦¬ / Video Gallery")
                            refresh_video_btn = gr.Button("ğŸ”„ ìµœì‹ í™” / Refresh", size="sm", variant="secondary")
                        
                        gr.Markdown("*ğŸ“± ë¹„ë””ì˜¤ë¥¼ íƒ­í•˜ì—¬ ì„ íƒ/í•´ì œí•˜ì„¸ìš” (ì„ íƒ ìˆœì„œê°€ í‘œì‹œë©ë‹ˆë‹¤) / Tap videos to select/deselect (selection order will be shown)*")

                        # Fixed gallery slots (max 60 videos)
                        MAX_VIDEOS = 60
                        gallery_components = []
                        
                        # Create fixed grid of components
                        for row_idx in range(MAX_VIDEOS // 3):
                            with gr.Row():
                                for col_idx in range(3):
                                    idx = row_idx * 3 + col_idx
                                    with gr.Column(scale=1, min_width=200, visible=False) as container:
                                        video = gr.Video(
                                            label=None,
                                            interactive=False,
                                            height=280,
                                            show_label=False
                                        )
                                        with gr.Row():
                                            order_display = gr.Textbox(
                                                value="",
                                                label=None,
                                                container=False,
                                                elem_classes=["order-display"],
                                                interactive=True
                                            )
                                            checkbox = gr.Checkbox(
                                                label="",
                                                value=False,
                                                container=False
                                            )
                                        
                                        # Store components for updates
                                        gallery_components.append({
                                            "container": container,
                                            "video": video,
                                            "order": order_display,
                                            "checkbox": checkbox,
                                            "index": idx
                                        })
                                        
                                        # Event handlers
                                        def handle_checkbox_change(checked, current_order, all_files, idx=idx):
                                            if not all_files or idx >= len(all_files):
                                                return current_order, gr.update()
                                            
                                            video_name = Path(all_files[idx]).name
                                            new_order = merger_checkbox_change(video_name, checked, current_order)
                                            
                                            # Only update the specific order display, NOT the whole gallery
                                            order_val = str(new_order.index(video_name) + 1) if video_name in new_order else ""
                                            return new_order, order_val

                                        checkbox.change(
                                            fn=handle_checkbox_change,
                                            inputs=[checkbox, selection_order_state, video_files_state],
                                            outputs=[selection_order_state, order_display]
                                        )
                                        
                                        def handle_order_submit(val, current_order, all_files, idx=idx):
                                            if not all_files or idx >= len(all_files):
                                                return current_order
                                            video_name = Path(all_files[idx]).name
                                            return merger_order_submit(video_name, val, current_order)
                                            
                                        order_display.submit(
                                            fn=handle_order_submit,
                                            inputs=[order_display, selection_order_state, video_files_state],
                                            outputs=[selection_order_state]
                                        )

                        def refresh_gallery_ui(current_order):
                            """Refresh the UI components based on files on disk."""
                            all_files = get_video_files()
                            video_names = [Path(v).name for v in all_files]
                            
                            updates = []
                            # Update video_files_state
                            updates.append(all_files)
                            # Update order_state (clean up invalid files)
                            valid_order = [v for v in current_order if v in video_names]
                            updates.append(valid_order)
                            
                            # Update components
                            for i, comp in enumerate(gallery_components):
                                if i < len(all_files):
                                    v_path = all_files[i]
                                    v_name = video_names[i]
                                    is_selected = v_name in valid_order
                                    order_val = str(valid_order.index(v_name) + 1) if is_selected else ""
                                    
                                    # Show container
                                    updates.append(gr.update(visible=True))
                                    # Update video
                                    updates.append(gr.update(value=v_path))
                                    # Update order
                                    updates.append(gr.update(value=order_val))
                                    # Update checkbox
                                    updates.append(gr.update(
                                        label=f"{v_name[:25]}..." if len(v_name) > 25 else v_name,
                                        value=is_selected
                                    ))
                                else:
                                    # Hide unused slots
                                    updates.append(gr.update(visible=False))
                                    updates.append(gr.update(value=None))
                                    updates.append(gr.update(value=""))
                                    updates.append(gr.update(value=False))
                            
                            return tuple(updates)

                        # Flatten output list for refresh button
                        refresh_outputs = [video_files_state, selection_order_state]
                        for comp in gallery_components:
                            refresh_outputs.extend([
                                comp["container"], 
                                comp["video"], 
                                comp["order"], 
                                comp["checkbox"]
                            ])

                        refresh_video_btn.click(
                            fn=refresh_gallery_ui,
                            inputs=[selection_order_state],
                            outputs=refresh_outputs
                        )

                    with gr.Column(scale=1, min_width=250):
                        gr.Markdown("### âš™ï¸ ì„¤ì • / Settings")

                        video_order = gr.Textbox(
                            label="ë¹„ë””ì˜¤ ìˆœì„œ (ì„ íƒì‚¬í•­) / Video Order (Optional)",
                            placeholder="ì˜ˆ: 0,2,1",
                            info="ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ ì¸ë±ìŠ¤. ë¹„ì›Œë‘ë©´ ì„ íƒ ìˆœì„œ ì‚¬ìš©",
                            lines=1
                        )

                        gr.Markdown("### ğŸ”Š ì˜¤ë””ì˜¤ ì„ íƒ / Select Audio")
                        gr.Markdown("*`ai video script/audio` í´ë”ì˜ íŒŒì¼ì´ë‚˜ ë°©ê¸ˆ ìƒì„±ëœ ì˜¤ë””ì˜¤ë¥¼ ì„ íƒí•˜ì„¸ìš”*")

                        tts_audio_choices = get_tts_audio_files()
                        audio_files_select = gr.CheckboxGroup(
                            choices=tts_audio_choices,
                            value=[],
                            label=f"TTS ì˜¤ë””ì˜¤ íŒŒì¼ (ì´ {len(tts_audio_choices)}ê°œ)",
                            info="ì—¬ëŸ¬ ê°œ ì„ íƒí•˜ë©´ ì˜¤ë””ì˜¤ ê°œìˆ˜ë§Œí¼ ì‡¼ì¸ ê°€ ìƒì„±ë©ë‹ˆë‹¤"
                        )

                        def refresh_audio_choices(generated_paths):
                            """Refresh audio list from disk, include newly generated ones."""
                            files_on_disk = get_tts_audio_files()
                            # Ensure generated files are surfaced even if not yet scanned
                            extra = []
                            for p in generated_paths or []:
                                name = Path(p).name
                                if name not in files_on_disk:
                                    extra.append(name)
                            all_files = extra + files_on_disk
                            return gr.update(
                                choices=all_files,
                                label=f"TTS ì˜¤ë””ì˜¤ íŒŒì¼ (ì´ {len(all_files)}ê°œ)",
                                value=[]
                            )

                        generated_audios.change(
                            fn=refresh_audio_choices,
                            inputs=[generated_audios],
                            outputs=[audio_files_select]
                        )

                        gr.Markdown("### ğŸµ ë°°ê²½ìŒì•… / Background Music")
                        bgm_files = get_bgm_files()
                        bgm_choices = ["ì—†ìŒ / None"] + bgm_files
                        bgm_dropdown = gr.Dropdown(
                            choices=bgm_choices,
                            value="ì—†ìŒ / None",
                            label="ë°°ê²½ìŒì•… ì„ íƒ / Select BGM",
                            info=f"background music í´ë”ì—ì„œ {len(bgm_files)}ê°œ íŒŒì¼ ë°œê²¬"
                        )
                        gr.Markdown("*ë°°ê²½ìŒì•…ì€ TTS ì˜¤ë””ì˜¤ì™€ ë¯¹ì‹±ë˜ì–´ ë‚®ì€ ë³¼ë¥¨(20%)ìœ¼ë¡œ ì¬ìƒë©ë‹ˆë‹¤*")

                        create_shorts_btn = gr.Button("ğŸ¬ ì‡¼ì¸  ë§Œë“¤ê¸° / Create Shorts", variant="primary", size="lg")

                with gr.Row():
                    gr.Markdown("### ğŸ“„ ìƒì„± ê²°ê³¼ / Creation Result")

                with gr.Row():
                    status_output = gr.Textbox(
                        label="ìƒíƒœ / Status",
                        lines=10,
                        interactive=False
                    )

                with gr.Row():
                    gr.Markdown("### ğŸ¬ ìƒì„±ëœ ì‡¼ì¸  ë¯¸ë¦¬ë³´ê¸° / Generated Shorts Preview")

                with gr.Row():
                    output_video1 = gr.Video(label="ì‡¼ì¸  1 / Shorts 1")
                    output_video2 = gr.Video(label="ì‡¼ì¸  2 / Shorts 2")
                    output_video3 = gr.Video(label="ì‡¼ì¸  3 / Shorts 3")

                with gr.Row():
                    output_video4 = gr.Video(label="ì‡¼ì¸  4 / Shorts 4")
                    output_video5 = gr.Video(label="ì‡¼ì¸  5 / Shorts 5")
                    output_video6 = gr.Video(label="ì‡¼ì¸  6 / Shorts 6")

                with gr.Row():
                    output_video7 = gr.Video(label="ì‡¼ì¸  7 / Shorts 7")

                # Create shorts handler
                def create_shorts_handler(current_selected_vids, selected_audio_files, generated_audio_paths, order, bgm):
                    # selected_audio_files: list of names from checkboxgroup
                    # generated_audio_paths: list of full paths from gr.State
                    # current_selected_vids: list of video names from selection_order_state
                    
                    selected_audio_files = selected_audio_files or []
                    generated_audio_paths = generated_audio_paths or []
                    selected_vids = current_selected_vids or []

                    # Build selected audios list from selected filenames (map to full paths)
                    selected_audios = []
                    for name in selected_audio_files:
                        full_path = TTS_AUDIO_DIR / name
                        if full_path.exists():
                            selected_audios.append(str(full_path))
                        else:
                            # fallback: maybe generated_audios contains absolute path
                            for p in generated_audio_paths:
                                if Path(p).name == name:
                                    selected_audios.append(p)
                                    break

                    if not selected_audios:
                        return ["âŒ ëŒ€ë³¸ ìƒì„± ë˜ëŠ” audio í´ë”ì—ì„œ ì˜¤ë””ì˜¤ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”"] + [None] * 7
                    
                    if not selected_vids:
                        return ["âŒ ë¹„ë””ì˜¤ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”"] + [None] * 7

                    status, output_paths = create_shorts(selected_vids, selected_audios, order, bgm)
                    outputs = [None] * 7
                    for i, path in enumerate(output_paths[:7]):
                        outputs[i] = path
                    return [status] + outputs

                # Prepare inputs: selection_order_state + audio_files_select + generated_audios + video_order + bgm_dropdown
                all_inputs = [selection_order_state, audio_files_select, generated_audios, video_order, bgm_dropdown]

                create_shorts_btn.click(
                    fn=create_shorts_handler,
                    inputs=all_inputs,
                    outputs=[
                        status_output,
                        output_video1, output_video2, output_video3,
                        output_video4, output_video5, output_video6, output_video7
                    ]
                )

                # Usage guide
                gr.Markdown("### ğŸ’¡ ì‚¬ìš© ë°©ë²• / How to Use")
                gr.Markdown("""
                1. **ëŒ€ë³¸ ìƒì„±**: "ğŸ“ ëŒ€ë³¸ ìƒì„± / Script Generator" íƒ­ì—ì„œ ë¨¼ì € ëŒ€ë³¸ì„ ìƒì„±í•˜ì„¸ìš”
                2. **ë¹„ë””ì˜¤ ì„ íƒ**: ê°¤ëŸ¬ë¦¬ì—ì„œ ì²´í¬ë°•ìŠ¤ë¡œ ë¹„ë””ì˜¤ë¥¼ ì„ íƒí•˜ì„¸ìš” (ì„ íƒ ìˆœì„œê°€ í‘œì‹œë©ë‹ˆë‹¤)
                3. **ì˜¤ë””ì˜¤ ì„ íƒ**: ì˜¤ë¥¸ìª½ íŒ¨ë„ì—ì„œ ìƒì„±ëœ ì˜¤ë””ì˜¤ë¥¼ ì„ íƒí•˜ì„¸ìš”
                4. **ìˆœì„œ ì§€ì •** (ì„ íƒì‚¬í•­): ë¹„ë””ì˜¤ ìˆœì„œë¥¼ ë³€ê²½í•˜ë ¤ë©´ ì¸ë±ìŠ¤ ì…ë ¥ (ì˜ˆ: 0,2,1)
                5. **ì‡¼ì¸  ë§Œë“¤ê¸°**: ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ì„ íƒí•œ ê° ì˜¤ë””ì˜¤ë§ˆë‹¤ ì‡¼ì¸ ê°€ ìƒì„±ë©ë‹ˆë‹¤

                **ì¶œë ¥ í´ë”**: `final_shorts/`
                """)

    return demo


def main():
    """Launch Gradio interface."""
    demo = create_gradio_interface()

    # Allow access to final_shorts directory
    final_shorts_dir = Path(__file__).parent.parent / "final_shorts"
    final_shorts_dir.mkdir(exist_ok=True)

    # Allow port override via environment (avoids collision if 7860 is busy)
    preferred_port = int(os.environ.get("GRADIO_SERVER_PORT", "7860"))

    def find_available_port(start_port: int, max_tries: int = 20) -> int:
        """Find an available port by attempting to bind incrementally."""
        for port in range(start_port, start_port + max_tries):
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                try:
                    s.bind(("127.0.0.1", port))
                    return port
                except OSError:
                    continue
        raise OSError(f"No available port found in range {start_port}-{start_port + max_tries - 1}")

    server_port = find_available_port(preferred_port)

    demo.launch(
        share=False,
        server_name="127.0.0.1",
        server_port=server_port,
        allowed_paths=[
            str(final_shorts_dir), 
            str(TTS_AUDIO_DIR), 
            str(INPUT_DIR), 
            str(VIDEOS_DIR), 
            str(BGM_DIR)
        ]
    )
    print(f"\nâœ“ Gradio interface launched at http://127.0.0.1:{server_port}")
    print("Press Ctrl+C to stop the server")


if __name__ == "__main__":
    main()
