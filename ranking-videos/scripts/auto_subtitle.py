"""Geminië¥¼ ì‚¬ìš©í•œ ìë™ ìë§‰ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (Windows ë²„ì „)"""

import os
import json
import re
import subprocess
from moviepy import VideoFileClip, TextClip, CompositeVideoClip
from PIL import ImageFont, ImageDraw, Image
from tqdm import tqdm
import numpy as np

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    genai = None
    GEMINI_AVAILABLE = False


def load_config():
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    config_path = os.path.join("Config", "config.json")
    if not os.path.exists(config_path):
        return {}

    with open(config_path, "r", encoding="utf-8") as f:
        return json.load(f)


def get_config_value(keys, default=None):
    """ì¤‘ì²©ëœ ì„¤ì • ê°’ ê°€ì ¸ì˜¤ê¸°"""
    config = load_config()
    value = config
    for key in keys:
        if isinstance(value, dict):
            value = value.get(key)
        else:
            return default
    return value if value is not None else default


def get_system_font():
    """ì‹œìŠ¤í…œ í°íŠ¸ ê²½ë¡œ ë°˜í™˜ (í•œê¸€ ì§€ì›)"""
    import platform
    system = platform.system()

    if system == "Darwin":  # macOS
        mac_fonts = [
            "/System/Library/Fonts/Supplemental/AppleGothic.ttf",  # ì• í”Œê³ ë”•
            "/System/Library/Fonts/Supplemental/AppleMyungjo.ttf",  # ì• í”Œëª…ì¡°
            "/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf",  # Noto Sans Gothic
            "/Library/Fonts/AppleGothic.ttf",
        ]
        for font_path in mac_fonts:
            if os.path.exists(font_path):
                return font_path

    elif system == "Windows":
        windows_fonts = [
            r"C:\Windows\Fonts\malgun.ttf",      # ë§‘ì€ ê³ ë”•
            r"C:\Windows\Fonts\arial.ttf",       # Arial
            r"C:\Windows\Fonts\arialbd.ttf",     # Arial Bold
        ]
        for font_path in windows_fonts:
            if os.path.exists(font_path):
                return font_path

    return None


def get_windows_font():
    """Windows ì‹œìŠ¤í…œ í°íŠ¸ ê²½ë¡œ ë°˜í™˜ (í•œê¸€ ì§€ì›) - í•˜ìœ„ í˜¸í™˜ì„±"""
    return get_system_font()


def apply_cinematic_filter(get_frame, t):
    """
    ê°•ë ¥í•œ ì‹œë„¤ë§ˆí‹± í•„í„° ì ìš© í•¨ìˆ˜ (ì›€ì§ì„ ì¶”ê°€)
    - ê°•í•œ ë¹„ë„¤íŠ¸ íš¨ê³¼ (ê°€ì¥ìë¦¬ ë§ì´ ì–´ë‘¡ê²Œ)
    - ë°ê¸° ê°ì†Œ
    - ì±„ë„ ëŒ€í­ ê°ì†Œ (desaturated ëŠë‚Œ)
    - Contrast ì¦ê°€
    - ì‹œê°„ì— ë”°ë¥¸ ë¯¸ë¬˜í•œ ë°ê¸° ë³€í™” (breathing íš¨ê³¼)
    - ì•½í•œ í•„ë¦„ ê·¸ë ˆì¸ íš¨ê³¼
    """
    frame = get_frame(t)
    h, w = frame.shape[:2]

    # 1. ê°•í•œ ë¹„ë„¤íŠ¸ íš¨ê³¼ ìƒì„±
    Y, X = np.ogrid[:h, :w]
    center_y, center_x = h / 2, w / 2

    # ê±°ë¦¬ ê³„ì‚°
    dist_from_center = np.sqrt((X - center_x)**2 + (Y - center_y)**2)
    max_dist = np.sqrt(center_x**2 + center_y**2)

    # ë¹„ë„¤íŠ¸ ê°•ë„ ëŒ€í­ ì¦ê°€ (ê°€ì¥ìë¦¬ë¥¼ ë” ì–´ë‘¡ê²Œ)
    vignette = 1 - (dist_from_center / max_dist) * 0.7
    vignette = np.clip(vignette, 0.4, 1.0)  # ìµœì†Œ 40% ë°ê¸° (ë” ì–´ë‘ì›€)

    # RGB ì±„ë„ì— ë¹„ë„¤íŠ¸ ì ìš©
    vignette_3d = np.stack([vignette, vignette, vignette], axis=-1)
    frame = (frame * vignette_3d).astype('uint8')

    # 2. ì „ì²´ ë°ê¸° ê°ì†Œ + ì‹œê°„ì— ë”°ë¥¸ breathing íš¨ê³¼
    breathing = 0.85 + 0.08 * np.sin(2 * np.pi * t / 3.5)  # 3.5ì´ˆ ì£¼ê¸°ë¡œ ë” ê°•í•˜ê²Œ ë°ì•„ì¡Œë‹¤ ì–´ë‘ì›Œì¡Œë‹¤
    frame = (frame * breathing).astype('uint8')

    # 3. ì±„ë„ë„ ì‹œê°„ì— ë”°ë¼ ë³€í™” (ì‚´ì•„ìˆëŠ” ëŠë‚Œ)
    gray = np.mean(frame, axis=-1, keepdims=True)
    saturation_factor = 0.65 + 0.05 * np.sin(2 * np.pi * t / 5.0)  # ì±„ë„ë„ ì•½ê°„ ë³€í™”
    frame = (frame * saturation_factor + gray * (1 - saturation_factor)).astype('uint8')

    # 4. Contrast ì¦ê°€ (ëª…ì•”ë¹„ ê°•í™”)
    frame = np.clip((frame - 128) * 1.15 + 128, 0, 255).astype('uint8')

    # 5. í•„ë¦„ ê·¸ë ˆì¸ íš¨ê³¼ (ë¯¸ë¬˜í•œ ë…¸ì´ì¦ˆ)
    grain = np.random.randint(-3, 4, frame.shape, dtype=np.int16)
    frame = np.clip(frame.astype(np.int16) + grain, 0, 255).astype('uint8')

    return frame


class GeminiSubtitleGenerator:
    """Geminië¥¼ ì‚¬ìš©í•œ ìë§‰ ìƒì„± í´ë˜ìŠ¤"""

    def __init__(self, video_path, text_color="white", text_size=40, text_font=None, y_offset=0, bottom_margin=220, ai_voice_audio_path=None):
        """
        Args:
            video_path (str): ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            text_color (str): ìë§‰ ìƒ‰ìƒ
            text_size (int): ìë§‰ í¬ê¸°
            text_font (str): í°íŠ¸ ê²½ë¡œ
            y_offset (int): í•˜ë‹¨ì—ì„œ ìœ„ë¡œ ì˜¬ë¦´ ê±°ë¦¬ (í”½ì…€)
            bottom_margin (int): í™”ë©´ í•˜ë‹¨ìœ¼ë¡œë¶€í„° í™•ë³´í•  ìµœì†Œ ì—¬ë°±
            ai_voice_audio_path (str): AI ìŒì„±ë§Œ í¬í•¨ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ìë§‰ ìƒì„±ìš©)
        """
        if not GEMINI_AVAILABLE:
            raise RuntimeError("google-generativeai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        self.video_path = video_path
        self.ai_voice_audio_path = ai_voice_audio_path  # AI ìŒì„± ì˜¤ë””ì˜¤ ê²½ë¡œ
        self.text_color = text_color
        self.text_size = text_size

        # ëœë¤ ìƒ‰ìƒ ì„¤ì • ë¡œë“œ
        self.random_colors_enabled = get_config_value(["subtitle_settings", "random_colors", "enabled"], False)
        self.random_colors_list = get_config_value(["subtitle_settings", "random_colors", "colors"], ["white"])
        self.current_color_index = 0

        # ì‹œìŠ¤í…œ í°íŠ¸ ìë™ ê°ì§€ (í•œê¸€ ì§€ì›)
        if text_font and os.path.exists(text_font):
            self.text_font = text_font
        else:
            detected_font = get_system_font()
            if detected_font:
                self.text_font = detected_font
                print(f"   ğŸ“ í•œê¸€ í°íŠ¸ ê°ì§€: {os.path.basename(detected_font)}")
            else:
                # í´ë°±: ê¸°ë³¸ í°íŠ¸
                self.text_font = None
                print("   âš ï¸ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©")

        self.y_offset = y_offset
        self.bottom_margin = max(0, int(bottom_margin))
        # ì¢Œìš° ì•ˆì „ ì—¬ë°± (ìë§‰ ì¤„ë°”ê¿ˆ í­ ê³„ì‚°ìš©)
        self.side_margin = int(get_config_value(["subtitle_settings", "side_margin"], 80))
        # í•˜ë‹¨ í´ë¦¬í•‘ ë°©ì§€ìš© ì—¬ìœ  íŒ¨ë”© (ë¹„ë””ì˜¤ ë°”ë‹¥ê³¼ì˜ ì¶”ê°€ ê°„ê²©)
        self.bottom_safety = int(get_config_value(["subtitle_settings", "bottom_safety"], 8))
        # ìë§‰ ê²¹ì¹¨ ë°©ì§€ ì„¸ë¶€ ì„¤ì •
        self.overlap_gap = max(0.0, float(get_config_value(["subtitle_settings", "safe_gap"], 0.1)))
        self.min_visible_duration = max(0.1, float(get_config_value(["subtitle_settings", "min_visible_duration"], 0.35)))
        self.strict_timing = bool(get_config_value(["subtitle_settings", "strict_timing"], True))
        self.script_match_ratio = float(get_config_value(["subtitle_settings", "script_match_ratio"], 0.7))
        self.script_min_chars = int(get_config_value(["subtitle_settings", "script_min_chars"], 6))

        # ìë§‰ í‘œì‹œ ì‹œê°„ ì œì–´: ëë‚˜ê³  ì¡°ê¸ˆ ë” ë¨¸ë¬´ë¥´ê²Œ + ë„ˆë¬´ ì§§ì€ ìë§‰ì€ ìµœì†Œ ì‹œê°„ ë³´ì¥
        self.extra_hold = float(get_config_value(["subtitle_settings", "extra_hold"], 0.6))
        self.min_duration = float(get_config_value(["subtitle_settings", "min_duration"], 1.2))

        self.video = VideoFileClip(video_path)
        self.width = self.video.w
        self.height = self.video.h
        self.sub_clips = []

        # Configure AI-script-only filtering
        self.require_ai_script_only = bool(get_config_value(["subtitle_settings", "require_ai_script_only"], True))
        self.script_filter_keep_ratio = max(0.0, min(1.0, float(
            get_config_value(["subtitle_settings", "script_keep_ratio"], 0.5)
        )))
        self.ai_script_lines = self._load_ai_script_lines() if self.require_ai_script_only else []
        self._allowed_subtitle_texts = [self._normalize_text(line) for line in self.ai_script_lines if line]

        # Gemini ì„¤ì •
        api_key = get_config_value(["ai_settings", "api_key"])
        if not api_key:
            raise ValueError("config.jsonì— ai_settings.api_keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        genai.configure(api_key=api_key)
        model_name = get_config_value(["subtitle_settings", "model"], "models/gemini-2.0-flash-exp")
        self.model = genai.GenerativeModel(model_name)

    def _normalize_text(self, text):
        """Normalize text for comparison."""
        normalized = re.sub(r"\s+", " ", (text or "")).strip().lower()
        normalized = re.sub(r"[^\w\s\u3131-\u318e\uac00-\ud7a3]", "", normalized)
        return re.sub(r"\s+", " ", normalized).strip()

    def _load_ai_script_lines(self):
        """Load AI generated dialogue lines if available."""
        script_path = get_config_value(["ai_settings", "last_script_path"], "Temp/last_script.txt")
        if not script_path:
            return []

        script_path = os.path.abspath(script_path)
        if not os.path.exists(script_path):
            return []

        dialogue_lines = []
        timing_pattern = re.compile(r"^\s*\([^)]*\)\s*(.+)$")
        skip_prefixes = (
            "key moment",
            "thumbnail title",
            "core keyword",
            "background music",
            "youtube title",
            "youtube description",
        )

        with open(script_path, "r", encoding="utf-8") as script_file:
            for raw_line in script_file:
                stripped = raw_line.strip()
                if not stripped:
                    continue

                match = timing_pattern.match(stripped)
                if match:
                    stripped = match.group(1).strip()

                lowered = stripped.lower()
                if any(lowered.startswith(prefix) for prefix in skip_prefixes):
                    continue

                dialogue_lines.append(stripped)

        return dialogue_lines

    def _is_allowed_subtitle_text(self, normalized_text):
        """Return True if the subtitle text is allowed under AI-only filtering."""
        if not normalized_text:
            return False

        if not self._allowed_subtitle_texts:
            # No AI script available; allow everything.
            return True

        for allowed in self._allowed_subtitle_texts:
            if not allowed:
                continue
            if normalized_text == allowed:
                return True
            allowed_len = len(allowed)
            text_len = len(normalized_text)
            min_chars = max(1, self.script_min_chars)
            ratio = max(0.0, min(1.0, self.script_match_ratio))

            if text_len >= min_chars and allowed_len >= min_chars:
                if normalized_text in allowed and (text_len / allowed_len) >= ratio:
                    return True
                if allowed in normalized_text and (allowed_len / text_len) >= ratio:
                    return True

        return False

    def _measure_text_width(self, text, font_size, stroke_width=0):
        """PILì„ ì‚¬ìš©í•´ í…ìŠ¤íŠ¸ í”½ì…€ í­ ì¸¡ì •"""
        try:
            font = ImageFont.truetype(self.text_font, font_size)
        except Exception:
            font = ImageFont.load_default()

        dummy_img = Image.new("RGB", (1, 1))
        draw = ImageDraw.Draw(dummy_img)
        bbox = draw.textbbox((0, 0), text, font=font, stroke_width=stroke_width)
        return bbox[2] - bbox[0]

    def _wrap_text_for_width(self, text, font_size, stroke_width, max_width):
        """ì£¼ì–´ì§„ í­ì— ë§ì¶° ìë™ ì¤„ë°”ê¿ˆ (ì˜ë¬¸ì€ ë‹¨ì–´ ë‹¨ìœ„, CJKëŠ” ê¸€ì ë‹¨ìœ„)"""
        if not text:
            return ""

        is_word_based = (" " in text)
        tokens = text.split(" ") if is_word_based else list(text)

        lines = []
        line = ""

        def add_token(cur, tok):
            if not cur:
                return tok
            return (cur + (" " if is_word_based else "") + tok)

        for tok in tokens:
            candidate = add_token(line, tok)
            width = self._measure_text_width(candidate, font_size, stroke_width)
            if width <= max_width:
                line = candidate
            else:
                if line:
                    # í˜„ì¬ ì¤„ì„ ì €ì¥í•˜ê³  í† í°ì„ ë‹¤ìŒ ì¤„ë¡œ
                    lines.append(line)
                    line = tok
                else:
                    # ì²« í† í°ë¶€í„° ë„˜ì¹˜ëŠ” ê²½ìš° - ë‹¨ì–´ë¥¼ ê·¸ëŒ€ë¡œ ë‹¤ìŒ ì¤„ì— ë°°ì¹˜
                    line = tok

        if line:
            lines.append(line)

        # ê° ì¤„ íŠ¸ë¦¬ë° í›„ í•©ì¹˜ê¸°
        return "\n".join(l.rstrip() for l in lines if l is not None)

    def detect_silence_offset(self, noise_threshold="-30dB", min_silence=0.5):
        """
        ë¹„ë””ì˜¤ ì‹œì‘ ë¶€ë¶„ì˜ ì¹¨ë¬µ êµ¬ê°„ ê°ì§€

        Returns:
            float: ì¹¨ë¬µ ë ì‹œê°„ (ì´ˆ)
        """
        try:
            cmd = [
                "ffmpeg", "-i", self.video_path,
                "-af", f"silencedetect=noise={noise_threshold}:d={min_silence}",
                "-f", "null", "-"
            ]

            process = subprocess.Popen(cmd, stderr=subprocess.PIPE, stdout=subprocess.PIPE, text=True)
            _, stderr = process.communicate()

            matches = re.findall(r"silence_end:\s*([0-9.]+)", stderr)
            if matches:
                return float(matches[0])
        except (FileNotFoundError, OSError) as e:
            # ffmpegê°€ ì—†ìœ¼ë©´ ì¹¨ë¬µ ê°ì§€ ê±´ë„ˆë›°ê¸°
            print(f"   âš ï¸ ffmpegë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì¹¨ë¬µ ê°ì§€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return 0.0

    def transcribe_with_gemini(self):
        """Geminië¡œ ë¹„ë””ì˜¤ ìŒì„± ì¸ì‹ ë° ìë§‰ ìƒì„±"""
        import time

        print("ğŸ“ Geminië¡œ ìŒì„± ì¸ì‹ ì¤‘...")

        # AI ìŒì„± ì˜¤ë””ì˜¤ íŒŒì¼ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ë¹„ë””ì˜¤ ì‚¬ìš©
        if self.ai_voice_audio_path and os.path.exists(self.ai_voice_audio_path):
            upload_file_path = self.ai_voice_audio_path
            print(f"   ğŸ™ï¸ AI ìŒì„± ì˜¤ë””ì˜¤ ì‚¬ìš©: {os.path.basename(upload_file_path)}")
            print(f"   âœ… ì›ë³¸ ë¹„ë””ì˜¤ ì˜¤ë””ì˜¤ëŠ” ìë§‰í™”í•˜ì§€ ì•ŠìŒ")
        else:
            upload_file_path = self.video_path
            print(f"   âš ï¸ AI ìŒì„± ì˜¤ë””ì˜¤ ì—†ìŒ, ì „ì²´ ë¹„ë””ì˜¤ ì‚¬ìš©: {os.path.basename(upload_file_path)}")

        # íŒŒì¼ ì—…ë¡œë“œ
        print(f"   íŒŒì¼ ì—…ë¡œë“œ ì¤‘...")
        video_file = genai.upload_file(upload_file_path)

        # íŒŒì¼ì´ ACTIVE ìƒíƒœê°€ ë  ë•Œê¹Œì§€ ëŒ€ê¸°
        print(f"   íŒŒì¼ ì²˜ë¦¬ ëŒ€ê¸° ì¤‘...", end="", flush=True)
        while video_file.state.name == "PROCESSING":
            print(".", end="", flush=True)
            time.sleep(2)
            video_file = genai.get_file(video_file.name)

        if video_file.state.name == "FAILED":
            raise ValueError(f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {video_file.state.name}")

        print(" âœ…")

        # Geminiì—ê²Œ ìë§‰ ìƒì„± ìš”ì²­
        prompt = """
Transcribe all spoken words in this audio/video with precise timestamps.

Return ONLY a JSON array in this exact format:
[
  {"start": 0.0, "end": 2.5, "text": "First sentence"},
  {"start": 2.5, "end": 5.0, "text": "Second sentence"}
]

Requirements:
- Each segment should be a complete sentence or phrase
- Timestamps must be in seconds (float)
- Include ALL spoken content
- Do not include ANY other text or explanation
- Return ONLY the JSON array
"""

        response = self.model.generate_content([video_file, prompt])

        # JSON íŒŒì‹±
        try:
            # ì½”ë“œ ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ
            json_text = response.text.strip()
            if "```json" in json_text:
                match = re.search(r'```json\s*([\s\S]*?)\s*```', json_text, re.DOTALL)
                if match:
                    json_text = match.group(1).strip()
            elif "```" in json_text:
                match = re.search(r'```\s*([\s\S]*?)\s*```', json_text, re.DOTALL)
                if match:
                    json_text = match.group(1).strip()

            # JSON ìˆ˜ì •: ë‹«ëŠ” ê´„í˜¸ê°€ ì—†ìœ¼ë©´ ì¶”ê°€
            if json_text.startswith('[') and not json_text.rstrip().endswith(']'):
                json_text = json_text.rstrip()
                # ë§ˆì§€ë§‰ ê°ì²´ê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
                if json_text.rstrip().endswith('}'):
                    json_text += '\n]'
                elif json_text.rstrip().endswith(','):
                    # ë§ˆì§€ë§‰ ì‰¼í‘œ ì œê±°í•˜ê³  ë‹«ê¸°
                    json_text = json_text.rstrip().rstrip(',') + '\n]'

            segments = json.loads(json_text)

        except (json.JSONDecodeError, AttributeError) as e:
            print(f"âš ï¸  JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ ì‘ë‹µ:\n{response.text}")
            print(f"âš ï¸  ì²˜ë¦¬ëœ JSON:\n{json_text}")
            raise ValueError(f"Gemini ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")

        # ì¹¨ë¬µ ì˜¤í”„ì…‹ ê°ì§€ ë° ì ìš© (ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ì— ì ìš©)
        silence_offset = self.detect_silence_offset()
        if silence_offset > 0 and len(segments) > 0:
            for seg in segments:
                seg['start'] += silence_offset
                seg['end'] += silence_offset
            print(f"   ì¹¨ë¬µ ì˜¤í”„ì…‹ ì ìš©: +{silence_offset:.2f}ì´ˆ")

        print(f"âœ… {len(segments)}ê°œì˜ ìë§‰ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± ì™„ë£Œ")
        return segments

    def get_optimal_font_size(self, text, max_width, stroke_width=0):
        """í…ìŠ¤íŠ¸ê°€ í™”ë©´ì— ë§ëŠ” ìµœì  í°íŠ¸ í¬ê¸° ê³„ì‚°"""
        font_size = self.text_size

        try:
            font = ImageFont.truetype(self.text_font, font_size)
        except:
            # í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í¬ê¸° ë°˜í™˜
            return min(font_size, 50)

        # PILë¡œ í…ìŠ¤íŠ¸ ë„ˆë¹„ ì¸¡ì •
        dummy_img = Image.new("RGB", (1, 1))
        draw = ImageDraw.Draw(dummy_img)
        bbox = draw.textbbox((0, 0), text, font=font, stroke_width=stroke_width)
        text_width = bbox[2] - bbox[0]

        # í…ìŠ¤íŠ¸ê°€ ìµœëŒ€ ë„ˆë¹„ë¥¼ ì´ˆê³¼í•˜ë©´ í°íŠ¸ í¬ê¸° ì¤„ì´ê¸°
        while text_width > max_width and font_size > 20:
            font_size = max(font_size - 2, 12)
            font = ImageFont.truetype(self.text_font, font_size)
            bbox = draw.textbbox((0, 0), text, font=font, stroke_width=stroke_width)
            text_width = bbox[2] - bbox[0]

        return font_size

    def _build_subtitle_clips(self, segments, enforce_script_filter=True, show_progress=True):
        """Build subtitle clips and report how many were filtered out."""
        iterator = tqdm(segments, desc="Subtitle Clips") if show_progress else segments
        sub_clips = []
        last_clip_start = None
        last_clip_end = 0.0
        skipped_by_filter = 0

        for seg in iterator:
            try:
                text = seg["text"].strip()
                if ((text.startswith('"') and text.endswith('"')) or
                        (text.startswith("'") and text.endswith("'"))):
                    text = text[1:-1]

                if not text:
                    continue

                normalized_text = self._normalize_text(text)
                if enforce_script_filter and not self._is_allowed_subtitle_text(normalized_text):
                    skipped_by_filter += 1
                    continue

                original_start = float(seg["start"])
                original_end = float(seg["end"])
                original_start = max(0.0, original_start)
                original_end = max(original_start, original_end)

                if sub_clips and last_clip_start is not None:
                    prev_clip = sub_clips[-1]
                    prev_start = last_clip_start
                    prev_end = last_clip_end
                    cutoff = original_start - self.overlap_gap
                    trimmed_end = min(prev_end, cutoff)
                    if trimmed_end < prev_start:
                        trimmed_end = prev_start
                    trimmed_duration = max(0.0, trimmed_end - prev_start)
                    sub_clips[-1] = prev_clip.with_duration(trimmed_duration)
                    last_clip_end = prev_start + trimmed_duration

                if self.strict_timing:
                    start_time = original_start
                    duration = max((original_end - original_start) + self.extra_hold, self.min_duration)
                    duration = max(duration, self.min_visible_duration)
                else:
                    if sub_clips:
                        start_time = max(original_start, last_clip_end + self.overlap_gap)
                    else:
                        start_time = original_start

                    base_duration = max(original_end - start_time, 0.0)
                    duration = max(base_duration + self.extra_hold, self.min_duration)
                    duration = max(duration, self.min_visible_duration)

                stroke_width = 3
                fixed_font_size = self.text_size
                inner_lr_margin = 40  # margin=(20,20,20,20) left/right total
                max_text_width = max(50, self.width - (2 * self.side_margin) - inner_lr_margin)

                wrapped_text = self._wrap_text_for_width(
                    text=text,
                    font_size=fixed_font_size,
                    stroke_width=stroke_width,
                    max_width=max_text_width,
                )

                # ëœë¤ ìƒ‰ìƒ ì„ íƒ (í™œì„±í™”ëœ ê²½ìš°)
                if self.random_colors_enabled and self.random_colors_list:
                    current_color = self.random_colors_list[self.current_color_index % len(self.random_colors_list)]
                    self.current_color_index += 1
                else:
                    current_color = self.text_color

                # í•œê¸€ ì§€ì›ì„ ìœ„í•´ method="caption" ì‚¬ìš©
                txt = TextClip(
                    text=wrapped_text,
                    font=self.text_font,
                    font_size=fixed_font_size,
                    color=current_color,
                    stroke_color="black",
                    stroke_width=stroke_width,
                    size=(max_text_width + inner_lr_margin, None),
                    method="caption",
                    align="center"
                )

                y_position = self.height - self.bottom_margin - txt.h
                if y_position < 0:
                    y_position = 0

                txt = (
                    txt.with_start(start_time)
                       .with_duration(duration)
                       .with_position(("center", y_position))
                )

                sub_clips.append(txt)
                last_clip_start = start_time
                last_clip_end = start_time + duration

            except Exception as e:
                print(f"[warn] subtitle clip build failed: {seg['text'][:30]}... ({e})")
                continue

        return sub_clips, skipped_by_filter

    def create_subtitle_clips(self, segments):
        """Create subtitle clips (default style)."""
        print("[subtitle] building caption clips...")

        sub_clips, skipped_by_filter = self._build_subtitle_clips(
            segments,
            enforce_script_filter=self.require_ai_script_only,
            show_progress=True
        )

        total_segments = len(segments)
        produced_count = len(sub_clips)

        if skipped_by_filter and self.require_ai_script_only:
            print(f"[subtitle] {skipped_by_filter} segments skipped by AI script filter")

        should_fallback = False
        if self.require_ai_script_only and total_segments > 0:
            matched_ratio = produced_count / total_segments if total_segments else 0.0
            if produced_count == 0 or matched_ratio < self.script_filter_keep_ratio:
                should_fallback = True
                print(
                    f"[subtitle] fallback: only {produced_count}/{total_segments} segments matched AI script"
                )

        if should_fallback:
            sub_clips, _ = self._build_subtitle_clips(
                segments,
                enforce_script_filter=False,
                show_progress=False
            )
            produced_count = len(sub_clips)

        self.sub_clips = sub_clips
        print(f"[subtitle] {produced_count} subtitle clips ready")

    def create_video_with_subtitles(self, output_path):
        """ìë§‰ì´ ì¶”ê°€ëœ ë¹„ë””ì˜¤ ìƒì„±"""
        print("ğŸ¥ ìë§‰ ë¹„ë””ì˜¤ ìƒì„± ì¤‘...")

        if not self.sub_clips:
            raise ValueError("ìë§‰ í´ë¦½ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € transcribe_with_gemini()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

        # ì‹œë„¤ë§ˆí‹± í•„í„° ì ìš© (ì‹œê°„ ê¸°ë°˜ íš¨ê³¼)
        print("   ğŸ¨ ì‹œë„¤ë§ˆí‹± í•„í„° ì ìš© ì¤‘...")
        filtered_video = self.video.fl(apply_cinematic_filter)

        # ë¹„ë””ì˜¤ì™€ ìë§‰ í•©ì„±
        final_video = CompositeVideoClip([filtered_video] + self.sub_clips).with_duration(self.video.duration)

        # ë¹„ë””ì˜¤ ì¶œë ¥
        final_video.write_videofile(
            output_path,
            codec="libx264",
            audio_codec="aac",
            fps=self.video.fps
        )

        print(f"âœ… ìë§‰ ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {output_path}")

    def generate(self, output_path):
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        segments = self.transcribe_with_gemini()
        self.create_subtitle_clips(segments)
        self.create_video_with_subtitles(output_path)


def find_video_file(input_dir):
    """Input í´ë”ì—ì„œ ë¹„ë””ì˜¤ íŒŒì¼ ì°¾ê¸°"""
    supported_extensions = ('.mp4', '.mov', '.mkv', '.avi', '.m4v', '.webm')

    if not os.path.exists(input_dir):
        raise FileNotFoundError(f"Input í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_dir}")

    video_files = [f for f in os.listdir(input_dir)
                   if f.lower().endswith(supported_extensions) and not f.startswith('.')]

    if not video_files:
        raise FileNotFoundError(f"Input í´ë”ì— ë¹„ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {input_dir}")

    # ê°€ì¥ ìµœê·¼ì— ìˆ˜ì •ëœ íŒŒì¼ ì„ íƒ
    video_files_with_time = [(f, os.path.getmtime(os.path.join(input_dir, f)))
                              for f in video_files]
    latest_video = max(video_files_with_time, key=lambda x: x[1])[0]

    return os.path.join(input_dir, latest_video)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import sys

    # ë¹„ë””ì˜¤ ê²½ë¡œ ê²°ì •
    if len(sys.argv) >= 2:
        video_path = sys.argv[1]
        if not os.path.exists(video_path):
            print(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
            return
    else:
        # ì¸ìê°€ ì—†ìœ¼ë©´ Input í´ë”ì—ì„œ ìë™ìœ¼ë¡œ ì°¾ê¸°
        input_dir = get_config_value(["paths", "input_dir"], "Input")
        try:
            video_path = find_video_file(input_dir)
            print(f"ğŸ¥ ë°œê²¬ëœ ë¹„ë””ì˜¤: {os.path.basename(video_path)}")
        except FileNotFoundError as e:
            print(f"âŒ {e}")
            return

    # ì¶œë ¥ ê²½ë¡œ ìƒì„±
    output_dir = get_config_value(["paths", "output_dir"], "Output")
    os.makedirs(output_dir, exist_ok=True)

    video_name = os.path.splitext(os.path.basename(video_path))[0]
    output_path = os.path.join(output_dir, f"{video_name}_subtitled.mp4")

    # ì„¤ì • ë¡œë“œ
    text_color = get_config_value(["subtitle_settings", "text_color"], "white")
    text_size = get_config_value(["subtitle_settings", "text_size"], 40)
    text_font = get_config_value(["subtitle_settings", "text_font"])
    y_offset = get_config_value(["subtitle_settings", "y_offset"], 0)
    bottom_margin = get_config_value(["subtitle_settings", "bottom_margin"], 220)

    # ìë§‰ ìƒì„±
    try:
        generator = GeminiSubtitleGenerator(
            video_path=video_path,
            text_color=text_color,
            text_size=text_size,
            text_font=text_font,
            y_offset=y_offset,
            bottom_margin=bottom_margin
        )
        generator.generate(output_path)
        print(f"\nğŸ‰ ì™„ë£Œ! ì¶œë ¥: {output_path}")
    except Exception as e:
        print(f"\nâŒì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
