"""ë­í‚¹ ì»´í•„ë ˆì´ì…˜ ë¹„ë””ì˜¤ ìë™ ìƒì„± ìŠ¤í¬ë¦½íŠ¸"""

import os
os.environ["GOOGLE_API_USE_CLIENT_CERTIFICATE"] = "false"

from moviepy import (
    VideoFileClip,
    TextClip,
    CompositeVideoClip,
    concatenate_videoclips,
    ColorClip,
    AudioFileClip,
    CompositeAudioClip
)
from moviepy.audio.fx import MultiplyVolume, AudioLoop
from PIL import Image, ImageDraw, ImageFont
import json
import re
from datetime import datetime
import sys
import random

try:
    import requests
    import base64
    from io import BytesIO
    AI_AVAILABLE = True
except ImportError:
    AI_AVAILABLE = False
    requests = None

# ì„¤ì • íŒŒì¼ ë¡œë“œ
def load_config(config_path=None):
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    if config_path is None:
        config_path = os.environ.get("CONFIG_FILE", "Config/config.json")
    if not os.path.exists(config_path):
        config_path = "Config/config.example.json"

    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def load_ranking_config(config_path=None):
    """ë­í‚¹ ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    if config_path is None:
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ CONFIG_FILEì„ ì½ê³  ranking_configë¡œ ë³€í™˜
        config_file = os.environ.get("CONFIG_FILE", "Config/config.json")
        # config.json -> ranking_config.json, config1.json -> ranking_config1.json
        config_path = config_file.replace("config", "ranking_config")

    if not os.path.exists(config_path):
        print(f"[WARNING] ë­í‚¹ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
        return {
            "ranking_settings": {
                "group_size": 3,
                "ranking_display_duration": 2.5,
                "title_position": "top_center",
                "ranking_position": "center",
                "transition_effect": "fade",
                "transition_duration": 0.5,
                "add_sound_effects": False
            },
            "overlay_settings": {
                "title": {
                    "font_size": 60,
                    "font_color": "white",
                    "keyword_color": "yellow",
                    "font_family": "Arial-Bold",
                    "position": "top",
                    "margin_top": 50
                },
                "ranking": {
                    "font_size": 100,
                    "font_family": "Impact",
                    "colors": {
                        "1": "#FFD700",
                        "2": "#C0C0C0",
                        "3": "#CD7F32"
                    },
                    "word_font_size": 50,
                    "word_color": "white",
                    "stroke_color": "black",
                    "stroke_width": 3
                }
            },
            "ai_settings": {
                "model": "gemini-1.5-flash",
                "temperature": 0.7
            }
        }

    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def get_random_background_music(music_dir="background music"):
    """background music í´ë”ì—ì„œ ëœë¤ ì˜¤ë””ì˜¤ íŒŒì¼ ì„ íƒ"""

    if not os.path.exists(music_dir):
        print(f"[WARNING] background music í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {music_dir}")
        return None

    audio_files = [
        f for f in os.listdir(music_dir)
        if f.lower().endswith((".mp3", ".wav", ".m4a", ".aac"))
    ]

    if not audio_files:
        print("[WARNING] background music í´ë”ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None

    selected = random.choice(audio_files)
    return os.path.join(music_dir, selected)


def get_random_highlight_music(music_dir="highlight music"):
    """highlight music í´ë”ì—ì„œ ëœë¤ ì˜¤ë””ì˜¤ íŒŒì¼ ì„ íƒ"""

    if not os.path.exists(music_dir):
        print(f"[WARNING] highlight music í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {music_dir}")
        return None

    audio_files = [
        f for f in os.listdir(music_dir)
        if f.lower().endswith((".mp3", ".wav", ".m4a", ".aac"))
    ]

    if not audio_files:
        print("[WARNING] highlight music í´ë”ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None

    selected = random.choice(audio_files)
    return os.path.join(music_dir, selected)


def get_random_highlight_emoji(emoji_dir="highlight emoji"):
    """highlight emoji í´ë”ì—ì„œ ëœë¤ PNG ì´ëª¨ì§€ ì„ íƒ"""

    if not os.path.exists(emoji_dir):
        print(f"[WARNING] highlight emoji í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {emoji_dir}")
        return None

    emoji_files = [
        f for f in os.listdir(emoji_dir)
        if f.lower().endswith((".png", ".jpg", ".jpeg"))
    ]

    if not emoji_files:
        print("[WARNING] highlight emoji í´ë”ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None

    selected = random.choice(emoji_files)
    return os.path.join(emoji_dir, selected)


def extract_key_moment_from_txt(video_path):
    """ë¹„ë””ì˜¤ì™€ ë™ì¼í•œ ì´ë¦„ì˜ txt íŒŒì¼ì—ì„œ Key moment/Most important timelineì„ ì´ˆ ë‹¨ìœ„ë¡œ ì¶”ì¶œ"""

    txt_path = os.path.splitext(video_path)[0] + ".txt"
    if not os.path.exists(txt_path):
        print(f"[HIGHLIGHT] Key moment í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {os.path.basename(txt_path)}")
        return None

    try:
        with open(txt_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"[WARNING] Key moment í…ìŠ¤íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

    pattern = re.compile(
        r'(?:Key moment|Most important timeline):\s*([0-9]{1,2}:[0-9]{2}|[0-9]+(?:\.[0-9]+)?)',
        flags=re.IGNORECASE
    )
    match = pattern.search(content)
    if not match:
        return None

    raw_value = match.group(1).strip()

    try:
        if ':' in raw_value:
            minutes, seconds = raw_value.split(':', 1)
            return int(minutes) * 60 + float(seconds)
        return float(raw_value)
    except ValueError:
        print(f"[WARNING] Key moment íŒŒì‹± ì‹¤íŒ¨: {raw_value}")
        return None


def create_highlight_ending(first_place_video_path, config):
    """
    1ìœ„ ë¹„ë””ì˜¤ì˜ í‚¤ ëª¨ë¨¼íŠ¸ë¥¼ ìº¡ì²˜í•´ì„œ highlight musicê³¼ í•¨ê»˜ ì—”ë”© í´ë¦½ ìƒì„±

    Args:
        first_place_video_path: 1ìœ„ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬

    Returns:
        ImageClip with audio (highlight music ê¸¸ì´ë§Œí¼)
    """
    from moviepy import ImageClip

    print("\n[HIGHLIGHT] í•˜ì´ë¼ì´íŠ¸ ì—”ë”© í´ë¦½ ìƒì„± ì¤‘...")

    # highlight music ì„ íƒ
    highlight_music_path = get_random_highlight_music()
    if not highlight_music_path:
        print("[WARNING] highlight musicì´ ì—†ì–´ ì—”ë”© í´ë¦½ì„ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None

    try:
        highlight_audio = AudioFileClip(highlight_music_path)
        highlight_duration = highlight_audio.duration
        print(f"[HIGHLIGHT] ìŒì•…: {os.path.basename(highlight_music_path)} ({highlight_duration:.1f}ì´ˆ)")
    except Exception as e:
        print(f"[WARNING] highlight music ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

    # 1ìœ„ ë¹„ë””ì˜¤ ë¡œë“œ
    try:
        first_video = VideoFileClip(first_place_video_path)

        # txt ë©”íƒ€ë°ì´í„°ì—ì„œ Key moment ì‹œì  ìš°ì„  ì‚¬ìš©
        key_moment_time = extract_key_moment_from_txt(first_place_video_path)

        if key_moment_time is not None:
            if key_moment_time >= first_video.duration:
                key_moment_time = max(0, first_video.duration - 0.1)
                print(f"[HIGHLIGHT] Key momentê°€ ì˜ìƒ ê¸¸ì´ë¥¼ ì´ˆê³¼í•´ {key_moment_time:.1f}ì´ˆë¡œ ì¡°ì •")
            else:
                print(f"[HIGHLIGHT] Key moment ë©”íƒ€ë°ì´í„° ì‚¬ìš©: {key_moment_time:.1f}ì´ˆ")
        else:
            # í‚¤ ëª¨ë¨¼íŠ¸ ì •ë³´ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            key_moment_time = min(3.0, first_video.duration * 0.3)
            print(f"[HIGHLIGHT] Key moment ì •ë³´ ì—†ìŒ â†’ {key_moment_time:.1f}ì´ˆ ì§€ì  ìº¡ì²˜")

        # í•´ë‹¹ ì‹œì ì˜ í”„ë ˆì„ ìº¡ì²˜
        frame = first_video.get_frame(key_moment_time)

        # ë¹„ë””ì˜¤ í¬ê¸° ì €ì¥
        video_width, video_height = first_video.size

        # ImageClip ìƒì„± (highlight music ê¸¸ì´ë§Œí¼)
        highlight_clip = ImageClip(frame, duration=highlight_duration)

        # ê²€ì€ìƒ‰ ë°˜íˆ¬ëª… ë ˆì´ì–´ ì¶”ê°€ (opacity 50%)
        black_overlay = ColorClip(
            size=(video_width, video_height),
            color=(0, 0, 0),
            duration=highlight_duration
        ).with_opacity(0.5)

        # ì´ëª¨ì§€ PNG ì¶”ê°€
        emoji_path = get_random_highlight_emoji()
        clips_to_composite = [highlight_clip, black_overlay]

        if emoji_path:
            try:
                from PIL import Image as PILImage
                import numpy as np

                # ì´ëª¨ì§€ ì´ë¯¸ì§€ ë¡œë“œ (RGBA ëª¨ë“œë¡œ ë³€í™˜í•˜ì—¬ íˆ¬ëª…ë„ ìœ ì§€)
                emoji_img = PILImage.open(emoji_path).convert("RGBA")

                # ì´ëª¨ì§€ í¬ê¸° ì¡°ì • (í™”ë©´ ë„ˆë¹„ì˜ 25%)
                emoji_width = int(video_width * 0.25)
                aspect_ratio = emoji_img.height / emoji_img.width
                emoji_height = int(emoji_width * aspect_ratio)
                emoji_img_resized = emoji_img.resize((emoji_width, emoji_height), PILImage.LANCZOS)

                # RGBA ë°°ì—´ë¡œ ë³€í™˜
                emoji_array = np.array(emoji_img_resized)

                # ImageClip ìƒì„± - RGBA ë°°ì—´ì„ ì§ì ‘ ì „ë‹¬í•˜ë©´ ìë™ìœ¼ë¡œ ì•ŒíŒŒ ì±„ë„ ì²˜ë¦¬
                emoji_clip = ImageClip(emoji_array, duration=highlight_duration, is_mask=False)

                # ìœ„ì¹˜: ìë§‰ ìœ„ì¹˜ì¯¤ (í™”ë©´ í•˜ë‹¨ì—ì„œ 450px ìœ„, ì¤‘ì•™)
                emoji_y = video_height - 450
                emoji_clip = emoji_clip.with_position(('center', emoji_y))

                clips_to_composite.append(emoji_clip)
                print(f"[HIGHLIGHT] ì´ëª¨ì§€ ì¶”ê°€: {os.path.basename(emoji_path)}")

            except Exception as e:
                print(f"[WARNING] ì´ëª¨ì§€ ì¶”ê°€ ì‹¤íŒ¨: {e}")

        # ì •ì§€í™”ë©´ + ê²€ì€ìƒ‰ ë ˆì´ì–´ + ì´ëª¨ì§€ í•©ì„±
        final_highlight = CompositeVideoClip(clips_to_composite)
        final_highlight = final_highlight.with_audio(highlight_audio)

        first_video.close()

        print(f"[HIGHLIGHT] ì—”ë”© í´ë¦½ ìƒì„± ì™„ë£Œ (ê²€ì€ìƒ‰ ì˜¤ë²„ë ˆì´ 50% + ì´ëª¨ì§€, {highlight_duration:.1f}ì´ˆ)")
        return final_highlight

    except Exception as e:
        print(f"[WARNING] í•˜ì´ë¼ì´íŠ¸ ì—”ë”© í´ë¦½ ìƒì„± ì‹¤íŒ¨: {e}")
        return None


def apply_background_music(video_clip, config):
    """ì™„ì„±ëœ ë­í‚¹ ë¹„ë””ì˜¤ì— í•­ìƒ ë°°ê²½ ìŒì•…ì„ ì…í˜€ì„œ ë°˜í™˜"""

    if video_clip.duration is None or video_clip.duration <= 0:
        print("[WARNING] ë¹„ë””ì˜¤ ê¸¸ì´ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ì–´ ë°°ê²½ ìŒì•…ì„ ì¶”ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return video_clip

    music_path = get_random_background_music()
    if not music_path:
        return video_clip

    # ë­í‚¹ ë¹„ë””ì˜¤ ë°°ê²½ ìŒì•… ë³¼ë¥¨ ê³ ì •
    background_music_volume = 0.5

    try:
        music_clip = AudioFileClip(music_path)
    except Exception as e:
        print(f"[WARNING] ë°°ê²½ ìŒì•… ë¡œë“œ ì‹¤íŒ¨ ({music_path}): {e}")
        return video_clip

    # ë°°ê²½ ìŒì•…ì€ ìµœëŒ€ 54.5ì´ˆê¹Œì§€ë§Œ ì¬ìƒ
    music_duration = min(video_clip.duration, 54.5)

    if music_clip.duration < music_duration:
        music_clip = music_clip.with_effects([AudioLoop(duration=music_duration)])

    music_clip = music_clip.subclipped(0, music_duration).with_start(0)

    if background_music_volume != 1.0:
        print(f"[AUDIO] ë°°ê²½ ìŒì•… ë³¼ë¥¨ ì¡°ì •: {background_music_volume:.2f}x")
        music_clip = music_clip.with_effects([MultiplyVolume(background_music_volume)])

    if video_clip.duration > 54.5:
        print(f"[MUSIC] ë­í‚¹ ë¹„ë””ì˜¤ì— ë°°ê²½ ìŒì•… ì¶”ê°€: {os.path.basename(music_path)} (54.5ì´ˆê¹Œì§€ë§Œ)")
    else:
        print(f"[MUSIC] ë­í‚¹ ë¹„ë””ì˜¤ì— ë°°ê²½ ìŒì•… ì¶”ê°€: {os.path.basename(music_path)}")

    base_audio = video_clip.audio
    if base_audio is None:
        # ì›ë³¸ ì˜¤ë””ì˜¤ê°€ ì—†ìœ¼ë©´ ë°°ê²½ ìŒì•…ë§Œ ì‚¬ìš©
        return video_clip.with_audio(music_clip)

    final_audio = CompositeAudioClip([base_audio, music_clip])
    return video_clip.with_audio(final_audio)

# 302.ai API ì´ˆê¸°í™”
def get_302ai_api_key():
    """302.ai API í‚¤ ê°€ì ¸ì˜¤ê¸° (ì„œë²„ í™˜ê²½ë³€ìˆ˜ ìš°ì„ )"""
    # ì„œë²„ì—ì„œ ì„¤ì •í•œ í™˜ê²½ë³€ìˆ˜ ìš°ì„  í™•ì¸
    api_key = os.environ.get("AI_302_API_KEY")

    if not api_key:
        # config.jsonì—ì„œ ì½ê¸°
        try:
            config = load_config()
            api_key = config.get("ai_settings", {}).get("api_key", "")
        except:
            pass

    return api_key

def extract_video_frames(video_path, num_frames=3):
    """ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ì„ ì¶”ì¶œí•˜ì—¬ base64 ì¸ì½”ë”©"""
    try:
        video = VideoFileClip(video_path)
        duration = video.duration
        frames_base64 = []

        # ë¹„ë””ì˜¤ë¥¼ ê· ë“±í•˜ê²Œ ë‚˜ëˆ„ì–´ í”„ë ˆì„ ì¶”ì¶œ
        for i in range(num_frames):
            timestamp = (i + 1) * duration / (num_frames + 1)
            frame = video.get_frame(timestamp)

            # numpy arrayë¥¼ PIL Imageë¡œ ë³€í™˜
            from PIL import Image as PILImage
            import numpy as np
            pil_image = PILImage.fromarray(frame.astype('uint8'), 'RGB')

            # ì´ë¯¸ì§€ í¬ê¸° ì¤„ì´ê¸° (512x512)
            pil_image.thumbnail((512, 512), PILImage.LANCZOS)

            # base64 ì¸ì½”ë”©
            buffered = BytesIO()
            pil_image.save(buffered, format="JPEG", quality=85)
            img_str = base64.b64encode(buffered.getvalue()).decode()
            frames_base64.append(f"data:image/jpeg;base64,{img_str}")

        video.close()
        return frames_base64
    except Exception as e:
        print(f"[ERROR] í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return []

# ë¹„ë””ì˜¤ íŒŒì¼ ìŠ¤ìº”
def scan_video_files(output_dir):
    """Output í´ë”ì—ì„œ ì™„ì„±ëœ ì˜ìƒ íŒŒì¼ ìŠ¤ìº”"""
    supported_extensions = ('.mp4', '.mov', '.mkv', '.avi', '.m4v', '.webm')
    video_files = []

    if not os.path.exists(output_dir):
        print(f"[ERROR] Output í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {output_dir}")
        return []

    for file in os.listdir(output_dir):
        if file.lower().endswith(supported_extensions):
            # ì´ë¯¸ ë­í‚¹ ì˜ìƒì¸ ê²½ìš° ì œì™¸
            if file.startswith('ranking_'):
                continue
            # description íŒŒì¼ ì œì™¸
            if file.endswith('.txt'):
                continue

            full_path = os.path.join(output_dir, file)
            if os.path.isfile(full_path):
                video_files.append(full_path)

    # íŒŒì¼ ìˆ˜ì • ì‹œê°„ ê¸°ì¤€ ì •ë ¬ (ì˜¤ë¦„ì°¨ìˆœ - ìµœì‹  íŒŒì¼ì´ ë§ˆì§€ë§‰ = 1ìœ„)
    video_files.sort(key=lambda x: os.path.getmtime(x), reverse=False)

    print(f"\n[SCAN] {len(video_files)}ê°œì˜ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    for i, video in enumerate(video_files, 1):
        print(f"  {i}. {os.path.basename(video)}")

    return video_files

# ë¹„ë””ì˜¤ ê·¸ë£¹í•‘
def group_videos(video_files, group_size=3):
    """ë¹„ë””ì˜¤ë¥¼ Nê°œì”© ê·¸ë£¹í•‘"""
    groups = []
    for i in range(0, len(video_files), group_size):
        group = video_files[i:i + group_size]
        if len(group) == group_size:
            groups.append(group)
        else:
            print(f"\n[WARNING] ê·¸ë£¹ {len(groups) + 1}ì€ {len(group)}ê°œì˜ ì˜ìƒë§Œ ìˆì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
            print(f"  ì˜ìƒ: {[os.path.basename(v) for v in group]}")

    return groups

# AI ê¸°ë°˜ ê³µí†µ ì£¼ì œ ë¶„ì„ (302.ai API ì‚¬ìš©)
def analyze_common_theme(video_group, ranking_config):
    """302.ai Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê³µí†µ ì£¼ì œ ë¶„ì„ (ë¹„ë””ì˜¤ í”„ë ˆì„ ê¸°ë°˜)"""
    if not AI_AVAILABLE:
        # AI ì‚¬ìš© ë¶ˆê°€ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return "EPIC CLIPS", "EPIC"

    api_key = get_302ai_api_key()
    if not api_key:
        print("[WARNING] AI_302_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return "EPIC CLIPS", "EPIC"

    num_videos = len(video_group)
    print(f"\n[AI] {num_videos}ê°œ ì˜ìƒì—ì„œ í”„ë ˆì„ ì¶”ì¶œ ë° 302.ai APIë¡œ ë¶„ì„ ì¤‘...")

    # config.json ë¡œë“œ
    config = load_config()
    language = config.get("voice_settings", {}).get("language", "en")
    base_url = config.get("ai_settings", {}).get("base_url", "https://api.302.ai/v1")
    model_name = ranking_config.get("ai_settings", {}).get("model", "gemini-2.5-flash")
    temperature = ranking_config.get("ai_settings", {}).get("temperature", 0.7)

    # ê° ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ ì¶”ì¶œ
    all_frames = []
    for i, video_path in enumerate(video_group, 1):
        print(f"  [{i}/{num_videos}] í”„ë ˆì„ ì¶”ì¶œ ì¤‘: {os.path.basename(video_path)}")
        frames = extract_video_frames(video_path, num_frames=2)  # ê° ë¹„ë””ì˜¤ì—ì„œ 2 í”„ë ˆì„
        if frames:
            all_frames.extend(frames)
            print(f"  âœ… {len(frames)}ê°œ í”„ë ˆì„ ì¶”ì¶œ ì™„ë£Œ")
        else:
            print(f"  [WARNING] í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨")

    if not all_frames:
        print("[WARNING] í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
        return "EPIC CLIPS", "EPIC"

    # ì–¸ì–´ë³„ í”„ë¡¬í”„íŠ¸
    if language == "ko":
        text_prompt = f"""{num_videos}ê°œì˜ ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ë³´ê³  ì´ë“¤ì˜ **ì‹¤ì œ ê³µí†µì **ì„ ì°¾ì•„ ì£¼ì œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

ì¤‘ìš” ì§€ì¹¨:
1. ë¹„ë””ì˜¤ì˜ **ì‹¤ì œ ë‚´ìš©**ì„ ë³´ê³  êµ¬ì²´ì ì¸ ê³µí†µ ì£¼ì œë¥¼ ì°¾ìœ¼ì„¸ìš”
2. ì˜ˆì‹œ:
   - ëª¨ë‘ ìŠ¤í¬ì¸  ì‹¤ìˆ˜ â†’ "ìŠ¤í¬ì¸  ì‹¤ìˆ˜"
   - ëª¨ë‘ ìŒì‹ ê´€ë ¨ ì‹¤ìˆ˜ â†’ "ìš”ë¦¬ ëŒ€ì°¸ì‚¬"
   - ëª¨ë‘ ì¹´ë¥´ë§ˆ/ë³µìˆ˜ â†’ "ì¦‰ê°ì ì¸ ì¹´ë¥´ë§ˆ"
   - ëª¨ë‘ ì˜ˆìƒì¹˜ ëª»í•œ ê²°ê³¼ â†’ "ì˜ˆìƒ ì™¸ ê²°ë§"
   - ëª¨ë‘ ì¹œêµ¬ ê´€ë ¨ â†’ "ìš°ì • ë°°ì‹ "
   - ëª¨ë‘ í• ì•„ë²„ì§€/ë…¸ì¸ â†’ "í• ì•„ë²„ì§€ ì¥ë‚œ"
3. **ì ˆëŒ€** ì¼ë°˜ì ì¸ ë‹¨ì–´ëŠ” í”¼í•˜ì„¸ìš”: ëŒ€ë°•, ìˆœê°„, ì›ƒê¸´, í´ë¦½, ì˜ìƒ ë“±
4. 2-3ê°œì˜ **êµ¬ì²´ì ì¸** í•œêµ­ì–´ ë‹¨ì–´ë¡œ ìš”ì•½
5. "ìˆœê°„"ì´ë¼ëŠ” ë‹¨ì–´ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš” (ë‚˜ì¤‘ì— ìë™ìœ¼ë¡œ ì¶”ê°€ë¨)
6. ê°•ì¡°í•  í•µì‹¬ í‚¤ì›Œë“œ 1ê°œ ì¶”ì¶œ

ì¶œë ¥ í˜•ì‹ (JSON):
{{
  "theme": "ì¦‰ê°ì ì¸ ì¹´ë¥´ë§ˆ",
  "keyword": "ì¹´ë¥´ë§ˆ"
}}

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ í•„ìš” ì—†ìŠµë‹ˆë‹¤."""
    else:  # ì˜ì–´
        text_prompt = f"""Look at the frames from {num_videos} videos and find their **actual commonalities** to extract a theme.

Important Instructions:
1. Look at the **actual content** to find specific common themes
2. Examples:
   - All sports fails â†’ "SPORTS FAILS"
   - All food-related mistakes â†’ "FOOD DISASTERS"
   - All karma/revenge â†’ "INSTANT KARMA"
   - All unexpected outcomes â†’ "UNEXPECTED ENDINGS"
   - All friend-related â†’ "FRIENDSHIP BETRAYALS"
   - All grandfather/elderly â†’ "GRANDPA PRANKS"
3. **NEVER** use generic words: EPIC, MOMENTS, FUNNY, CLIPS, VIDEOS, etc.
4. Summarize in 2-3 **specific** English words (UPPERCASE)
5. NEVER include the word "MOMENTS" (it will be added automatically later)
6. Extract one core keyword to emphasize

Output Format (JSON):
{{
  "theme": "INSTANT KARMA",
  "keyword": "KARMA"
}}

Output JSON only. No other explanation needed."""

    # 302.ai API í˜¸ì¶œ
    try:
        url = f"{base_url}/chat/completions"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

        # ë©”ì‹œì§€ content êµ¬ì„± (í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ë“¤)
        content = [{"type": "text", "text": text_prompt}]
        for frame_data in all_frames:
            content.append({
                "type": "image_url",
                "image_url": {"url": frame_data}
            })

        data = {
            "model": model_name,
            "messages": [
                {
                    "role": "user",
                    "content": content
                }
            ],
            "temperature": temperature,
            "max_tokens": 500
        }

        print(f"\n[AI] 302.ai API í˜¸ì¶œ ì¤‘... (ëª¨ë¸: {model_name})")
        response = requests.post(url, headers=headers, json=data, timeout=60)
        response.raise_for_status()

        result_data = response.json()
        result_text = result_data["choices"][0]["message"]["content"].strip()

        # JSON ì½”ë“œ ë¸”ë¡ ì œê±°
        result_text = re.sub(r'^```json\s*', '', result_text)
        result_text = re.sub(r'\s*```$', '', result_text)

        result = json.loads(result_text)
        theme = result.get("theme", "EPIC CLIPS")
        keyword = result.get("keyword", "EPIC")

        print(f"\n[AI] ê³µí†µ ì£¼ì œ ë¶„ì„ ì™„ë£Œ:")
        print(f"  ì£¼ì œ: {theme}")
        print(f"  í‚¤ì›Œë“œ: {keyword}")

        return theme, keyword

    except Exception as e:
        print(f"\n[WARNING] AI ì£¼ì œ ë¶„ì„ ì‹¤íŒ¨: {e}")
        print("  ê¸°ë³¸ê°’ ì‚¬ìš©: EPIC CLIPS")
        return "EPIC CLIPS", "EPIC"

# í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ìƒì„± (PIL ê¸°ë°˜)
def create_text_overlay_pil(text, width, height, font_size, color, stroke_color=None, stroke_width=0):
    """PILì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ìƒì„±"""
    # íˆ¬ëª… ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±
    img = Image.new('RGBA', (width, height), (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)

    # í°íŠ¸ ë¡œë“œ (ExtraBold ìš°ì„ )
    try:
        # macOS ê¸°ë³¸ í°íŠ¸ (í•œê¸€ ì§€ì› í°íŠ¸ ìš°ì„ , ExtraBold ì‚¬ìš©)
        font_candidates = [
            ("/System/Library/Fonts/Supplemental/AppleSDGothicNeo.ttc", [14], "AppleSDGothicNeo.ttc"),  # ExtraBold
            ("/System/Library/Fonts/AppleSDGothicNeo.ttc", [14, 6, 5], "AppleSDGothicNeo.ttc"),  # ExtraBold, Bold
            ("/Library/Fonts/AppleGothic.ttf", [0], "AppleGothic.ttf"),
            ("/System/Library/Fonts/Supplemental/Arial Unicode.ttf", [0], "Arial Unicode.ttf"),
            ("/System/Library/Fonts/Supplemental/Impact.ttf", [0], "Impact.ttf"),
            ("/System/Library/Fonts/Supplemental/Arial Bold.ttf", [0], "Arial Bold.ttf"),
        ]

        font = None
        for font_path, indexes, label in font_candidates:
            if not os.path.exists(font_path):
                continue

            for idx in indexes:
                try:
                    font = ImageFont.truetype(font_path, font_size, index=idx)
                    break
                except:
                    continue

            if font is not None:
                break

        if font is None:
            font = ImageFont.load_default()
    except:
        font = ImageFont.load_default()

    # í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚° ë° ìë™ ì¤„ë°”ê¿ˆ ì²˜ë¦¬
    bbox = draw.textbbox((0, 0), text, font=font)
    text_width = bbox[2] - bbox[0]
    text_height = bbox[3] - bbox[1]

    # í™”ë©´ ë„ˆë¹„ì˜ 90%ë¥¼ ìµœëŒ€ ë„ˆë¹„ë¡œ ì„¤ì •
    max_width = int(width * 0.9)

    # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì¤„ë°”ê¿ˆ ì²˜ë¦¬
    lines = []
    if text_width > max_width:
        words = text.split()
        current_line = ""

        for word in words:
            test_line = current_line + " " + word if current_line else word
            test_bbox = draw.textbbox((0, 0), test_line, font=font)
            test_width = test_bbox[2] - test_bbox[0]

            if test_width <= max_width:
                current_line = test_line
            else:
                if current_line:
                    lines.append(current_line)
                current_line = word

        if current_line:
            lines.append(current_line)
    else:
        lines = [text]

    # ì—¬ëŸ¬ ì¤„ì¸ ê²½ìš° ê° ì¤„ì˜ ë†’ì´ ê³„ì‚°
    if len(lines) > 1:
        line_height = text_height
        total_height = line_height * len(lines) + (len(lines) - 1) * 10  # ì¤„ ê°„ê²© 10px
        start_y = (height - total_height) // 2

        for i, line in enumerate(lines):
            line_bbox = draw.textbbox((0, 0), line, font=font)
            line_width = line_bbox[2] - line_bbox[0]
            x = (width - line_width) // 2
            y = start_y + i * (line_height + 10)

            # ì™¸ê³½ì„  ê·¸ë¦¬ê¸°
            if stroke_color and stroke_width > 0:
                for adj_x in range(-stroke_width, stroke_width + 1):
                    for adj_y in range(-stroke_width, stroke_width + 1):
                        draw.text((x + adj_x, y + adj_y), line, font=font, fill=stroke_color)

            # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
            draw.text((x, y), line, font=font, fill=color)
    else:
        # í•œ ì¤„ì¸ ê²½ìš° ê¸°ì¡´ ë¡œì§
        x = (width - text_width) // 2
        y = (height - text_height) // 2

        # ì™¸ê³½ì„  ê·¸ë¦¬ê¸°
        if stroke_color and stroke_width > 0:
            for adj_x in range(-stroke_width, stroke_width + 1):
                for adj_y in range(-stroke_width, stroke_width + 1):
                    draw.text((x + adj_x, y + adj_y), text, font=font, fill=stroke_color)

        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
        draw.text((x, y), text, font=font, fill=color)

    return img

# ë­í‚¹ ì˜¤ë²„ë ˆì´ í´ë¦½ ìƒì„±
def create_ranking_overlay(rank, video_width, video_height, duration, ranking_config, video_title=""):
    """ë­í‚¹ ì˜¤ë²„ë ˆì´ í´ë¦½ ìƒì„± (ë­í‚¹ ë²ˆí˜¸ + ë¹„ë””ì˜¤ ì œëª© í‘œì‹œ)"""

    overlay_config = ranking_config.get("overlay_settings", {}).get("ranking", {})

    # ë­í‚¹ ë²ˆí˜¸ ìƒ‰ìƒ (#1: ê¸ˆìƒ‰, #2: ì€ìƒ‰, #3: ë™ìƒ‰, #4: ì£¼í™©, #5: ë³´ë¼)
    colors = overlay_config.get("colors", {
        "1": "#FFD700",
        "2": "#C0C0C0",
        "3": "#CD7F32",
        "4": "#E67E22",
        "5": "#9B59B6"
    })
    rank_color = colors.get(str(rank), "#FFFFFF")

    # ë­í‚¹ ë²ˆí˜¸ + ë¹„ë””ì˜¤ ì œëª© í…ìŠ¤íŠ¸ (#5 She Tried the Messi Bowling Kick)
    rank_text = f"#{rank} {video_title}" if video_title else f"#{rank}"
    rank_font_size = overlay_config.get("font_size", 100)

    stroke_color = overlay_config.get("stroke_color", "black")
    stroke_width = overlay_config.get("stroke_width", 3)

    # ë­í‚¹ ë²ˆí˜¸ ì´ë¯¸ì§€ ìƒì„±
    rank_img = create_text_overlay_pil(
        rank_text,
        video_width,
        video_height // 3,
        rank_font_size,
        rank_color,
        stroke_color,
        stroke_width
    )

    # PIL Imageë¥¼ numpy arrayë¡œ ë³€í™˜
    import numpy as np
    img_array = np.array(rank_img)

    # ImageClip ìƒì„±
    from moviepy import ImageClip
    overlay_clip = ImageClip(img_array, duration=duration)
    overlay_clip = overlay_clip.with_position(('center', 'center'))

    # í˜ì´ë“œ íš¨ê³¼ëŠ” ì œê±° (ImageClipì—ì„œ ì§€ì›í•˜ì§€ ì•ŠìŒ)
    # í•„ìš”ì‹œ ë‚˜ì¤‘ì— opacity ì¡°ì ˆë¡œ êµ¬í˜„ ê°€ëŠ¥

    return overlay_clip

# ê³µí†µ íƒ€ì´í‹€ ì˜¤ë²„ë ˆì´ ìƒì„± (ê¸°ì¡´ - ì‚¬ìš© ì•ˆí•¨)
def create_title_overlay(theme, keyword, video_width, video_height, duration, ranking_config):
    """ê³µí†µ íƒ€ì´í‹€ ì˜¤ë²„ë ˆì´ ìƒì„± (TOP N XXX MOMENTS)"""

    title_config = ranking_config.get("overlay_settings", {}).get("title", {})
    group_size = ranking_config.get("ranking_settings", {}).get("group_size", 3)

    # ì–¸ì–´ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    language = ranking_config.get("voice_settings", {}).get("language", "en")

    # ì–¸ì–´ë³„ íƒ€ì´í‹€ ìƒì„±
    if language == "ko":
        # í•œêµ­ì–´: "ìˆœê°„" ì¤‘ë³µ ë°©ì§€
        if "ìˆœê°„" in theme:
            title_text = f"TOP {group_size} {theme}"
        else:
            title_text = f"TOP {group_size} {theme} ìˆœê°„"
    else:
        # ì˜ì–´: "MOMENTS" ì¤‘ë³µ ë°©ì§€
        if "MOMENTS" in theme.upper():
            title_text = f"TOP {group_size} {theme}"
        else:
            title_text = f"TOP {group_size} {theme} MOMENTS"

    font_size = title_config.get("font_size", 60)
    font_color = title_config.get("font_color", "white")
    keyword_color = title_config.get("keyword_color", "yellow")
    margin_top = title_config.get("margin_top", 20)  # ë” ìœ„ë¡œ ì˜¬ë¦¼ (50 â†’ 20)

    # íƒ€ì´í‹€ ì´ë¯¸ì§€ ìƒì„±
    title_img = create_text_overlay_pil(
        title_text,
        video_width,
        200,
        font_size,
        font_color,
        "black",
        8
    )

    import numpy as np
    img_array = np.array(title_img)

    from moviepy import ImageClip
    title_clip = ImageClip(img_array, duration=duration)
    title_clip = title_clip.with_position(('center', margin_top))

    return title_clip


# ì¸ë„¤ì¼ ì„¤ì • ê¸°ë°˜ íƒ€ì´í‹€ ì˜¤ë²„ë ˆì´ ìƒì„±
def create_thumbnail_title_overlay(thumbnail_config, video_width, video_height, duration):
    """ì›¹ì•±ì—ì„œ ì„¤ì •í•œ ì¸ë„¤ì¼ ì œëª©ìœ¼ë¡œ íƒ€ì´í‹€ ì˜¤ë²„ë ˆì´ ìƒì„± (ë‹¨ì–´ë³„ ìƒ‰ìƒ ì§€ì›, ìë™ í¬ê¸° ì¡°ì • ë° ì¤„ë°”ê¿ˆ)"""

    title_lines = thumbnail_config.get('title_lines', [])

    # ì˜¤ë²„ë ˆì´ ë†’ì´ (ìƒë‹¨ 35%)
    overlay_height = int(video_height * 0.35)

    # íˆ¬ëª… ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±
    img = Image.new('RGBA', (video_width, overlay_height), (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)

    # ìµœëŒ€ ë„ˆë¹„ (í™”ë©´ì˜ 90%)
    max_width = int(video_width * 0.9)

    # í°íŠ¸ ì„¤ì • í•¨ìˆ˜
    def load_font(font_size, font_path, index):
        try:
            return ImageFont.truetype(font_path, font_size, index=index)
        except:
            return ImageFont.load_default()

    # í°íŠ¸ í›„ë³´
    extrabold_font_candidates = [
        ("/System/Library/Fonts/Supplemental/AppleSDGothicNeo.ttc", [14], "AppleSDGothicNeo.ttc"),
        ("/System/Library/Fonts/AppleSDGothicNeo.ttc", [14, 6, 5], "AppleSDGothicNeo.ttc"),
        ("/Library/Fonts/AppleGothic.ttf", [0], "AppleGothic.ttf"),
        ("/System/Library/Fonts/Supplemental/AppleGothic.ttf", [0], "AppleGothic.ttf"),
        ("/System/Library/Fonts/Supplemental/Arial Bold.ttf", [0], "Arial Bold.ttf"),
    ]

    # ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸ ê²½ë¡œ ì°¾ê¸°
    font_path = None
    font_index = 0
    for path, indexes, label in extrabold_font_candidates:
        if os.path.exists(path):
            font_path = path
            font_index = indexes[0]
            print(f"[FONT] í°íŠ¸ ë¡œë“œ: {label}")
            break

    if not font_path:
        print("[FONT WARNING] ExtraBold í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©")

    # ê° ì¤„ ê·¸ë¦¬ê¸°
    y_positions = [int(overlay_height * 0.25), int(overlay_height * 0.6)]
    current_y_offset = 0  # ì¤„ë°”ê¿ˆìœ¼ë¡œ ì¸í•œ Y ìœ„ì¹˜ ì¡°ì •

    for line_idx, line in enumerate(title_lines):
        words = line.get('words', [])
        if not words:
            continue

        # ì´ˆê¸° í°íŠ¸ í¬ê¸° ì„¤ì •
        base_font_size = 105 if line_idx == 0 else 112
        min_font_size = 60  # ìµœì†Œ í°íŠ¸ í¬ê¸°
        spacing = 10

        # í°íŠ¸ í¬ê¸° ìë™ ì¡°ì •: í™”ë©´ì— ë§ì„ ë•Œê¹Œì§€ ì¤„ì´ê¸°
        font_size = base_font_size
        font = load_font(font_size, font_path, font_index) if font_path else ImageFont.load_default()

        # ì „ì²´ ì¤„ì˜ ë„ˆë¹„ ê³„ì‚°
        while font_size >= min_font_size:
            font = load_font(font_size, font_path, font_index) if font_path else ImageFont.load_default()

            total_width = 0
            word_widths = []
            for word in words:
                bbox = draw.textbbox((0, 0), word['text'], font=font)
                word_width = bbox[2] - bbox[0]
                word_widths.append(word_width)
                total_width += word_width

            total_width += spacing * (len(words) - 1)

            # í™”ë©´ì— ë§ìœ¼ë©´ ì¤‘ë‹¨
            if total_width <= max_width:
                break

            # í°íŠ¸ í¬ê¸° ì¤„ì´ê¸°
            font_size -= 5

        if font_size < min_font_size:
            font_size = min_font_size
            font = load_font(font_size, font_path, font_index) if font_path else ImageFont.load_default()

        print(f"[FONT] ë¼ì¸ {line_idx + 1} í°íŠ¸ í¬ê¸°: {font_size}px (ì „ì²´ ë„ˆë¹„: {total_width}px, ìµœëŒ€: {max_width}px)")

        # ì—¬ì „íˆ ë„ˆë¹„ ì´ˆê³¼ ì‹œ ë‹¨ì–´ë¥¼ ì—¬ëŸ¬ ì¤„ë¡œ ë‚˜ëˆ„ê¸°
        if total_width > max_width:
            print(f"[WRAP] ë¼ì¸ {line_idx + 1}ì´ í™”ë©´ì„ ì´ˆê³¼í•˜ì—¬ ì¤„ë°”ê¿ˆ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

            # ë‹¨ì–´ë¥¼ ì—¬ëŸ¬ ì¤„ë¡œ ë‚˜ëˆ„ê¸°
            lines_to_draw = []
            current_line_words = []
            current_line_width = 0

            for word_idx, word in enumerate(words):
                bbox = draw.textbbox((0, 0), word['text'], font=font)
                word_width = bbox[2] - bbox[0]

                test_width = current_line_width + word_width
                if current_line_words:
                    test_width += spacing

                if test_width <= max_width or not current_line_words:
                    current_line_words.append((word, word_width))
                    current_line_width = test_width
                else:
                    # í˜„ì¬ ì¤„ ì €ì¥í•˜ê³  ìƒˆ ì¤„ ì‹œì‘
                    lines_to_draw.append(current_line_words)
                    current_line_words = [(word, word_width)]
                    current_line_width = word_width

            # ë§ˆì§€ë§‰ ì¤„ ì¶”ê°€
            if current_line_words:
                lines_to_draw.append(current_line_words)

            # ì—¬ëŸ¬ ì¤„ ê·¸ë¦¬ê¸°
            y_pos = y_positions[line_idx] if line_idx < len(y_positions) else y_positions[-1]
            y_pos += current_y_offset
            line_height = int(font_size * 1.2)

            for sub_line_idx, sub_line in enumerate(lines_to_draw):
                # ì¤„ ë„ˆë¹„ ê³„ì‚°
                line_width = sum(w[1] for w in sub_line) + spacing * (len(sub_line) - 1)
                current_x = (video_width - line_width) // 2

                # ë‹¨ì–´ ê·¸ë¦¬ê¸°
                for word_data, word_width in sub_line:
                    word_text = word_data['text']
                    word_color = word_data.get('color', '#FFFFFF')

                    # ì™¸ê³½ì„ 
                    stroke_width = 8 if line_idx == 1 else 7
                    for offset_x in range(-stroke_width, stroke_width + 1):
                        for offset_y in range(-stroke_width, stroke_width + 1):
                            if offset_x != 0 or offset_y != 0:
                                draw.text((current_x + offset_x, y_pos + offset_y),
                                         word_text, font=font, fill='black')

                    # ì»¬ëŸ¬ í…ìŠ¤íŠ¸
                    draw.text((current_x, y_pos), word_text, font=font, fill=word_color)
                    current_x += word_width + spacing

                # ë‹¤ìŒ ì¤„ ìœ„ì¹˜
                y_pos += line_height

            # ë‹¤ìŒ ë¼ì¸ì„ ìœ„í•œ Y ì˜¤í”„ì…‹ ì¡°ì •
            current_y_offset += line_height * (len(lines_to_draw) - 1)

        else:
            # í•œ ì¤„ë¡œ ê·¸ë¦¬ê¸° (ê¸°ì¡´ ë¡œì§)
            y_pos = y_positions[line_idx] if line_idx < len(y_positions) else y_positions[-1]
            y_pos += current_y_offset

            current_x = (video_width - total_width) // 2

            for word_idx, word in enumerate(words):
                word_text = word['text']
                word_color = word.get('color', '#FFFFFF')

                # ì™¸ê³½ì„  íš¨ê³¼
                stroke_width = 8 if line_idx == 1 else 7
                for offset_x in range(-stroke_width, stroke_width + 1):
                    for offset_y in range(-stroke_width, stroke_width + 1):
                        if offset_x != 0 or offset_y != 0:
                            draw.text((current_x + offset_x, y_pos + offset_y),
                                     word_text, font=font, fill='black')

                # ì»¬ëŸ¬ í…ìŠ¤íŠ¸
                draw.text((current_x, y_pos), word_text, font=font, fill=word_color)

                # ë‹¤ìŒ ë‹¨ì–´ ìœ„ì¹˜ë¡œ ì´ë™
                current_x += word_widths[word_idx] + spacing

    # PIL Imageë¥¼ numpy arrayë¡œ ë³€í™˜
    import numpy as np
    img_array = np.array(img)

    # ImageClip ìƒì„±
    from moviepy import ImageClip
    title_clip = ImageClip(img_array, duration=duration)
    title_clip = title_clip.with_position(('center', 'top'))

    return title_clip

# ë­í‚¹ ë¹„ë””ì˜¤ ìƒì„±
def create_ranking_video(video_group, group_index, config, ranking_config):
    """Nê°œì˜ ë¹„ë””ì˜¤ë¥¼ ë­í‚¹ í˜•ì‹ìœ¼ë¡œ ë³‘í•©"""

    print(f"\n{'='*60}")
    print(f"[GROUP {group_index}] ë­í‚¹ ë¹„ë””ì˜¤ ìƒì„± ì‹œì‘")
    print(f"{'='*60}")

    # 1. AI ë¶„ì„
    print("\n[STEP 1] AI ë¶„ì„ ì¤‘...")
    theme, keyword = analyze_common_theme(video_group, ranking_config)

    # 2. ë¹„ë””ì˜¤ ë¡œë“œ ë° ìˆœì„œ ì •ë ¬ (ì—­ìˆœìœ¼ë¡œ: N -> ... -> 2 -> 1)
    print("\n[STEP 2] ë¹„ë””ì˜¤ ë¡œë“œ ì¤‘...")
    clips = []
    for i, video_path in enumerate(video_group):
        print(f"  ë¡œë“œ ì¤‘: {os.path.basename(video_path)}")
        clip = VideoFileClip(video_path)
        clips.append(clip)

    # 3. ë­í‚¹ ì˜¤ë²„ë ˆì´ ì¶”ê°€
    print("\n[STEP 3] ë­í‚¹ ì˜¤ë²„ë ˆì´ ì¶”ê°€ ì¤‘...")
    ranking_duration = ranking_config.get("ranking_settings", {}).get("ranking_display_duration", 2.5)
    group_size = ranking_config.get("ranking_settings", {}).get("group_size", 3)

    final_clips = []
    clip_durations = []  # ê° í´ë¦½ ê¸¸ì´ ì €ì¥
    for i, clip in enumerate(clips):
        rank = group_size - i  # 5 -> 4 -> 3 -> 2 -> 1

        # ë¹„ë””ì˜¤ ì œëª© ì¶”ì¶œ (íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°)
        video_path = video_group[i]
        video_title = os.path.splitext(os.path.basename(video_path))[0]

        print(f"  #{rank}: {clip.duration:.1f}ì´ˆ - {video_title}")

        # ë­í‚¹ ì˜¤ë²„ë ˆì´ ìƒì„±
        ranking_overlay = create_ranking_overlay(
            rank,
            int(clip.w),
            int(clip.h),
            ranking_duration,
            ranking_config,
            video_title
        )

        # í´ë¦½ì— ë­í‚¹ ì˜¤ë²„ë ˆì´ í•©ì„± (ì²˜ìŒ Nì´ˆë§Œ)
        if clip.duration > ranking_duration:
            overlay_part = CompositeVideoClip([
                clip.subclipped(0, ranking_duration),
                ranking_overlay
            ])
            remaining_part = clip.subclipped(ranking_duration, clip.duration)
            final_clip = concatenate_videoclips([overlay_part, remaining_part])
        else:
            final_clip = CompositeVideoClip([clip, ranking_overlay])

        final_clips.append(final_clip)
        clip_durations.append(clip.duration)  # ì›ë³¸ í´ë¦½ ê¸¸ì´ ì €ì¥

    # 4. ë¹„ë””ì˜¤ ë³‘í•©
    print("\n[STEP 4] ë¹„ë””ì˜¤ ë³‘í•© ì¤‘...")
    merged_video = concatenate_videoclips(final_clips, method="compose")

    # 5. ì¸ë„¤ì¼ ì„¤ì •ì—ì„œ íƒ€ì´í‹€ ì˜¤ë²„ë ˆì´ ì¶”ê°€
    print("\n[STEP 5] íƒ€ì´í‹€ ì˜¤ë²„ë ˆì´ ì¶”ê°€ ì¤‘...")

    # thumbnail_config.json ë¡œë“œ
    from create_thumbnail import load_thumbnail_config
    thumbnail_config = load_thumbnail_config()

    if thumbnail_config and 'title_lines' in thumbnail_config and len(thumbnail_config['title_lines']) > 0:
        print("  ì›¹ì•±ì—ì„œ ì„¤ì •í•œ ì¸ë„¤ì¼ ì œëª©ì„ ë¹„ë””ì˜¤ ì „ì²´ì— ì˜¤ë²„ë ˆì´í•©ë‹ˆë‹¤.")

        # ì „ì²´ ë¹„ë””ì˜¤ ê¸¸ì´ ë™ì•ˆ í‘œì‹œë˜ëŠ” íƒ€ì´í‹€ ìƒì„±
        title_overlay = create_thumbnail_title_overlay(
            thumbnail_config,
            int(merged_video.w),
            int(merged_video.h),
            merged_video.duration
        )

        # íƒ€ì´í‹€ ì˜¤ë²„ë ˆì´ í•©ì„±
        final_video = CompositeVideoClip([merged_video, title_overlay])
    else:
        print("  [WARNING] ì¸ë„¤ì¼ ì„¤ì •ì´ ì—†ì–´ íƒ€ì´í‹€ ì˜¤ë²„ë ˆì´ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        print("  ì›¹ì•±(http://192.168.0.8:3000)ì—ì„œ ì¸ë„¤ì¼ ì œëª©ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        final_video = merged_video

    # 6. í•˜ì´ë¼ì´íŠ¸ ì—”ë”© ì¶”ê°€ (1ìœ„ ë¹„ë””ì˜¤ì˜ í‚¤ ëª¨ë¨¼íŠ¸ + highlight music)
    first_place_video_path = video_group[-1]  # ì—­ìˆœì´ë¯€ë¡œ ë§ˆì§€ë§‰ì´ 1ìœ„
    highlight_ending = create_highlight_ending(first_place_video_path, config)

    if highlight_ending:
        print("\n[STEP 6] í•˜ì´ë¼ì´íŠ¸ ì—”ë”© ì¶”ê°€ ì¤‘...")
        final_video = concatenate_videoclips([final_video, highlight_ending], method="compose")
        print(f"  í•˜ì´ë¼ì´íŠ¸ ì—”ë”© ì¶”ê°€ ì™„ë£Œ (ì´ ê¸¸ì´: {final_video.duration:.1f}ì´ˆ)")

    # 6-1. ë°°ê²½ ìŒì•… í•­ìƒ ì¶”ê°€
    final_video = apply_background_music(final_video, config)

    # 7. ì €ì¥
    # ranking_configì—ì„œ output_dir ìš°ì„  í™•ì¸, ì—†ìœ¼ë©´ ê¸°ë³¸ config ì‚¬ìš©
    output_dir = ranking_config.get("ranking_settings", {}).get("output_dir") or config.get("paths", {}).get("output_dir", "Output")

    # ì¶œë ¥ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)

    # ì¸ë„¤ì¼ ì œëª©ì„ íŒŒì¼ëª… ì•ì— ì¶”ê°€ (ì¶©ëŒ ë°©ì§€)
    thumbnail_title = ""
    if thumbnail_config and 'title_lines' in thumbnail_config and len(thumbnail_config['title_lines']) > 0:
        # ì²« ë²ˆì§¸ íƒ€ì´í‹€ ë¼ì¸ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        title_text = thumbnail_config['title_lines'][0].get('text', '').strip()
        # íŒŒì¼ëª…ì— ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡ ì •ë¦¬ (ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ, íŠ¹ìˆ˜ë¬¸ì ì œê±°)
        thumbnail_title = title_text.replace(" ", "_").replace("/", "_").replace("\\", "_")
        # ì—°ì†ëœ ì–¸ë”ìŠ¤ì½”ì–´ë¥¼ í•˜ë‚˜ë¡œ
        while "__" in thumbnail_title:
            thumbnail_title = thumbnail_title.replace("__", "_")
        thumbnail_title = thumbnail_title.strip("_")

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    theme_slug = theme.lower().replace(" ", "_")

    # ì¸ë„¤ì¼ ì œëª©ì´ ìˆìœ¼ë©´ ë§¨ ì•ì— ì¶”ê°€
    if thumbnail_title:
        output_filename = f"{thumbnail_title}_ranking_{theme_slug}_{timestamp}.mp4"
    else:
        output_filename = f"ranking_{theme_slug}_{timestamp}.mp4"

    output_path = os.path.join(output_dir, output_filename)

    print(f"\n[STEP 7] ì €ì¥ ì¤‘: {output_filename}")
    print("  ë©”íƒ€ë°ì´í„°: CapCut ìŠ¤íƒ€ì¼ (Core Media Video/Audio, H.264 encoder)")

    # ë™ì‹œ ì¸ì½”ë”©ì„ ìœ„í•œ ì¸ìŠ¤í„´ìŠ¤ë³„ temp íŒŒì¼ëª…
    temp_dir = config.get("paths", {}).get("temp_dir", "Temp")
    temp_audio_file = os.path.join(temp_dir, f"temp-audio-ranking-{os.getpid()}.m4a")

    final_video.write_videofile(
        output_path,
        codec=config.get("audio_settings", {}).get("codec", "libx264"),
        audio_codec=config.get("audio_settings", {}).get("audio_codec", "aac"),
        fps=30,
        preset='medium',
        threads=2,  # FFmpeg ìŠ¤ë ˆë“œ ìˆ˜ ì œí•œ (ë™ì‹œ ì¸ì½”ë”© ëŒ€ì‘)
        temp_audiofile=temp_audio_file,
        remove_temp=True,
        ffmpeg_params=[
            '-metadata', 'handler_name=Core Media Video',
            '-metadata:s:a:0', 'handler_name=Core Media Audio',
            '-metadata', 'encoder=H.264',
            '-brand', 'qt',
        ]
    )

    # 8. description.txt ìƒì„±
    print("\n[STEP 8] description.txt ìƒì„± ì¤‘...")
    desc_filename = os.path.splitext(output_filename)[0] + ".txt"
    desc_path = os.path.join(output_dir, desc_filename)

    # ë­í‚¹ ë¹„ë””ì˜¤ ì„¤ëª… ìƒì„±
    group_size = ranking_config.get("ranking_settings", {}).get("group_size", 3)

    # MOMENTS ì¤‘ë³µ ë°©ì§€
    if "MOMENTS" in theme.upper():
        title_for_desc = f"TOP {group_size} {theme}"
    else:
        title_for_desc = f"TOP {group_size} {theme} MOMENTS"

    # ë­í‚¹ ë²ˆí˜¸ ëª©ë¡ ìƒì„± (5 -> 4 -> 3 -> 2 -> 1)
    ranking_list = "\n".join([f"#{i}" for i in range(group_size, 0, -1)])

    description_text = f"""{title_for_desc}

This compilation features the most {theme.lower()} from our recent videos. Watch as we count down from #{group_size} to #1!

{ranking_list}

Which moment was your favorite? Let us know in the comments!

#top{group_size} #{theme.lower().replace(' ', '')} #compilation #viral #trending"""

    try:
        with open(desc_path, 'w', encoding='utf-8') as f:
            f.write(description_text)
        print(f"  âœ… description.txt ì €ì¥: {desc_filename}")
    except Exception as e:
        print(f"  [WARNING] description.txt ì €ì¥ ì‹¤íŒ¨: {e}")

    # 9. ì •ë¦¬
    print("\n[CLEANUP] ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
    for clip in clips:
        clip.close()
    final_video.close()

    # 10. ì›ë³¸ ê°œë³„ ì˜ìƒ ë° txt íŒŒì¼ì„ before merge í´ë”ë¡œ ì´ë™
    print("\n[STEP 10] ì›ë³¸ ê°œë³„ ì˜ìƒì„ before merge í´ë”ë¡œ ì´ë™ ì¤‘...")

    # before merge í´ë” ê²½ë¡œ - video_groupì˜ ì²« ì˜ìƒì´ ìˆëŠ” Output ë””ë ‰í† ë¦¬ ê¸°ì¤€
    source_output_dir = os.path.dirname(video_group[0])  # Output, Output1, Output2 ë“±
    before_merge_dir = os.path.join(source_output_dir, "before merge")

    # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    if not os.path.exists(before_merge_dir):
        os.makedirs(before_merge_dir)
        print(f"  ğŸ“ í´ë” ìƒì„±: {before_merge_dir}")

    import shutil
    for video_path in video_group:
        try:
            # ì˜ìƒ íŒŒì¼ ì´ë™
            if os.path.exists(video_path):
                dest_video = os.path.join(before_merge_dir, os.path.basename(video_path))
                shutil.move(video_path, dest_video)
                print(f"  ğŸ“¦ ì´ë™ë¨: {os.path.basename(video_path)}")

            # ì—°ê´€ëœ txt íŒŒì¼ ì´ë™
            base_name = os.path.splitext(video_path)[0]
            txt_path = base_name + ".txt"
            if os.path.exists(txt_path):
                dest_txt = os.path.join(before_merge_dir, os.path.basename(txt_path))
                shutil.move(txt_path, dest_txt)
                print(f"  ğŸ“¦ ì´ë™ë¨: {os.path.basename(txt_path)}")

            # description.txt í˜•ì‹ë„ ì²´í¬
            desc_txt_path = base_name + "_description.txt"
            if os.path.exists(desc_txt_path):
                dest_desc = os.path.join(before_merge_dir, os.path.basename(desc_txt_path))
                shutil.move(desc_txt_path, dest_desc)
                print(f"  ğŸ“¦ ì´ë™ë¨: {os.path.basename(desc_txt_path)}")

        except Exception as e:
            print(f"  [WARNING] ì´ë™ ì‹¤íŒ¨: {os.path.basename(video_path)} - {e}")

    print(f"\n{'='*60}")
    print(f"[SUCCESS] ë­í‚¹ ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!")
    print(f"[OUTPUT] {output_path}")
    print(f"  âœ… ê°œë³„ ì˜ìƒ ë° txt íŒŒì¼ì„ before merge í´ë”ë¡œ ì´ë™ ì™„ë£Œ")
    print(f"{'='*60}\n")

    return output_path

# ë©”ì¸ í•¨ìˆ˜
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    print("\n" + "="*60)
    print("  ë­í‚¹ ì»´í•„ë ˆì´ì…˜ ë¹„ë””ì˜¤ ìƒì„±ê¸°")
    print("="*60 + "\n")

    # ì„¤ì • ë¡œë“œ
    config = load_config()
    ranking_config = load_ranking_config()

    # MoviePy ì„ì‹œ ë””ë ‰í† ë¦¬ë¥¼ ì¸ìŠ¤í„´ìŠ¤ë³„ë¡œ ë¶„ë¦¬ (ë™ì‹œ ì¸ì½”ë”© ëŒ€ì‘)
    temp_dir = config.get("paths", {}).get("temp_dir", "Temp")
    moviepy_temp_dir = os.path.join(temp_dir, f"moviepy_ranking_{os.getpid()}")
    os.makedirs(moviepy_temp_dir, exist_ok=True)
    os.environ["MOVIEPY_TEMP_DIR"] = moviepy_temp_dir
    print(f"[INIT] MoviePy temp ë””ë ‰í† ë¦¬: {moviepy_temp_dir}")

    # Output í´ë” ê²½ë¡œ
    output_dir = config.get("paths", {}).get("output_dir", "Output")

    # 1. ë¹„ë””ì˜¤ ìŠ¤ìº”
    video_files = scan_video_files(output_dir)

    if not video_files:
        print("\n[ERROR] ì²˜ë¦¬í•  ë¹„ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print(f"  Output í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”: {output_dir}")
        return

    # 2. ê·¸ë£¹í•‘
    group_size = ranking_config.get("ranking_settings", {}).get("group_size", 3)
    groups = group_videos(video_files, group_size)

    if not groups:
        print(f"\n[ERROR] {group_size}ê°œì”© ê·¸ë£¹ì„ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"  ìµœì†Œ {group_size}ê°œì˜ ë¹„ë””ì˜¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    print(f"\n[INFO] ì´ {len(groups)}ê°œì˜ ê·¸ë£¹ì„ ìƒì„±í•©ë‹ˆë‹¤.\n")

    # 3. ê° ê·¸ë£¹ì— ëŒ€í•´ ë­í‚¹ ë¹„ë””ì˜¤ ìƒì„±
    created_videos = []
    for i, group in enumerate(groups, 1):
        try:
            output_path = create_ranking_video(group, i, config, ranking_config)
            created_videos.append(output_path)
        except Exception as e:
            print(f"\n[ERROR] ê·¸ë£¹ {i} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            continue

    # 4. ìµœì¢… ê²°ê³¼
    print("\n" + "="*60)
    print(f"  ì „ì²´ ì‘ì—… ì™„ë£Œ!")
    print("="*60)
    print(f"\nìƒì„±ëœ ë­í‚¹ ë¹„ë””ì˜¤: {len(created_videos)}ê°œ\n")
    for i, video in enumerate(created_videos, 1):
        print(f"  {i}. {os.path.basename(video)}")
    print()

if __name__ == "__main__":
    main()
