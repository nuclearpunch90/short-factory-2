/**
 * AI Video Short-form Generator Routes
 * 
 * Handles:
 * - Image listing from video-sources folder
 * - Video generation with ByteDance Seedance
 * - Script generation with Gemini
 */
// Restart trigger for ffmpeg-static fix

import express from 'express';
import fs from 'fs/promises';
import fsSync from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import multer from 'multer';
import textToSpeech from '@google-cloud/text-to-speech';
import sdk from 'microsoft-cognitiveservices-speech-sdk';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const router = express.Router();

// Initialize Google TTS client
const ttsClient = new textToSpeech.TextToSpeechClient();

// Image source folder path
const IMAGE_SOURCE_PATH = path.join(__dirname, '../public/images/video-sources');
const OUTPUT_PATH = path.join(__dirname, '../Output/ai-videos');
const AUDIO_OUTPUT_PATH = path.join(__dirname, '../data/common/audio');

// Supported image extensions
const IMAGE_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.webp', '.gif'];

// Camera work prompts (unchanged)
const CAMERA_WORK_PROMPTS = {
    zoom_out: "Use the provided image strictly as the final frame. Camera originates above the scene and glides downward into the final frame at extremely slow cinematic speed. Camera performs a very slow, subtle zoom-out only. Food or subject must remain completely static, no morphing, no movement. Only camera moves. 8 seconds duration.",
    rotate: "Barely moving camera. Camera rotates only 10-15 degrees total throughout entire 8 second video. Not a turntable, object stays perfectly still. 35mm lens, 3:4 vertical aspect ratio. Subject must not move or deform at all.",
    zoom_in: "Very slow forward zoom in. Scale zoom from 1.0x to 1.2x over 8 seconds. Absolutely no object motion. Subject must remain completely static. Camera movement only, cinematic documentary style.",
    pan_down: "Camera starts above the scene and performs a linear vertical tracking move downward at an extremely slow, cinematic-documentary speed. Subject remains absolutely frozen in place. Only camera performs the movement. 8 seconds.",
    diagonal: "Camera originates outside the top-left area and moves diagonally from the bottom-left corner toward the top-right corner at extremely slow pace. The subject must remain perfectly stationary. Smooth, professional camera motion only. 8 seconds duration.",
    pan_right: "Camera starts from the left side and performs a linear horizontal tracking move from left to right at an extremely slow, cinematic-documentary speed. Subject remains absolutely frozen in place. Only camera performs the smooth horizontal movement. 8 seconds duration."
};

// Interior Mode Camera Prompts
const INTERIOR_CAMERA_WORK_PROMPTS = {
    zoom_out: "Start frame is the absolute reference. Strictly maintain all original furniture, lighting, and textures. Camera slowly zooms out. No new objects appearing. No morphing. High-fidelity architectural visualization.",
    rotate: "Keep all furniture and decor completely static. Camera moves in a subtle arc. Strictly preserve the original structure and layout. No new elements. maintain consistency with the start frame.",
    zoom_in: "Strictly adhere to the original image details. Camera slowly pushes in. Do not change any furniture designs. No hallucinations. Maintain perfect structural stability of the room.",
    pan_down: "Vertical scan of the room. Keep all original objects exactly as they are. No warping or adding items. Clean, stable, and professional architectural presentation.",
    diagonal: "Diagonal slide movement. Parallax effect only. Do not add or remove any objects. Strictly faithful to the original interior design. High geometric stability.",
    pan_right: "Horizontal tracking movement from left to right. Maintain all furniture and decor exactly as shown in the original image. No object morphing or hallucination. Clean architectural camera move preserving room integrity."
};

// Script styles (Updated to match Python source)
const SCRIPT_STYLES = {
    "Review": { korean: "ë¦¬ë·°í˜•", english: "Review", description: "ê°œì¸ì ì¸ ë°©ë¬¸ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ì§„ì†”í•œ ë¦¬ë·° ìŠ¤íƒ€ì¼" },
    "Promotional": { korean: "í™ë³´í˜•", english: "Promotional", description: "ë§¤ì¥ì˜ ì¥ì ì„ ê°•ì¡°í•˜ëŠ” ì§ì ‘ì ì¸ í™ë³´ ìŠ¤íƒ€ì¼" },
    "Storytelling": { korean: "ìŠ¤í† ë¦¬í…”ë§í˜•", english: "Storytelling", description: "ê°€ê²Œì˜ ìŠ¤í† ë¦¬ë‚˜ ì‚¬ì¥ë‹˜ì˜ ì´ì•¼ê¸°ë¥¼ ë‹´ì€ ê°ì„± ìŠ¤íƒ€ì¼" },
    "Tips": { korean: "íŒ/ì¶”ì²œí˜•", english: "Tips & Recommendation", description: "ê¿€íŒì´ë‚˜ ì¶”ì²œ ë©”ë‰´ë¥¼ ì†Œê°œí•˜ëŠ” ì •ë³´ ì œê³µ ìŠ¤íƒ€ì¼" },
    "HoneyTips": { korean: "ê¿€íŒ", english: "Honey Tips", description: "ìœ ìš©í•œ ê¿€íŒì„ í•µì‹¬ë§Œ ì™ì™ ë½‘ì•„ ì•Œë ¤ì£¼ëŠ” ìŠ¤íƒ€ì¼" },
    "Urgency": { korean: "ê¸´ê¸‰/FOMOí˜•", english: "Urgency/FOMO", description: "ì§€ê¸ˆ ê°€ì•¼ í•˜ëŠ” ì´ìœ ë¥¼ ê°•ì¡°í•˜ëŠ” ê¸´ë°•ê° ìˆëŠ” ìŠ¤íƒ€ì¼" },
    "Comparison": { korean: "ë¹„êµí˜•", english: "Comparison", description: "ë‹¤ë¥¸ ê³³ê³¼ ë¹„êµí•˜ë©° ì°¨ë³„ì ì„ ë¶€ê°í•˜ëŠ” ìŠ¤íƒ€ì¼" },
    "Question": { korean: "ì§ˆë¬¸í˜•", english: "Question", description: "ì‹œì²­ìì—ê²Œ ì§ˆë¬¸ì„ ë˜ì§€ë©° í˜¸ê¸°ì‹¬ì„ ìœ ë°œí•˜ëŠ” ìŠ¤íƒ€ì¼" },
    // Entertainment Styles
    "Humor/Gag": { korean: "ìœ ë¨¸/ê°œê·¸", english: "Humor/Gag", description: "ì¬ë¯¸ìˆê³  ì›ƒê¸´ ìš”ì†Œê°€ ê°•ì¡°ëœ ìŠ¤íƒ€ì¼" },
    "Information": { korean: "ì •ë³´ì „ë‹¬", english: "Information", description: "ìœ ìš©í•œ ì •ë³´ë‚˜ ì‚¬ì‹¤ì„ ì „ë‹¬í•˜ëŠ” ìŠ¤íƒ€ì¼" },
    "Ranking/Top 5": { korean: "ìˆœìœ„/ë­í‚¹", english: "Ranking/Top 5", description: "Top 5 ë“± ìˆœìœ„ë¥¼ ë§¤ê²¨ ì†Œê°œí•˜ëŠ” ìŠ¤íƒ€ì¼" },
    "Vlog": { korean: "ë¸Œì´ë¡œê·¸", english: "Vlog", description: "ì¼ìƒì ì¸ ì´ì•¼ê¸°ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í’€ì–´ë‚´ëŠ” ìŠ¤íƒ€ì¼" },
    "Reaction": { korean: "ë¦¬ì•¡ì…˜/í›„ê¸°", english: "Reaction", description: "ì° ë°˜ì‘ê³¼ ë¦¬ì–¼í•œ í›„ê¸°ë¥¼ ë‹´ì€ ìŠ¤íƒ€ì¼" },
    "Story/Rumor": { korean: "ì°/ìŠ¤í† ë¦¬", english: "Story/Rumor", description: "í¥ë¯¸ì§„ì§„í•œ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ëŠ” ìŠ¤íƒ€ì¼" }
};

// Intro styles (Updated to match Python source)
const INTRO_STYLES = {
    "ì¶©ê²©ì  ì‚¬ì‹¤í˜•": { english: "Shocking Fact", description: "ë†€ë¼ìš´ ì‚¬ì‹¤ë¡œ ì‹œì‘ (ì˜ˆ: ì•Œê³  ê³„ì…¨ë‚˜ìš”? ì´ ì§‘ì€...)" },
    "ì§ˆë¬¸ ë˜ì§€ê¸°í˜•": { english: "Question Hook", description: "ì‹œì²­ìì—ê²Œ ì§ˆë¬¸ ë˜ì§€ê¸° (ì˜ˆ: ì—¬ëŸ¬ë¶„ì€ ì–´ë–¤ ìŒì‹ ì¢‹ì•„í•˜ì„¸ìš”?)" },
    "ë†€ëŒ í›„í¬í˜•": { english: "Surprise Hook", description: "ê°íƒ„ì‚¬ë¡œ ì‹œì‘ (ì˜ˆ: ì™€, ì§„ì§œ ëŒ€ë°•ì´ì—ìš”!)" },
    "ì§€ì—­ ì¸ì¦í˜•": { english: "Local Authority", description: "ì§€ì—­ ì‚¬ëŒë“¤ì˜ ì¸ì • ê°•ì¡° (ì˜ˆ: ê³ ì–‘ì‹œ íƒì‹œ ê¸°ì‚¬ë‹˜ë“¤ì´ 1ë“±ìœ¼ë¡œ ë½‘ëŠ”ë‹¤ëŠ”...)" },
    "ì§ì„¤ì  ì†Œê°œí˜•": { english: "Direct Introduction", description: "ë°”ë¡œ ë³¸ë¡ ìœ¼ë¡œ ì‹œì‘ (ì˜ˆ: 40ë…„ ì „í†µì˜ í• ë§¤ ìˆœëŒ€êµ­, ë“œë””ì–´ ë°©ë¬¸í–ˆìŠµë‹ˆë‹¤!)" },
    "ë°©ë¬¸ ì¸ì¦í˜•": { english: "Visit Verification", description: "ë§¤ì¥ ìœ„ì¹˜ì™€ ì´ë¦„ì„ ì–¸ê¸‰í•˜ë©° ë°©ë¬¸ ì‚¬ì‹¤ì„ ì•Œë¦¬ë©° ì‹œì‘ (ì˜ˆ: ì˜¤ëŠ˜ì€ [ìœ„ì¹˜]ì— ìˆëŠ” [ê°€ê²Œì´ë¦„]ì— ë‹¤ë…€ì™”ëŠ”ë°ìš”...)" },
    // Entertainment Styles
    "ì‹œì„ ê°•íƒˆí˜•": { english: "Hook/Attention", description: "ì´ˆë°˜ 3ì´ˆ ì•ˆì— ì‹œì„ ì„ í™• ë„ëŠ” ë¹„ì£¼ì–¼ì´ë‚˜ ë©˜íŠ¸" },
    "ì§ˆë¬¸ìœ ë°œí˜•": { english: "Question/Curiosity", description: "ê¶ê¸ˆì¦ì„ ìì•„ë‚´ëŠ” ì§ˆë¬¸ìœ¼ë¡œ ì‹œì‘" },
    "ê²°ë¡ ì œì‹œí˜•": { english: "Conclusion First", description: "ê²°ê³¼ë¬¼ì´ë‚˜ ê²°ë¡ ì„ ë¨¼ì € ë³´ì—¬ì£¼ê³  ì‹œì‘" },
    "ìƒí™©ê·¹í˜•": { english: "Situation/Skit", description: "ì§§ì€ ìƒí™©ê·¹ìœ¼ë¡œ ì¬ë¯¸ìˆê²Œ ì‹œì‘" }
};

// Outro styles (Updated to match Python source)
const OUTRO_STYLES = {
    "ë¬¼ìŒí‘œ ë§ˆë¬´ë¦¬í˜•": { english: "Question Mark Ending", description: "ì¥ì†Œë¥¼ ë¬¼ìŒí‘œë¡œ ë§ˆë¬´ë¦¬ (ì˜ˆ: ë°°í„°ì§€ê²Œ ë¨¹ì„ ìˆ˜ ìˆëŠ” ì´ê³³ì€?)" },
    "ì¥ì  ê°•ì¡° ë¬¼ìŒí˜•": { english: "Benefits Question", description: "ë§¤ì¥ ì¥ì  ê°•ì¡° í›„ 'ì´ê³³ì€?'ìœ¼ë¡œ ë§ˆë¬´ë¦¬ (ì˜ˆ: ì‚¼ê²¹ì‚´ì„ ì €ë ´í•˜ê²Œ ë°°í„°ì§€ê²Œ ë¨¹ì„ ìˆ˜ ìˆëŠ” ì´ê³³ì€?)" },
    "ë¬¼ìŒí‘œ ì¥ë‚œí˜•": { english: "Playful Question", description: "ì¬ì¹˜ìˆëŠ” ì§ˆë¬¸ìœ¼ë¡œ ë§ˆë¬´ë¦¬ (ì˜ˆ: ì´ ê°€ê²©ì— ë­ ë‚¨ëŠ” ê²ƒ ìˆìœ¼ì„¸ìš”?)" },
    "ì¶”ì²œí˜•": { english: "Recommendation", description: "ì§ì ‘ì ì¸ ì¶”ì²œ (ì˜ˆ: ë“ ë“ í•œ í•œ ë¼ ìƒê°ë‚˜ë©´ ê¼­ ë“¤ëŸ¬ë³´ì„¸ìš”!)" },
    "í–‰ë™ ìœ ë„í˜•": { english: "Call to Action", description: "ë°©ë¬¸ ìœ ë„ (ì˜ˆ: ì—¬ëŸ¬ë¶„ë„ í•œë²ˆ ê°€ë³´ì‹œê¸¸ ì¶”ì²œë“œë¦½ë‹ˆë‹¤!)" },
    "ë°˜ì „ í™•ì‹ í˜•": { english: "Confident Conclusion", description: "í™•ì‹ ì„ ì£¼ëŠ” ë§ˆë¬´ë¦¬ (ì˜ˆ: ì§„ì§œ ì°ë§›ì§‘ ë§ë”ë¼ê³ ìš”!)" },
    // Entertainment Styles
    "êµ¬ë…/ì¢‹ì•„ìš” ìœ ë„": { english: "Subscribe/Like", description: "êµ¬ë…ê³¼ ì¢‹ì•„ìš”ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìš”ì²­" },
    "ë‹¤ìŒí™” ì˜ˆê³ ": { english: "Next Episode", description: "ë‹¤ìŒ ë‚´ìš©ì„ ì˜ˆê³ í•˜ë©° ê¸°ëŒ€ê° ì¡°ì„±" },
    "ëŒ“ê¸€ì°¸ì—¬ ìœ ë„": { english: "Comment Question", description: "ì‹œì²­ìì˜ ì˜ê²¬ì„ ë¬»ëŠ” ì§ˆë¬¸ìœ¼ë¡œ ëŒ“ê¸€ ìœ ë„" },
    "ìš”ì•½ì •ë¦¬": { english: "Summary", description: "í•µì‹¬ ë‚´ìš©ì„ ì§§ê²Œ ìš”ì•½í•˜ë©° ë§ˆë¬´ë¦¬" }
};

// Ensure output directory exists
async function ensureOutputDir() {
    try {
        await fs.mkdir(OUTPUT_PATH, { recursive: true });
    } catch (error) {
        console.error('Failed to create output directory:', error);
    }
}

// Ensure image source directory exists
async function ensureImageSourceDir() {
    try {
        await fs.mkdir(IMAGE_SOURCE_PATH, { recursive: true });
    } catch (error) {
        console.error('Failed to create image source directory:', error);
    }
}

// Multer configuration for image upload
const imageStorage = multer.diskStorage({
    destination: async (req, file, cb) => {
        try {
            if (!fsSync.existsSync(IMAGE_SOURCE_PATH)) {
                fsSync.mkdirSync(IMAGE_SOURCE_PATH, { recursive: true });
            }
            cb(null, IMAGE_SOURCE_PATH);
        } catch (error) {
            cb(error);
        }
    },
    filename: (req, file, cb) => {
        // Keep original filename but add timestamp to avoid conflicts
        const ext = path.extname(file.originalname);
        const name = path.basename(file.originalname, ext);
        // Sanitize filename to prevent OneDrive sync issues
        // Allow Korean, English, Numbers, Hyphen, Underscore
        const sanitizedName = name.replace(/[^a-zA-Z0-9ê°€-í£_-]/g, '').trim() || 'image';
        const timestamp = Date.now();
        cb(null, `${sanitizedName}_${timestamp}${ext}`);
    }
});

const imageUpload = multer({
    storage: imageStorage,
    limits: { fileSize: 50 * 1024 * 1024 }, // 50MB limit per file
    fileFilter: (req, file, cb) => {
        const allowedTypes = /jpeg|jpg|png|gif|webp/;
        const extname = allowedTypes.test(path.extname(file.originalname).toLowerCase());
        const mimetype = file.mimetype.startsWith('image/');
        if (extname && mimetype) {
            return cb(null, true);
        } else {
            cb(new Error('ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'));
        }
    }
});

// Upload images
router.post('/upload', imageUpload.array('images', 50), async (req, res) => {
    try {
        const files = req.files;
        if (!files || files.length === 0) {
            return res.status(400).json({ success: false, error: 'ì—…ë¡œë“œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.' });
        }

        console.log(`[AI Video] Uploaded ${files.length} images`);

        res.json({
            success: true,
            uploaded: files.length,
            files: files.map(f => ({
                name: f.filename,
                path: `/images/video-sources/${f.filename}`,
                size: f.size
            }))
        });
    } catch (error) {
        console.error('Image upload failed:', error);
        res.status(500).json({ success: false, error: error.message });
    }
});

// Delete image
router.post('/delete-image', async (req, res) => {
    try {
        const { imagePath } = req.body;

        if (!imagePath) {
            return res.status(400).json({ success: false, error: 'ì´ë¯¸ì§€ ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤.' });
        }

        // Clean the path and get the actual file path
        const cleanPath = imagePath.replace(/^\/+/, ''); // Remove leading slashes
        const actualPath = path.join(__dirname, '../public', cleanPath);

        // Check if file exists
        try {
            await fs.access(actualPath);
        } catch {
            return res.status(404).json({ success: false, error: 'íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.' });
        }

        // Delete the file
        await fs.unlink(actualPath);
        console.log(`[AI Video] Deleted image: ${actualPath}`);

        res.json({ success: true, message: 'ì´ë¯¸ì§€ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.' });
    } catch (error) {
        console.error('Image deletion failed:', error);
        res.status(500).json({ success: false, error: error.message });
    }
});

// Get list of images from video-sources folder
router.get('/images', async (req, res) => {
    try {
        // Ensure the source directory exists
        try {
            await fs.access(IMAGE_SOURCE_PATH);
        } catch {
            await fs.mkdir(IMAGE_SOURCE_PATH, { recursive: true });
            return res.json({ success: true, images: [] });
        }

        const files = await fs.readdir(IMAGE_SOURCE_PATH);
        const images = [];

        for (const file of files) {
            const ext = path.extname(file).toLowerCase();
            if (IMAGE_EXTENSIONS.includes(ext)) {
                const filePath = path.join(IMAGE_SOURCE_PATH, file);
                const stats = await fs.stat(filePath);

                images.push({
                    name: file,
                    path: `/images/video-sources/${file}`,
                    size: stats.size,
                    modified: stats.mtime
                });
            }
        }

        // Sort by modified date (newest first)
        images.sort((a, b) => new Date(b.modified) - new Date(a.modified));

        res.json({ success: true, images });
    } catch (error) {
        console.error('Failed to get images:', error);
        res.status(500).json({ success: false, error: error.message });
    }
});

// Generate script using Gemini
router.post('/generate-script', async (req, res) => {
    try {
        const { storeName, storeDescription, scriptStyle, introStyle, outroStyle } = req.body;

        if (!storeName) {
            return res.status(400).json({ success: false, error: 'Store name is required' });
        }

        const styleInfo = SCRIPT_STYLES[scriptStyle] || SCRIPT_STYLES.review;
        const introInfo = INTRO_STYLES[introStyle] || INTRO_STYLES.shocking;
        const outroInfo = OUTRO_STYLES[outroStyle] || OUTRO_STYLES.question_mark;

        const prompt = `You are a professional YouTube Shorts scriptwriter specializing in food and restaurant content.

## Input Information:
- Store/Product Name: ${storeName}
- Description: ${storeDescription || 'No additional description provided'}

## Script Style: ${styleInfo.korean}
${styleInfo.description}

## Intro Style:
${introInfo}

## Outro Style:
${outroInfo}

## Writing Guidelines:
1. Title: Create a click-worthy title (10-15 words in Korean)
2. Length: 35-50 seconds when read aloud (approximately 100-130 Korean characters)
3. Tone: Natural, conversational, casual speech - like talking to a friend
4. Use natural fillers like "ì§„ì§œ ëŒ€ë°•ì¸ ê²Œ", "ê·¼ë°", "ì†”ì§íˆ" sparingly
5. NO emojis (for TTS compatibility)
6. Mention the store name only ONCE
7. Make it engaging and authentic

## Output Format (JSON):
{
  "title": "ì˜ìƒ ì œëª©",
  "script": "ëŒ€ë³¸ ë‚´ìš©...",
  "description": "ì˜ìƒ ì„¤ëª… ë° í•´ì‹œíƒœê·¸"
}

Write the script in Korean:`;

        // Check for API key
        const apiKey = process.env.GEMINI_API_KEY || process.env.GOOGLE_API_KEY;

        if (!apiKey) {
            // Return a sample script if no API key
            const sampleScript = {
                title: `${storeName} ë¦¬ë·° - ì§„ì§œ ë§›ì§‘ì¸ì§€ í™•ì¸í•´ë´¤ìŠµë‹ˆë‹¤`,
                script: `ì—¬ëŸ¬ë¶„ ì˜¤ëŠ˜ ì§„ì§œ ëŒ€ë°•ì¸ ê³³ ë°œê²¬í–ˆì–´ìš”. ${storeName}ì¸ë°ìš”, ${storeDescription || 'ì—¬ê¸° ì§„ì§œ ë§›ìˆì–´ìš”'}. ì†”ì§íˆ ì²˜ìŒì—ëŠ” ë°˜ì‹ ë°˜ì˜í–ˆëŠ”ë° í•œì… ë¨¹ìë§ˆì 'ì•„ ì´ê±°ë‹¤' ì‹¶ë”ë¼ê³ ìš”. ê°€ê²©ë„ ì°©í•˜ê³  ì–‘ë„ í‘¸ì§í•˜ê³ , ì§„ì§œ ë§›ì§‘ ë§ë”ë¼ê³ ìš”. ì—¬ëŸ¬ë¶„ë„ í•œë²ˆ ê°€ë³´ì„¸ìš”!`,
                description: `#${storeName.replace(/\s/g, '')} #ë§›ì§‘ #ë¨¹ë°© #ë§›ì§‘ì¶”ì²œ #ë¦¬ë·°`
            };
            return res.json({ success: true, script: JSON.stringify(sampleScript, null, 2) });
        }

        // Call Gemini API
        // Call Gemini API (Using gemini-2.0-flash-exp as requested/latest)
        const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                contents: [{ parts: [{ text: prompt }] }],
                generationConfig: {
                    temperature: 0.8,
                    maxOutputTokens: 1024
                }
            })
        });

        const data = await response.json();

        if (!response.ok) {
            throw new Error(`Gemini API Error (${response.status}): ${data.error?.message || response.statusText}`);
        }

        if (data.promptFeedback?.blockReason) {
            throw new Error(`Script blocked by safety filters: ${data.promptFeedback.blockReason}`);
        }

        if (data.candidates && data.candidates[0]?.content?.parts?.[0]?.text) {
            const scriptText = data.candidates[0].content.parts[0].text;
            res.json({ success: true, script: scriptText });
        } else {
            console.error('Unexpected Gemini Response:', JSON.stringify(data, null, 2));
            throw new Error(`Invalid response structure from Gemini API: ${JSON.stringify(data)}`);
        }

    } catch (error) {
        console.error('Script generation failed:', error);
        res.status(500).json({ success: false, error: error.message });
    }
});

// Generate video from image using AI
router.post('/generate', async (req, res) => {
    try {
        const { imagePath, cameraWork, model, prompt, videoFilter, videoMode = 'restaurant' } = req.body;

        if (!imagePath || !cameraWork) {
            return res.status(400).json({ success: false, error: 'Image path and camera work are required' });
        }

        await ensureOutputDir();

        // Select prompt based on mode
        let cameraPrompt;
        if (videoMode === 'interior') {
            cameraPrompt = INTERIOR_CAMERA_WORK_PROMPTS[cameraWork] || prompt;
            console.log(`[AI Video] Using INTERIOR mode prompt for ${cameraWork}`);
        } else {
            cameraPrompt = CAMERA_WORK_PROMPTS[cameraWork] || prompt;
            console.log(`[AI Video] Using RESTAURANT mode prompt for ${cameraWork}`);
        }

        // Get the actual file path
        const actualImagePath = path.join(__dirname, '../public', imagePath);

        // Check if image exists
        try {
            await fs.access(actualImagePath);
        } catch {
            return res.status(404).json({ success: false, error: 'Image not found' });
        }

        // Generate output filename
        const rawImageName = path.basename(imagePath, path.extname(imagePath));
        // Sanitize image name for video output
        const imageName = rawImageName.replace(/[^a-zA-Z0-9ê°€-í£_-]/g, '').trim() || 'video';
        const timestamp = Date.now();

        // Add stratified sampling prefix if indices are provided
        const { imageIndex, variationIndex } = req.body;
        let prefix = "";
        if (imageIndex && variationIndex) {
            prefix = `${imageIndex}-${variationIndex}_`;
        }

        // Include mode in filename for easier debugging
        const modePrefix = videoMode === 'interior' ? 'interior_' : '';
        const outputFileName = `${prefix}${modePrefix}${imageName}_${cameraWork}_${timestamp}.mp4`;
        const outputPath = path.join(OUTPUT_PATH, outputFileName);

        // TODO: Integrate with actual ByteDance Seedance API
        // For now, return a placeholder response

        console.log(`[AI Video] Generating video:`);
        console.log(`  - Image: ${imagePath}`);
        console.log(`  - Camera Work: ${cameraWork}`);
        console.log(`  - Model: ${model}`);
        console.log(`  - Prompt: ${cameraPrompt.substring(0, 100)}...`);


        // Check for API key
        const apiKey = process.env.SEEDANCE_API_KEY || process.env.ARK_API_KEY;

        if (!apiKey) {
            return res.status(400).json({
                success: false,
                error: 'API key not configured. Please set SEEDANCE_API_KEY or ARK_API_KEY in your .env file.'
            });
        }

        // BytePlus ModelArk API endpoint  
        const apiEndpoint = 'https://ark.ap-southeast.bytepluses.com/api/v3/contents/generations/tasks';

        // Model name mapping
        const modelNames = {
            'seedance-1.5-pro': 'seedance-1-5-pro-251215',
            'seedance-1.0-pro-fast': 'seedance-1-0-pro-fast-251015',
            'seedance-1.0-lite': 'seedance-1-0-lite-i2v-250428',
            'seedance-1.0-pro': 'seedance-1-0-pro-250528'
        };
        const modelName = modelNames[model] || 'seedance-1-0-pro-fast-251015';

        // Create image URL (we need to serve the image or encode it)
        // For BytePlus, we'll use base64 data URL
        let imageDataUrl;
        try {
            const imageBuffer = await fs.readFile(actualImagePath);
            const imageBase64 = imageBuffer.toString('base64');
            const ext = path.extname(actualImagePath).toLowerCase();
            const mimeType = ext === '.png' ? 'image/png' : ext === '.webp' ? 'image/webp' : 'image/jpeg';
            imageDataUrl = `data:${mimeType};base64,${imageBase64}`;
        } catch (error) {
            return res.status(500).json({
                success: false,
                error: 'Failed to read image file: ' + error.message
            });
        }

        // Set resolution based on model (9:16 vertical for shorts)
        const isLiteModel = modelName.includes('lite'); // lite adapts to source; avoid forcing resolution
        const modelResolution = {
            'seedance-1-5-pro-251215': '720p',   // supports 480p/720p
            'seedance-1-0-pro-250528': '1080p',  // supports 480p/720p/1080p
            'seedance-1-0-pro-fast-251015': '720p' // not documented; use 720p for speed/cost balance
        };
        const resolution = modelResolution[modelName];
        const resolutionParams = isLiteModel
            ? '--ratio 9:16'
            : `--resolution ${resolution || '720p'} --ratio 9:16`;

        // Build prompt with parameters
        const promptWithParams = `${cameraPrompt} ${resolutionParams} --duration 2 --camerafixed false --watermark false`;

        try {
            // Create video generation task
            console.log(`[AI Video] Calling BytePlus ModelArk API...`);
            console.log(`[AI Video] Model: ${modelName}`);
            console.log(`[AI Video] Endpoint: ${apiEndpoint}`);

            const response = await fetch(apiEndpoint, {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${apiKey}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    model: modelName,
                    content: [
                        {
                            type: 'text',
                            text: promptWithParams
                        },
                        {
                            type: 'image_url',
                            image_url: {
                                url: imageDataUrl
                            }
                        }
                    ]
                })
            });

            const data = await response.json();
            console.log(`[AI Video] Response status: ${response.status}`);

            if (!response.ok) {
                console.error('[AI Video] API Error:', JSON.stringify(data, null, 2));
                return res.status(response.status).json({
                    success: false,
                    error: `BytePlus API error: ${data.message || data.error || JSON.stringify(data)}`,
                    details: data
                });
            }

            // Check if task was created successfully
            const taskId = data.id || data.task_id || data.req_id;
            if (taskId) {
                console.log(`[AI Video] Task created: ${taskId}`);

                // Poll for task completion
                const maxAttempts = 60; // 5 minutes max (5s intervals)
                let attempts = 0;
                let videoUrl = null;

                while (attempts < maxAttempts) {
                    attempts++;

                    // Wait 5 seconds before checking
                    await new Promise(resolve => setTimeout(resolve, 5000));

                    // Check task status
                    const statusResponse = await fetch(`${apiEndpoint}/${taskId}`, {
                        headers: {
                            'Authorization': `Bearer ${apiKey}`
                        }
                    });

                    const statusData = await statusResponse.json();
                    const status = statusData.status || statusData.task_status || statusData.state;
                    console.log(`[AI Video] Polling ${attempts}/${maxAttempts}: status=${status}`);

                    if (status === 'SUCCESS' || status === 'SUCCEEDED' || status === 'COMPLETED' || status === 'succeeded') {
                        // BytePlus API returns video URL in content.video_url field
                        videoUrl = (statusData.content && statusData.content.video_url) ||
                            (statusData.content && statusData.content[0] && statusData.content[0].video_url) ||
                            statusData.video_url ||
                            statusData.videoUrl;

                        if (videoUrl) {
                            console.log(`[AI Video] Video URL found: ${videoUrl}`);
                            break;
                        } else {
                            // Task succeeded but no video URL - log response for debugging
                            console.error('[AI Video] Task succeeded but no video URL found. Response:', JSON.stringify(statusData, null, 2));
                            return res.status(500).json({
                                success: false,
                                error: 'Video generation completed but no video URL was returned',
                                details: statusData
                            });
                        }
                    } else if (status === 'FAILED' || status === 'ERROR' || status === 'failed') {
                        console.error('[AI Video] Task failed:', statusData);
                        return res.status(500).json({
                            success: false,
                            error: 'Video generation failed on server',
                            details: statusData
                        });
                    }
                }

                if (!videoUrl) {
                    return res.status(408).json({
                        success: false,
                        error: 'Video generation timeout or video URL not found. Please try again.',
                        task_id: taskId
                    });
                }

                // Download the video to local storage
                console.log(`[AI Video] Downloading video from: ${videoUrl}`);
                const videoResponse = await fetch(videoUrl);

                if (!videoResponse.ok) {
                    throw new Error(`Failed to download video: ${videoResponse.status}`);
                }

                const videoBuffer = Buffer.from(await videoResponse.arrayBuffer());

                await fs.writeFile(outputPath, videoBuffer);
                console.log(`[AI Video] Video saved to: ${outputPath}`);

                // Appy Video Filter if requested
                if (videoFilter === 'western') {
                    console.log('[AI Video] Applying Western Filter...');
                    try {
                        const ffmpeg = (await import('fluent-ffmpeg')).default;
                        const tempFilteredPath = outputPath.replace('.mp4', '_filtered.mp4');

                        await new Promise((resolve, reject) => {
                            ffmpeg(outputPath)
                                .videoFilters('eq=contrast=1.15:saturation=1.2,colorbalance=rs=.05:bs=-.05')
                                .outputOptions('-c:a copy') // Copy audio if any (though AI video usually has none or we want to keep it)
                                .save(tempFilteredPath)
                                .on('end', async () => {
                                    // Replace original with filtered
                                    await fs.rename(tempFilteredPath, outputPath);
                                    console.log('[AI Video] Western Filter applied successfully');
                                    resolve();
                                })
                                .on('error', (err) => {
                                    console.error('[AI Video] Filter application failed:', err);
                                    // Continue with original video on error
                                    resolve();
                                });
                        });
                    } catch (filterErr) {
                        console.error('[AI Video] Filter setup failed:', filterErr);
                    }
                }

                res.json({
                    success: true,
                    videoPath: `/Output/ai-videos/${outputFileName}`,
                    task_id: taskId,
                    message: 'Video generated successfully'
                });

            } else {
                console.error('[AI Video] No task ID in response:', data);
                return res.status(500).json({
                    success: false,
                    error: 'Unexpected API response format - no task ID received',
                    details: data
                });
            }

        } catch (error) {
            console.error('[AI Video] Generation error:', error);
            return res.status(500).json({
                success: false,
                error: 'Video generation failed: ' + error.message
            });
        }


    } catch (error) {
        console.error('Video generation failed:', error);
        res.status(500).json({ success: false, error: error.message });
    }
});

// Get available models
router.get('/models', (req, res) => {
    res.json({
        success: true,
        models: [
            { id: 'seedance-1.0', name: 'Seedance 1.0', description: 'ë¹ ë¥¸ ìƒì„±, ì•ˆì •ì ' },
            { id: 'seedance-1.5', name: 'Seedance 1.5', description: 'ê³ í’ˆì§ˆ, ëŠë¦¼' }
        ]
    });
});

// Get camera work options
router.get('/camera-works', (req, res) => {
    res.json({
        success: true,
        cameraWorks: Object.entries(CAMERA_WORK_PROMPTS).map(([key, prompt]) => ({
            id: key,
            name: key.replace('_', ' ').replace(/\b\w/g, l => l.toUpperCase()),
            prompt
        }))
    });
});

// Ensure audio output directory exists
async function ensureAudioDir() {
    try {
        await fs.mkdir(AUDIO_OUTPUT_PATH, { recursive: true });
    } catch (error) {
        console.error('Failed to create audio output directory:', error);
    }
}

// Generate multiple scripts with new logic
router.post('/generate-scripts', async (req, res) => {
    try {
        const {
            restaurantName,
            description,
            styles,
            language,
            introStyle,
            outroStyle,
            location,
            locationIn,
            includeRestaurantName,

            mode = 'business',
            count = 1
        } = req.body;

        const actualCount = Math.min(Math.max(parseInt(count) || 1, 1), 10);

        const apiKey = process.env.GEMINI_API_KEY;
        if (!apiKey) {
            return res.status(500).json({ success: false, error: 'GEMINI_API_KEY is not set' });
        }

        console.log(`[Script Gen] Generating scripts for styles: ${styles.join(', ')}`);

        const results = {};

        // Helper to generate one script
        async function generateSingleScript(styleName) {
            // Find key by matching korean or english name
            const styleKey = Object.keys(SCRIPT_STYLES).find(key =>
                SCRIPT_STYLES[key].korean === styleName || SCRIPT_STYLES[key].english === styleName
            ) || styleName;

            // Construct Prompt
            let prompt = "";
            const introDesc = INTRO_STYLES[introStyle]?.description || "";
            const outroDesc = OUTRO_STYLES[outroStyle]?.description || "";

            // Determine language for prompt construction
            const isKorean = language === "Korean";
            const isEntertainment = mode === 'entertainment';

            if (isEntertainment) {
                // === ENTERTAINMENT MODE PROMPT ===
                if (isKorean) {
                    prompt = `ë‹¹ì‹ ì€ ìœ íŠœë¸Œ ì‡¼ì¸  ì „ë¬¸ ëŒ€ë³¸ ì‘ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ **ì£¼ì œ**ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¬ë¯¸ìˆê³  í¥ë¯¸ë¡œìš´ ì‡¼ì¸  ëŒ€ë³¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ì¤‘ìš” ì§€ì¹¨ (ì €ì‘ê¶Œ ë° ì‚¬ì‹¤ ê´€ê³„):**
ë§Œì•½ ì•„ë˜ 'ìƒì„¸ ë‚´ìš©/ê°€ì´ë“œ'ì— ì™„ì„±ëœ ëŒ€ë³¸ì´ë‚˜ êµ¬ì²´ì ì¸ ì •ë³´(íŒ, ìˆœì„œ ë“±)ê°€ ìˆë‹¤ë©´, **í•µì‹¬ ë‚´ìš©ê³¼ íŒ©íŠ¸ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€**í•˜ë˜ ë¬¸ì¥ ëë§ºìŒì´ë‚˜ ì—°ê²°ì–´ë§Œ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ë“¬ì–´ì£¼ì„¸ìš”. **ë‚´ìš©ì„ ê³¼ë„í•˜ê²Œ ë³€í˜•í•˜ê±°ë‚˜ ì—†ëŠ” ì‚¬ì‹¤ì„ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.**

**ì˜ìƒ ì •ë³´:**
- ì£¼ì œ/ì œëª©: ${includeRestaurantName ? restaurantName : "ë¹„ê³µê°œ (ëŒ€ë³¸/ì œëª©ì— ì–¸ê¸‰ ê¸ˆì§€)"} (ì´ê²ƒì„ ëŒ€ë³¸ì˜ í•µì‹¬ ì†Œì¬ë¡œ ì‚¬ìš©í•˜ì„¸ìš”)
- ìƒì„¸ ë‚´ìš©/ê°€ì´ë“œ: 
${description}

**ëŒ€ë³¸ ìŠ¤íƒ€ì¼:** ${styleName} (ì˜ˆ: ìŠ¤í† ë¦¬í…”ë§, ìœ ë¨¸, ì •ë³´ì „ë‹¬ ë“±)
**ì¸íŠ¸ë¡œ ìŠ¤íƒ€ì¼:** ${introStyle} (ì˜ˆ: ì¶©ê²©ì  ì‚¬ì‹¤, ì§ˆë¬¸ ë˜ì§€ê¸° ë“±)
**ì•„ì›ƒíŠ¸ë¡œ ìŠ¤íƒ€ì¼:** ${outroStyle} (ì˜ˆ: ë°˜ì „ í™•ì‹ í˜•, ì¶”ì²œí˜• ë“±)

**ì‘ì„± ê°€ì´ë“œë¼ì¸:**

0. **[ì¤‘ìš”] ì´ëª¨ì§€ ì ˆëŒ€ ê¸ˆì§€**:
   - ì œëª©ê³¼ ëŒ€ë³¸ ì–´ë””ì—ë„ ì´ëª¨ì§€(ğŸ˜Š, âœ¨, ğŸ‘ ë“±)ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
   - TTSê°€ ì´ëª¨ì§€ë¥¼ ì½ì§€ ëª»í•˜ê±°ë‚˜ ì´ìƒí•˜ê²Œ ì½ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

1. **ì œëª© ì‘ì„±**:
   - í´ë¦­ì„ ìœ ë„í•˜ëŠ” 20-30ì ë‚´ì™¸ì˜ ì„íŒ©íŠ¸ ìˆëŠ” ì œëª©
   - í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” í‘œí˜„ ì‚¬ìš©

2. **ëŒ€ë³¸ ë¶„ëŸ‰**: 35-50ì´ˆ ë‚´ì™¸ (ì•½ 150-180ì)
   - ëŠ˜ì–´ì§€ì§€ ì•Šê²Œ í•µì‹¬ë§Œ ì „ë‹¬
   - ìœ íŠœë¸Œ ì‡¼ì¸  íŠ¹ìœ ì˜ ë¹ ë¥¸ í˜¸í¡ ìœ ì§€

3. **ë§íˆ¬**: ìì—°ìŠ¤ëŸ¬ìš´ ì¼ìƒ ëŒ€í™”ì²´ êµ¬ì–´ì²´
   - "~í–ˆëŠ”ë°", "~í•˜ë”ë¼ê³ ìš”", "~ìŠµë‹ˆë‹¤", "~ê¸¸ë˜", "~ì¸ì§€" ê°™ì€ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ ì‚¬ìš©
   - ì‹¤ì œ ì‚¬ëŒì´ ë§í•˜ë“¯ì´ í¸ì•ˆí•˜ê³  ì¹œê·¼í•œ í†¤

4. **êµ¬ì¡°**:
   - **ì¸íŠ¸ë¡œ**: ${introStyle} ìŠ¤íƒ€ì¼ë¡œ ì‹œì‘ (ë„ˆë¬´ ê³¼ì¥ë˜ì§€ ì•Šê²Œ)
   - **ë³¸ë¬¸**: ${(styleKey === 'Ranking/Top 5' || styleKey === 'Tips' || styleKey === 'HoneyTips') ?
                            '**í•„ìˆ˜: ì¤„ê¸€(ë¬¸ë‹¨)ë¡œ ì“°ì§€ ë§ê³ , ë²ˆí˜¸ë¥¼ ë§¤ê²¨ì„œ "ì²«ì§¸, [ë‚´ìš©]", "ë‘˜ì§¸, [ë‚´ìš©]" í˜•ì‹ìœ¼ë¡œ ë”±ë”± ëŠì–´ì„œ ì‘ì„±í•  ê²ƒ. (ì…ë ¥ëœ íŒì˜ ê°œìˆ˜ì™€ ìˆœì„œë¥¼ ì •í™•íˆ ì§€í‚¬ ê²ƒ)**' :
                            `ì£¼ì œ(${includeRestaurantName ? restaurantName : "ì´ê³³"})ì— ëŒ€í•œ ì´ì•¼ê¸°. ì…ë ¥ëœ ë‚´ìš©ì´ ë¦¬ìŠ¤íŠ¸ë¼ë©´ ìˆœì„œì™€ íŒ©íŠ¸ë¥¼ ìœ ì§€.`}
   - **ì•„ì›ƒíŠ¸ë¡œ**: ${outroStyle} ìŠ¤íƒ€ì¼ë¡œ ê¹”ë”í•˜ê²Œ ë§ˆë¬´ë¦¬

5. **ì¤‘ìš” - ë‹´ë°±í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì–´ì¡°**:
   - "ì–´ë¨¸ ì„¸ìƒì—!", "ë‚œë¦¬ ë‚¬ì–´ìš”!" ê°™ì€ **ì§€ë‚˜ì¹œ í˜¸ë“¤ê°‘(ì˜¤ë²„ì•¡ì…˜) ê¸ˆì§€**.
   - ì¹œêµ¬ì—ê²Œ ì°¨ë¶„í•˜ê²Œ ì •ë³´ë¥¼ ê³µìœ í•˜ê±°ë‚˜ ì„¤ëª…í•˜ëŠ” ë“¯í•œ **ë‹´ë°±í•œ í†¤** ìœ ì§€.
   - ë¬¸ì¥ì€ "~ìŠµë‹ˆë‹¤", "~í•´ìš”", "~í•˜ë”ë¼ê³ ìš”" ë“±ìœ¼ë¡œ ê¹”ë”í•˜ê²Œ ëë§ºìŒ.
6. **[ê°€ê²Œ ì´ë¦„] ê°™ì€ ê´„í˜¸ë‚˜ í”Œë ˆì´ìŠ¤í™€ë” ì ˆëŒ€ ê¸ˆì§€**:
   - ê°€ê²Œ ì´ë¦„ì´ ì œê³µë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¹„ê³µê°œë¼ë©´, ì•„ì˜ˆ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.
   - ì–µì§€ë¡œ "[ê°€ê²Œ ì´ë¦„]"ì´ë¼ê³  ì“°ë©´ TTSê°€ ê·¸ëŒ€ë¡œ ì½ì–´ì„œ ë°©ì†¡ ì‚¬ê³ ê°€ ë‚©ë‹ˆë‹¤.
   - ${includeRestaurantName ? "ê°€ê²Œ ì´ë¦„(" + restaurantName + ")ì„ ìì—°ìŠ¤ëŸ½ê²Œ 1ë²ˆ ì •ë„ ì–¸ê¸‰í•˜ì„¸ìš”." : "ê°€ê²Œ ì´ë¦„ì„ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”."}


**ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ ì´ í˜•ì‹ì„ ë”°ë¼ì£¼ì„¸ìš”):**
ì œëª©: [ì—¬ê¸°ì— ì œëª© ì‘ì„±]

ëŒ€ë³¸: [ì—¬ê¸°ì— ëŒ€ë³¸ ì‘ì„±]

(ì„¤ëª…ì´ë‚˜ ì£¼ì„ ì—†ì´ ìœ„ í˜•ì‹ëŒ€ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”)`;
                } else {
                    prompt = `You are a professional YouTube Shorts scriptwriter. Create an engaging 35-50 second script based on the following **Topic**.

**IMPORTANT (Copyright Compliance):**
If the 'Details/Guide' below contains a full script or long text, you **MUST paraphrase or rewrite it slightly** to avoid copyright issues. Keep the core meaning and style, but change sentence structures and vocabulary to make it original.

**CRITICAL - LANGUAGE REQUIREMENT:**
- The input/description may be provided in Korean or other languages
- You MUST write the ENTIRE output (title + script) in ENGLISH ONLY
- NO mixing of languages allowed
- Translate the core concepts from the input, then write naturally in English

**Video Info:**
- Topic/Title: ${includeRestaurantName ? restaurantName : "Hidden (DO NOT mention name in title/script)"} (Use this as the core subject)
- Details/Guide: 
${description}

**Script Style:** ${styleName}
**Intro Style:** ${introStyle}
**Outro Style:** ${outroStyle}

**Guidelines:**

0. **[CRITICAL] NO EMOJIS**:
   - Do NOT use emojis (ğŸ˜Š, ğŸ”¥, etc.) in the title or script.
   - TTS cannot process emojis correctly. Keep it text-only.

1. **Title**: Catchy, click-worthy title (20-30 chars). NO emojis in title.
2. **Length**: 35-50 seconds (approx 100-130 words). Keep it snappy.
3. **Tone**: Conversational, engaging, typical YouTuber energy.
4. **Structure**:
   - **Intro**: Hook the viewer immediately using '${introStyle}' style.
   - **Body**: Develop the '${includeRestaurantName ? restaurantName : "hidden spot"}' topic. Expand on the details provided in '${description}' creatively.
   - **Outro**: Wrap up with a strong '${outroStyle}' ending.
5. **CRITICAL - ABSOLUTELY FORBIDDEN**:
   - **NO timestamps**: NEVER include (0-5s), (10-20 seconds), [15s], etc.
   - **NO emojis**: NEVER use ğŸ’ª, ğŸ”¥, âœ¨ anywhere in title or script.
   - **NO stage directions**: NEVER include (Visual: ...), (Cut to...), **(Scene: ...)**, etc.
   - NO scene descriptions: Write NARRATION ONLY - what will be SPOKEN
   - This is pure voice-over text for TTS, not a video script with directions
   
6. ${includeRestaurantName ? "Include the restaurant name naturally in the script (narration) at least once." : "Do NOT mention the restaurant name in the title or script."}

**Output Format:**
Title: [Write title here]

Script: [Write script here]

(No extra comments, just the format above. REMEMBER: English narration text ONLY!)`;
                }
            }
            else if (isKorean) {
                // === BUSINESS MODE PROMPT (Existing) ===
                // Korean Prompt Construction
                let locationInstruction = "";
                if (location) {
                    if (locationIn === "intro") {
                        locationInstruction = `
**ë§¤ì¥ ìœ„ì¹˜ ì •ë³´ (í•„ìˆ˜):**
- ìœ„ì¹˜: ${location}
- **ì¤‘ìš”**: ì¸íŠ¸ë¡œì—ì„œ ë°˜ë“œì‹œ ìœ„ì¹˜ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•´ì•¼ í•©ë‹ˆë‹¤.
- ì˜ˆì‹œ: "ì˜¤ëŠ˜ì€ ${location}ì— ìˆëŠ” ${includeRestaurantName ? restaurantName : 'ì´ê³³'}ì— ë‹¤ë…€ì™”ëŠ”ë°ìš”..", "${location}ì—ì„œ ì°¾ì€ ìˆ¨ì€ ë§›ì§‘..", "ì´ë²ˆì— ${location}ì— ê°”ë‹¤ê°€ ë°œê²¬í•œ.."
- ì¸íŠ¸ë¡œ ìŠ¤íƒ€ì¼(${introStyle})ì— ë§ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ìœ„ì¹˜ ì •ë³´ë¥¼ ë…¹ì—¬ë‚´ì„¸ìš”. íŠ¹ë³„íˆ '${introStyle}'ì¸ ê²½ìš° ìœ„ì¹˜ì™€ ê°€ê²Œ ì´ë¦„ì„ ì¸íŠ¸ë¡œ ì²« ë¬¸ì¥ì— ë°”ë¡œ ì–¸ê¸‰í•˜ì„¸ìš”.`;
                    } else { // outro
                        locationInstruction = `
**ë§¤ì¥ ìœ„ì¹˜ ì •ë³´ (í•„ìˆ˜):**
- ìœ„ì¹˜: ${location}
- **ì¤‘ìš”**: ì•„ì›ƒíŠ¸ë¡œì—ì„œ ë°˜ë“œì‹œ ìœ„ì¹˜ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•´ì•¼ í•©ë‹ˆë‹¤.
- ì˜ˆì‹œ: "${location}ì— 40ë…„ ì „í†µì„ ì´ì–´ê°€ëŠ” ì´ê³³ì€?", "${location}ì—ì„œ ê¼­ ê°€ë´ì•¼ í•  ë§›ì§‘ì€?", "${location} ë§›ì§‘ ì°¾ëŠ”ë‹¤ë©´ ë°”ë¡œ ì—¬ê¸°"
- ì•„ì›ƒíŠ¸ë¡œ ìŠ¤íƒ€ì¼(${outroStyle})ì— ë§ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ìœ„ì¹˜ ì •ë³´ë¥¼ ë…¹ì—¬ë‚´ì„¸ìš”.`;
                    }
                }

                prompt = `ë‹¹ì‹ ì€ ìœ íŠœë¸Œ ì‡¼ì¸  ì „ë¬¸ ëŒ€ë³¸ ì‘ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜ìƒ ì œëª©ê³¼ 35-50ì´ˆ ë¶„ëŸ‰ì˜ ì‡¼ì¸  ëŒ€ë³¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ì¤‘ìš” ì§€ì¹¨ (ì‚¬ì‹¤ ê´€ê³„ ìœ ì§€ ë° ë‹´ë°±í•œ í†¤):**
ì…ë ¥ëœ 'ì‹ë‹¹ ìƒì„¸ ì„¤ëª…'ì´ êµ¬ì²´ì ì¸ ì •ë³´ë‚˜ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¼ë©´, **ê·¸ ë‚´ìš©ì„ ì™œê³¡í•˜ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ì‚´ë ¤ì„œ** ìì—°ìŠ¤ëŸ½ê²Œ ì½ì„ ìˆ˜ ìˆê²Œë§Œ ë‹¤ë“¬ì–´ì£¼ì„¸ìš”. "ì–´ë¨¸!", "ëŒ€ë°•!" ê°™ì€ ê³¼ë„í•œ ì¶”ì„ìƒˆëŠ” ë¹¼ê³ , **ë‹´ë°±í•˜ê³  ì‹ ë¢°ê° ìˆê²Œ** ì‘ì„±í•´ì£¼ì„¸ìš”. ì—†ëŠ” ë‚´ìš©(ì§€ì–´ë‚¸ ì—í”¼ì†Œë“œ ë“±)ì€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.

**ì‹ë‹¹ ì •ë³´:**
- ê°€ê²Œ ì´ë¦„: ${includeRestaurantName ? restaurantName : "ë¹„ê³µê°œ (ëŒ€ë³¸/ì œëª©ì— ì–¸ê¸‰ ê¸ˆì§€)"}
- ì‹ë‹¹ ìƒì„¸ ì„¤ëª… (ì¥ì , ë¦¬ë·° ë“± í¬í•¨ ê°€ëŠ¥): 
${description}
${locationInstruction}

**ëŒ€ë³¸ ìŠ¤íƒ€ì¼:** ${styleName}

**ì¸íŠ¸ë¡œ ìŠ¤íƒ€ì¼:** ${introStyle}
- ${introDesc}

**ì•„ì›ƒíŠ¸ë¡œ ìŠ¤íƒ€ì¼:** ${outroStyle}
- ${outroDesc}

**ì‘ì„± ê°€ì´ë“œë¼ì¸:**

0. **[ì¤‘ìš”] ì´ëª¨ì§€ ì ˆëŒ€ ê¸ˆì§€**:
   - ì œëª©ê³¼ ëŒ€ë³¸ ì–´ë””ì—ë„ ì´ëª¨ì§€(ğŸ˜Š, âœ¨, ğŸ‘ ë“±)ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
   - TTSê°€ ì´ëª¨ì§€ë¥¼ ì½ì§€ ëª»í•˜ê±°ë‚˜ ì´ìƒí•˜ê²Œ ì½ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

1. ì œëª© ì‘ì„±:
   - í´ë¦­ì„ ìœ ë„í•˜ëŠ” ì„íŒ©íŠ¸ ìˆëŠ” ì œëª©
   - 20-30ì ë‚´ì™¸
   - í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” í‘œí˜„ ì‚¬ìš©
   - ì˜ˆ: "íƒì‹œê¸°ì‚¬ë‹˜ë“¤ë„ ì¸ì •í•˜ëŠ” ê³ ì–‘ ëˆê¹ŒìŠ¤ ì°ë§›ì§‘"

2. ëŒ€ë³¸ ë¶„ëŸ‰: 35-50ì´ˆì— ë§ê²Œ ì‘ì„± (ì•½ 150-170ì ë‚´ì™¸, ê³µë°± ì œì™¸)
   - êµ¬ì²´ì ì¸ ë””í…Œì¼ì„ í¬í•¨í•˜ë˜ ì¥í™©í•˜ì§€ ì•Šê²Œ
   - í•µì‹¬ ê²½í—˜ì„ ìƒë™ê° ìˆê²Œ ì „ë‹¬

3. ë§íˆ¬: ë‹´ë°±í•˜ê³  í¸ì•ˆí•œ êµ¬ì–´ì²´
   - ì§€ë‚˜ì¹œ ê°íƒ„ì‚¬ë‚˜ í˜¸ë“¤ê°‘("ì–´ë¨¸ ì„¸ìƒì—", "ë‚œë¦¬ ë‚¬ì–´ìš”") ì§€ì–‘
   - "~í–ˆëŠ”ë°", "~í•˜ë”ë¼ê³ ìš”", "~ìŠµë‹ˆë‹¤" ê°™ì´ ì°¨ë¶„í•˜ê²Œ ëë§ºìŒ
   - ê°ê´€ì ì¸ ì •ë³´ë¥¼ ì „ë‹¬í•  ë•ŒëŠ” ì‹ ë¢°ê° ìˆëŠ” í†¤ ìœ ì§€

4. ë‚´ìš©: ì…ë ¥ëœ ì •ë³´ë¥¼ ì¶©ì‹¤íˆ ë°˜ì˜
   - ì…ë ¥ëœ ë‚´ìš©ì˜ **ìˆœì„œë‚˜ íŒ©íŠ¸ë¥¼ ì„ì˜ë¡œ ë°”ê¾¸ì§€ ë§ ê²ƒ**
   - ë¶ˆí•„ìš”í•œ ë¯¸ì‚¬ì—¬êµ¬(í˜•ìš©ì‚¬ ë‚¨ë°œ) ìì œ

5. ${styleName} ìŠ¤íƒ€ì¼ì„ ì ìš©í•˜ë˜, ê¸°ë³¸ì ìœ¼ë¡œ ë“£ê¸° í¸ì•ˆí•œ í†¤ ìœ ì§€

6. ëŒ€ë³¸ êµ¬ì¡°:
   - **ì¸íŠ¸ë¡œ**: ${introStyle} ìŠ¤íƒ€ì¼ë¡œ ì‹œì‘ (ê°„ê²°í•˜ê²Œ)
   - **ë³¸ë¬¸**: ${(styleKey === 'Ranking/Top 5' || styleKey === 'Tips' || styleKey === 'HoneyTips') ?
                        '**í•„ìˆ˜: ë‚´ìš©ì„ ì¤„ê¸€ë¡œ ì“°ì§€ ë§ê³ , "ì²«ì§¸, [ë‚´ìš©]", "ë‘˜ì§¸, [ë‚´ìš©]" ì²˜ëŸ¼ ë²ˆí˜¸ë¥¼ ë¶™ì—¬ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ë§í•  ê²ƒ. (ìµœì†Œ 3ê°œ ì´ìƒì˜ í¬ì¸íŠ¸ë¡œ ì •ë¦¬)**' :
                        'í•µì‹¬ ê²½í—˜ê³¼ ì¥ì ì„ ëª…í™•í•˜ê²Œ ì „ë‹¬'}
   - **ì•„ì›ƒíŠ¸ë¡œ**: ${outroStyle} ìŠ¤íƒ€ì¼ë¡œ ë§ˆë¬´ë¦¬
   ${(outroStyle === 'ì¥ì  ê°•ì¡° ë¬¼ìŒí˜•' || outroStyle === 'ë¬¼ìŒí‘œ ë§ˆë¬´ë¦¬í˜•') ? '- **(ì¤‘ìš”)** ë°˜ë“œì‹œ ë¬¸ì¥ì˜ ë§¨ ë§ˆì§€ë§‰ì„ "ì´ê³³ì€ ì–´ë””ì¼ê¹Œìš”?"ê°€ ì•„ë‹Œ **"ì´ê³³ì€ ?"**ìœ¼ë¡œ ëë‚¼ ê²ƒ' : ''}

7. ì˜ìƒ ëŒ€ë³¸ìš©ìœ¼ë¡œ ì‘ì„± (ì§€ë¬¸ ì œì™¸, ìŠ¤í”¼í‚¹ í…ìŠ¤íŠ¸ë§Œ)

8. **ì¤‘ìš” - ì™„ì „í•œ ë¬¸ì¥**:
   - "ìµœê³ !", "ì¶”ì²œ!" ê°™ì€ ë‹¨ë‹µí˜• ëŒ€ì‹  "ì •ë§ ìµœê³ ì˜€ìŠµë‹ˆë‹¤.", "ê°•ë ¥ ì¶”ì²œí•©ë‹ˆë‹¤."ë¡œ ì„œìˆ ì–´ ì™„ê²°
   - **ì´ëª¨ì§€ë‚˜ íŠ¹ìˆ˜ë¬¸ì ì‚¬ìš© ê¸ˆì§€ (í…ìŠ¤íŠ¸ë§Œ ì‘ì„±)**

9. **[ê°€ê²Œ ì´ë¦„] ê°™ì€ í”Œë ˆì´ìŠ¤í™€ë” ì‚¬ìš© ê¸ˆì§€**:
   - ê°€ê²Œ ì´ë¦„ì´ ë¹„ê³µê°œì´ê±°ë‚˜ ë¬¸ë§¥ìƒ ë¶ˆí•„ìš”í•˜ë©´ ì•„ì˜ˆ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.
   - "[ê°€ê²Œ ì´ë¦„]", "[ìƒí˜¸ëª…]" ì´ë ‡ê²Œ ì“°ë©´ TTSê°€ ê·¸ëŒ€ë¡œ ì½ìœ¼ë¯€ë¡œ ì ˆëŒ€ ê¸ˆì§€ì…ë‹ˆë‹¤.
   - ${includeRestaurantName ? "ê°€ê²Œ ì´ë¦„(" + restaurantName + ")ì„ ìì—°ìŠ¤ëŸ½ê²Œ 1ë²ˆ ì •ë„ ì–¸ê¸‰í•˜ì„¸ìš”." : "ê°€ê²Œ ì´ë¦„ì„ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”."}

**ì˜ˆì‹œ ë§íˆ¬ (161ì):**
"ê³ ì–‘ì‹œ íƒì‹œ ê¸°ì‚¬ë‹˜ë“¤ì´ 1ë“±ìœ¼ë¡œ ë½‘ëŠ”ë‹¤ëŠ” ëˆê°€ìŠ¤ ë§›ì§‘ì…ë‹ˆë‹¤. ì‚¬ì´ì¦ˆê°€ ì‚¬ëŒ ì–¼êµ´ë³´ë‹¤ í›¨ì”¬ í¬ê¸¸ë˜ ë‘ê»˜ëŠ” ì–‡ê²Œ ì°Œí–ˆëŠ”ë° ë‘ê»˜ë„ ì ë‹¹íˆ ë‘ê»ê³  ê¸°ë¦„ë„ ì¢‹ì€ ê±° ì“°ëŠ”ì§€ ê¸°ë¦„ ëƒ„ìƒˆ 1ì¼ë„ ì•ˆ ë‚˜ê³  ê¹”ë”í•˜ê²Œ ë°”ì‚­í•˜ê³  ë§›ìˆìŠµë‹ˆë‹¤. ìˆ˜ì œ ì†ŒìŠ¤ë„ í›Œë¥­í•˜ê³  ì…€í”„ë°”ì—ì„œ ë°¥ì´ë‘ ìŠ¤í”„ ë°˜ì°¬ë“¤ê¹Œì§€ ì „ë¶€ ë¬´í•œì¸ ê²ƒë„ ì¢‹ë”ë¼ê³ ìš”."

**ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ ì´ í˜•ì‹ì„ ë”°ë¼ì£¼ì„¸ìš”):**
ì œëª©: [ì—¬ê¸°ì— ì œëª© ì‘ì„±]

ëŒ€ë³¸: [ì—¬ê¸°ì— ëŒ€ë³¸ ì‘ì„±]

**ì„¤ëª…ì´ë‚˜ ì£¼ì„ì€ ë¶ˆí•„ìš”í•©ë‹ˆë‹¤. ìœ„ í˜•ì‹ëŒ€ë¡œë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”.**`;

            } else {
                // English Prompt
                const introEng = INTRO_STYLES[introStyle]?.english || introStyle;
                const outroEng = OUTRO_STYLES[outroStyle]?.english || outroStyle;
                const styleEng = SCRIPT_STYLES[styleKey]?.english || styleName;

                let locationInstruction = "";
                if (location) {
                    if (locationIn === "intro") {
                        locationInstruction = `
**Restaurant Location (REQUIRED):**
- Location: ${location}
- **IMPORTANT**: You MUST naturally mention the location in the intro.
- Examples: "Today I visited this amazing restaurant in ${location}...", "Found this hidden gem in ${location}...", "Went to ${location} and discovered..."
- Blend the location naturally into the ${introEng} style.`;
                    } else { // outro
                        locationInstruction = `
**Restaurant Location (REQUIRED):**
- Location: ${location}
- **IMPORTANT**: You MUST naturally mention the location in the outro.
- Examples: "This 40-year tradition continues in ${location}, where is it?", "Must-visit spot in ${location}?", "If you're looking for great food in ${location}, this is it"
- Blend the location naturally into the ${outroEng} style.`;
                    }
                }

                prompt = `You are a professional YouTube Shorts scriptwriter. Create a video title and 35-50 second script based on the following information.

**IMPORTANT (Copyright Compliance):**
If the 'Restaurant Description' below contains a full script or long text, you **MUST paraphrase or rewrite it slightly** to avoid copyright issues. Keep the core meaning and style, but change sentence structures and vocabulary to make it original. Do not copy it verbatim.

**CRITICAL - LANGUAGE REQUIREMENT:**
- The input/description may be provided in Korean or other languages
- You MUST write the ENTIRE output (title + script) in ENGLISH ONLY
- NO mixing of languages allowed
- Translate the concepts naturally, maintaining the restaurant review tone

**Restaurant Information:**
- Restaurant Name: ${includeRestaurantName ? restaurantName : "Hidden (DO NOT mention name in title/script)"}
- Restaurant Description (detailed features, strengths, reviews):
${description}
${locationInstruction}

**Script Style:** ${styleEng}

**Intro Style:** ${introEng}
- ${introDesc}

**Outro Style:** ${outroEng}
- ${outroDesc}

**Writing Guidelines:**

0. **[CRITICAL] NO EMOJIS**:
   - Do NOT use emojis (ğŸ˜Š, ğŸ”¥, etc.) in the title or script.
   - TTS cannot process emojis correctly. Keep it text-only.

1. Title:
   - Create an attention-grabbing, click-worthy title
   - 10-15 words max
   - Use curiosity-inducing language
   - Example: "Taxi Drivers' #1 Pick: The Best Tonkatsu in Town"

2. Script Duration: 35-50 seconds (approximately 100-130 words)
   - Include specific details but stay focused
   - Deliver the core experience vividly

3. Tone: Natural, conversational, casual speech
   - Use everyday language like "so", "actually", "you know", "I mean"
   - Sound like a real person talking to a friend
   - Relaxed and authentic voice

4. Content: Detailed and specific descriptions
   - Include specific details about size, taste, atmosphere
   - Paint a vivid picture with concrete examples
   - Share personal observations and experiences

5. Match the ${styleEng} style

6. Script Structure:
   - **Intro**: Use ${introEng} style to grab viewer's attention
   - **Body**: Deliver core experience and strengths in detail
   - **Outro**: End with ${outroEng} style for strong impression

7. Consider this will be narrated over video

8. No emojis or special characters

9. **NO PLACEHOLDERS**:
   - NEVER use "[Restaurant Name]" or "[Store Name]" in the script.
   - If the name is hidden or not strictly needed, just omit it.
   - ${includeRestaurantName ? "Include the restaurant name (" + restaurantName + ") naturally at least once." : "Do NOT mention the restaurant name."}

**Example tone:**
"This is the tonkatsu place that Goyang taxi drivers voted number one. The portion size was way bigger than I expected - like, seriously huge compared to my face. I thought it would be thin, but it was actually pretty thick and crispy. The oil they use must be really good quality because there's zero greasy smell, and everything tastes so fresh and clean. The homemade sauce is excellent, and the self-service bar with unlimited rice, soup, and side dishes is a great touch."

**Output Format (You must follow this format):**
Title: [Your title here]

Script: [Your script here]

**No explanations or annotations needed. Follow the format above.**`;
            }

            // Call AI API based on user
            const EXCLUDED_USER = 'moonlight8909@gmail.com';
            const userEmail = req.user ? req.user.email : ''; // req.user comes from requireAuth middleware

            if (userEmail && userEmail !== EXCLUDED_USER) {
                // === USE 302.AI (OpenAI Compatible) ===
                const api302Key = process.env.API_KEY_302AI;
                // Assuming standard OpenAI-compatible endpoint for 302.ai
                // User mentioned 302.ai, usually proxies OpenAI. 
                // If not set, we might fallback or error. For now, try/catch with fallback or specific error.

                if (!api302Key) {
                    // Since user requested it, we should probably error if missing, or use Gemini as fallback?
                    // "All features must run on 302ai api" implies strict requirement.
                    // But to avoid breakage if keys are missing during dev:
                    console.warn('302.ai Key missing, falling back to Gemini temporarily or failing.');
                    // throw new Error('302.ai API Key (API_KEY_302AI) is not configured.');
                }

                // 302.ai Endpoint (defaulting to typical if not in env)
                const api302Endpoint = process.env.BASE_URL_302AI || 'https://api.302.ai/v1/chat/completions';
                const api302Model = process.env.MODEL_302AI || 'gpt-4o';

                const response = await fetch(api302Endpoint, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${api302Key}`
                    },
                    body: JSON.stringify({
                        model: api302Model,
                        messages: [
                            { role: "system", content: "You are a professional script writer." },
                            { role: "user", content: prompt }
                        ],
                        temperature: 0.8,
                        max_tokens: 1024
                    })
                });

                const data = await response.json();
                if (!response.ok) {
                    throw new Error(`302.ai API Error: ${data.error?.message || response.statusText}`);
                }

                if (data.choices && data.choices[0]?.message?.content) {
                    return data.choices[0].message.content;
                } else {
                    return "Error: No generation from 302.ai";
                }

            } else {
                // === USE GOOGLE GEMINI (Existing) ===
                // Using gemini-2.0-flash-exp
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        contents: [{ parts: [{ text: prompt }] }],
                        generationConfig: {
                            temperature: 0.8,
                            maxOutputTokens: 1024
                        }
                    })
                });

                const data = await response.json();
                if (!response.ok) {
                    throw new Error(`Gemini API Error: ${data.error?.message || response.statusText}`);
                }
                if (data.candidates && data.candidates[0]?.content?.parts?.[0]?.text) {
                    return data.candidates[0].content.parts[0].text;
                } else {
                    return "Error: No generation";
                }
            }
        }

        // Execute all promises
        // Execute all promises
        const promises = [];
        for (const style of styles) {
            for (let i = 0; i < actualCount; i++) {
                promises.push(
                    generateSingleScript(style)
                        .then(script => ({ style, script, index: i, success: true }))
                        .catch(e => {
                            console.error(`Error generating style ${style} #${i + 1}:`, e);
                            return { style, script: `Error: ${e.message}`, index: i, success: false };
                        })
                );
            }
        }

        const generated = await Promise.all(promises);

        generated.forEach(item => {
            const key = actualCount > 1 ? `${item.style} #${item.index + 1}` : item.style;
            results[key] = item.script;
        });

        await Promise.all(promises);
        res.json({ success: true, results });

    } catch (error) {
        console.error('Script generation failed:', error);
        res.status(500).json({ success: false, error: error.message });
    }
});


// TTS Endpoint
router.post('/generate-tts', async (req, res) => {
    try {
        const { text, provider, language, title, storeName } = req.body;

        console.log(`[TTS] Request: Provider=${provider}, Lang=${language}, Text Length=${text.length}, Title=${title || storeName || 'N/A'}`);

        // íŒŒì¼ëª… ìƒì„±: ì œëª©/ê°€ê²Œëª… + ë‚ ì§œ + ì‹œê°„
        const now = new Date();
        const dateStr = now.toISOString().slice(0, 10).replace(/-/g, ''); // YYYYMMDD
        const timeStr = now.toTimeString().slice(0, 8).replace(/:/g, ''); // HHMMSS

        // Sanitize and normalize filename
        // 1. Normalize to NFC (to avoid NFD/NFC conflicts in sync)
        let safeName = (storeName || title || '').normalize('NFC');
        // 2. Remove any chars that aren't Word, Korean, or Space
        // \w includes [A-Za-z0-9_]
        safeName = safeName.replace(/[^\w\sê°€-í£]/g, '');
        // 3. Replace whitespace with underscore
        safeName = safeName.replace(/\s+/g, '_');
        // 4. Remove consecutive underscores and trim from ends
        safeName = safeName.replace(/_+/g, '_').replace(/^_+|_+$/g, '');

        let baseName = safeName.slice(0, 30) || 'tts_audio';
        const ttsFileName = `${baseName}_${dateStr}_${timeStr}.mp3`;

        if (provider === 'Google') {
            await ensureAudioDir();

            // Google Cloud TTS configuration
            const request = {
                input: { text: text },
                voice: {
                    languageCode: language === 'Korean' ? 'ko-KR' : 'en-US',
                    // Use standard voices as fallback if specific 'Algenib' is not available in standard lib
                    // However, user requested Algenib. 'ko-KR-Standard-A' is safe.
                    // Algenib corresponds to a specific new voice type, potentially Chirp or Journey.
                    // We will use Neural2 Male if possible as a good substitute if Algenib ID is unknown.
                    // Actually, let's try 'ko-KR-Neural2-C' (Male) for Korean and 'en-US-Neural2-D' (Male) for English
                    name: language === 'Korean' ? 'ko-KR-Neural2-C' : 'en-US-Neural2-D'
                },
                audioConfig: {
                    audioEncoding: 'MP3',
                    speakingRate: 1.5
                },
            };

            const [response] = await ttsClient.synthesizeSpeech(request);
            const audioContent = response.audioContent;

            const filePath = path.join(AUDIO_OUTPUT_PATH, ttsFileName);

            await fs.writeFile(filePath, audioContent, 'binary');

            res.json({
                success: true,
                audioPath: `/audio/${ttsFileName}`,
                localPath: filePath
            });

        } else if (provider === 'Azure') {
            await ensureAudioDir();

            // Checks for Azure keys
            const speechKey = process.env.AZURE_SPEECH_KEY;
            const serviceRegion = process.env.AZURE_SPEECH_REGION;

            if (!speechKey || !serviceRegion) {
                return res.status(400).json({
                    success: false,
                    error: "Azure API Key or Region is missing. Please configure them in Settings."
                });
            }

            const speechConfig = sdk.SpeechConfig.fromSubscription(speechKey, serviceRegion);

            // Set voice based on language
            // Using 'Hyunsu' for Korean and 'Andrew Multilingual' for English
            let rate;
            if (language === 'Korean') {
                speechConfig.speechSynthesisVoiceName = "ko-KR-HyunsuNeural";
                rate = "1.5"; // Korean 1.5x
            } else {
                speechConfig.speechSynthesisVoiceName = "en-US-AndrewMultilingualNeural";
                rate = "1.3"; // English 1.3x
            }

            const filePath = path.join(AUDIO_OUTPUT_PATH, ttsFileName);

            // Synthesize to file
            const audioConfig = sdk.AudioConfig.fromAudioFileOutput(filePath);
            const synthesizer = new sdk.SpeechSynthesizer(speechConfig, audioConfig);

            // SSML for speaking rate adjustment
            // Azure SDK doesn't have a direct 'speakingRate' property on SpeechConfig like Google.
            // We use SSML to adjust speed.
            const ssml = `
                <speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="${language === 'Korean' ? 'ko-KR' : 'en-US'}">
                    <voice name="${speechConfig.speechSynthesisVoiceName}">
                        <prosody rate="${rate}">
                            ${text}
                        </prosody>
                    </voice>
                </speak>
            `;

            synthesizer.speakSsmlAsync(ssml,
                result => {
                    if (result.reason === sdk.ResultReason.SynthesizingAudioCompleted) {
                        synthesizer.close();
                        res.json({
                            success: true,
                            audioPath: `/audio/${ttsFileName}`,
                            localPath: filePath
                        });
                    } else {
                        synthesizer.close();
                        res.status(500).json({
                            success: false,
                            error: `Azure TTS Generation Failed: ${result.errorDetails}`
                        });
                    }
                },
                error => {
                    synthesizer.close();
                    console.error('Azure TTS Error:', error);
                    res.status(500).json({ success: false, error: error });
                }
            );

        } else if (provider === 'ElevenLabs') {
            await ensureAudioDir();

            const apiKey = process.env.ELEVENLABS_API_KEY;

            // Define allowed voices for random selection
            const PRESET_VOICES = [
                'mYk0rAapHek2oTw18z8x', // Voice 1
                '4JJwo477JUAx3HV0T7n7', // Voice 2
                'QPFsEL6IBxlT15xfiD6C', // Voice 3
                'uyVNoMrnUku1dZyVEXwD'  // Voice 4
            ];

            let voiceId = req.body.voiceId || process.env.ELEVENLABS_VOICE_ID;

            // If voiceId is 'random', 'neutral' (legacy default), 'surprise' (legacy), or not in list (and not explicitly set in env to something else), pick random
            // Actually, allow any valid ID if passed, but if 'random' or legacy keywords, pick from PRESET.
            if (!voiceId || voiceId === 'random' || voiceId === 'neutral' || voiceId === 'surprise') {
                voiceId = PRESET_VOICES[Math.floor(Math.random() * PRESET_VOICES.length)];
                console.log(`[ElevenLabs] Random voice selected: ${voiceId}`);
            }

            // Fallback if still empty (shouldn't happen with logic above)
            if (!voiceId) voiceId = '21m00Tcm4TlvDq8ikWAM';

            if (!apiKey) {
                return res.status(500).json({ success: false, error: 'ELEVENLABS_API_KEY is not configured.' });
            }

            const filePath = path.join(AUDIO_OUTPUT_PATH, ttsFileName);

            const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`, {
                method: 'POST',
                headers: {
                    'Accept': 'audio/mpeg',
                    'Content-Type': 'application/json',
                    'xi-api-key': apiKey
                },
                body: JSON.stringify({
                    text: text,
                    model_id: "eleven_multilingual_v2", // Better for multiple languages including Korean
                    voice_settings: {
                        stability: 0.5,
                        similarity_boost: 0.75
                    }
                })
            });

            if (!response.ok) {
                const errorData = await response.json();
                console.error('ElevenLabs API Error:', errorData);

                // Check for quota exceeded, payment required error and Fallback to 302.ai (MiniMax)
                if (errorData.detail?.status === 'quota_exceeded' || errorData.detail?.status === 'payment_required' || response.status === 401 || response.status === 429) {
                    console.warn('ElevenLabs Quota Exceeded or Payment Required. Falling back to 302.ai (MiniMax)...');

                    const api302Key = process.env.AI_302_API_KEY;
                    if (!api302Key) {
                        throw new Error(`ElevenLabs Limit Reached & 302.ai Key Missing: ${errorData.detail?.message}`);
                    }

                    // 302.ai TTS (MiniMax) Logic
                    // voice_id: 'male-qn-qingse', 'female-shaonv', 'male-ad-boy' etc.
                    // Let's use a standard Korean 302 voice or map randomness
                    const minimaxVoices = ['male-qn-qingse', 'female-shaonv', 'presenter_male', 'presenter_female'];
                    const randomVoice = minimaxVoices[Math.floor(Math.random() * minimaxVoices.length)];

                    const response302 = await fetch('https://api.302.ai/v1/audio/speech', {
                        method: 'POST',
                        headers: {
                            'Authorization': `Bearer ${api302Key}`,
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify({
                            model: 'minimax', // or tts-1-hd depending on 302 support. Assuming 'minimax' or standard openai format
                            input: text,
                            voice: randomVoice,
                            speed: 1.3 // 302/MiniMax might support speed directly
                        })
                    });

                    if (!response302.ok) {
                        const errText = await response302.text();
                        throw new Error(`302.ai Backup TTS Failed: ${errText}`);
                    }

                    const arrayBuffer302 = await response302.arrayBuffer();
                    const buffer302 = Buffer.from(arrayBuffer302);

                    // Save directly (assuming 302 returns mp3) - no speed adjustment needed if speed param worked, 
                    // but we will treat it same as ElevenLabs output for consistency
                    await fs.writeFile(filePath, buffer302);

                    console.log(`[TTS] Applied 302.ai (Backup) text-to-speech.`);

                    res.json({
                        success: true,
                        audioPath: `/audio/${ttsFileName}`,
                        localPath: filePath
                    });
                    return; // Exit successfully
                }

                throw new Error(`ElevenLabs TTS Failed: ${errorData.detail?.message || response.statusText}`);
            }

            const arrayBuffer = await response.arrayBuffer();
            const buffer = Buffer.from(arrayBuffer);

            // Speed up audio to 1.3x using ffmpeg
            const tempFilePath = filePath.replace('.mp3', '_temp.mp3');
            await fs.writeFile(tempFilePath, buffer);
            console.log(`[TTS] Applied text-to-speech. Original size: ${buffer.length}`);

            try {
                const ffmpeg = (await import('fluent-ffmpeg')).default;
                const ffmpegStatic = (await import('ffmpeg-static')).default;
                const ffprobeStatic = (await import('ffprobe-static')).default;

                let ffmpegPath = ffmpegStatic;
                try {
                    if (!ffmpegPath || !(await fs.stat(ffmpegPath).catch(() => false))) {
                        console.warn('[AI Video] ffmpeg-static binary not found, falling back to system "ffmpeg"');
                        ffmpegPath = 'ffmpeg';
                    }
                } catch (e) { ffmpegPath = 'ffmpeg'; }

                ffmpeg.setFfmpegPath(ffmpegPath);
                ffmpeg.setFfprobePath(ffprobeStatic.path);
                await new Promise((resolve, reject) => {
                    console.log('[TTS] Starting speed adjustment (1.3x) and silence removal...');
                    ffmpeg(tempFilePath)
                        .audioFilters([
                            'silenceremove=start_periods=1:start_duration=0:start_threshold=-60dB', // Trim only start silence, stricter threshold
                            'atempo=1.3' // Speed up
                        ])
                        .save(filePath)
                        .on('end', () => {
                            console.log('[TTS] Speed adjustment completed.');
                            resolve();
                        })
                        .on('error', (err) => {
                            console.error('[TTS] Speed adjustment error:', err);
                            reject(err);
                        });
                });
                // Remove temp file
                await fs.unlink(tempFilePath);
            } catch (ffmpegErr) {
                console.error('FFmpeg speed adjustment failed, using original:', ffmpegErr);
                // Fallback: use original (rename temp to final)
                await fs.rename(tempFilePath, filePath);
            }

            res.json({
                success: true,
                audioPath: `/audio/${ttsFileName}`,
                localPath: filePath
            });

        } else {
            res.status(400).json({ success: false, error: 'Invalid provider' });
        }

    } catch (error) {
        console.error('TTS Failed:', error);
        res.status(500).json({ success: false, error: error.message });
    }
});

export default router;
